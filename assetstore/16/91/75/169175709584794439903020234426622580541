 
 
Instituto Tecnológico de Orizaba 
División de Estudios de Posgrado e Investigación 
Maestría en Sistemas Computacionales 
TESIS 
 “Generación automática de interfaces de usuario multi-dispositivo para el 
ámbito de e-Commerce y Social Media mediante técnicas de Deep Learning” 
 
PRESENTA: 
I.T.C. Aarón Colmenares Morales 
 
PARA OBTENER EL GRADO DE: 
Maestro en Sistemas Computacionales 
 
DIRECTOR: 
Dr. Giner Alor Hernández 
 
CO-DIRECTOR: 
M.S.C. Laura Nely Sánchez Morales
Contenido 
Resumen ............................................................................................................................ VIII 
Abstract ................................................................................................................................. IX 
Introducción ........................................................................................................................... X 
Capítulo 1 Antecedentes ......................................................................................................... 1 
1.1. Marco Conceptual .................................................................................................... 1 
1.1.1. Inteligencia Artificial ........................................................................................... 1 
1.1.1.1. Aprendizaje Automático ................................................................................... 1 
1.1.1.2. Aprendizaje Profundo ....................................................................................... 1 
1.1.1.2.1. Redes Neuronales Convolucionales .............................................................. 2 
1.1.1.2.1.1. Inception_V3................................................................................................. 2 
1.1.1.2.1.2. AlexNet ......................................................................................................... 3 
1.1.2. User Interface Design Pattern, Patrones de Diseño de Interfaz de Usuario 
(UIDPs) 3 
1.1.2.1. Composición de Interfaces de Usuarios ........................................................... 3 
1.1.3. Aplicaciones de Social Media .............................................................................. 3 
1.1.3.1. Tipos de aplicación ........................................................................................... 3 
1.1.4. Aplicaciones de Comercio Electrónico ................................................................ 4 
1.1.4.1. Tipos de aplicación ........................................................................................... 4 
1.1.6. APIs de aprendizaje profundo .............................................................................. 4 
1.1.6.1. TensorFlow ....................................................................................................... 5 
1.1.6.2. Keras ................................................................................................................. 6 
1.1.7. Lenguaje de programación con soporte para Deep Learning .............................. 8 
1.1.7.1. Python ............................................................................................................... 8 
1.1.8. IDEs ...................................................................................................................... 8 
1.1.7.1. Spyder ............................................................................................................... 8 
1.1.9. Servidor de aplicaciones Web .............................................................................. 9 
1.1.9.1. Apache HTTPS Server ..................................................................................... 9 
1.1.10. Metodología para el desarrollo de software ..................................................... 9 
1.1.9.1. Prototipado........................................................................................................ 9 
1.2. Planteamiento del Problema .................................................................................. 10 
1.3. Objetivo General .................................................................................................... 11 
1.3.1. Objetivos Específicos ......................................................................................... 11 
1.4. Justificación ........................................................................................................... 11 
Capítulo 2 Estado de la Práctica ........................................................................................... 13 
2.1. Trabajos relacionados ............................................................................................ 13 
2.1.1. Herramientas para la generación de aplicaciones o desarrollo de software ....... 13 
2.1.2. Técnicas Deep Learning en el desarrollo de software ....................................... 17 
2.2. Análisis comparativo ............................................................................................. 21 
2.3. Solución propuesta ................................................................................................. 23 
2.4. Justificación de la solución propuesta.................................................................... 24 
Capítulo 3 Aplicación de la metodología ............................................................................. 25 
3.1. Proceso de generación de software ........................................................................ 25 
3.2. Elementos identificados de UIDPs ........................................................................ 28 
3.2.1. Análisis de UIDPs en Social Media ................................................................... 28 
3.2.2. Análisis de UIDPs en e-Commerce .................................................................... 34 
3.2.3. Análisis de Composiciones de UIDPs ................................................................ 36 
3.3. Proceso de identificación de elementos en interfaces mediante Deep Learning ... 47 
3.3.1. Conjunto de imágenes ........................................................................................ 47 
3.4. Proceso de transformación de la imagen ............................................................... 50 
3.4.1. Descripción del entrenamiento ........................................................................... 51 
II 
 
3.4.1.1. Entrenamiento con diferentes modelos de redes neuronales .......................... 52 
3.4.1.2. Entrenamiento con AlexNet ........................................................................... 54 
3.4.1.3. Entrenamiento con Inception_v3 .................................................................... 71 
3.5. Implementación del módulo del procesamiento .................................................... 85 
3.5.1. Diagramas de clases ........................................................................................... 85 
3.5.2. Funcionalidades principales ............................................................................... 87 
3.6. Implementación del módulo de generación de código. ......................................... 96 
3.6.1. Archivo de configuración basado en XML ........................................................ 96 
3.6.2. Estructura final de los proyectos generados ....................................................... 99 
3.6.3. Servicio REST del módulo generador de aplicaciones .................................... 101 
Capítulo 4 Resultados ......................................................................................................... 103 
4.1. Caso de estudio 1: Generación de una aplicación de e-Commerce ..................... 103 
4.1.1. Diseño de la aplicación a generar ..................................................................... 103 
4.1.2. Generación de aplicación ................................................................................. 105 
4.1.3. Revisión de la aplicación generada .................................................................. 113 
4.2. Caso de estudio 2: Generación de una aplicación Social Media ......................... 114 
4.2.1. Diseño de la aplicación a generar ..................................................................... 114 
4.2.2. Generar aplicación............................................................................................ 116 
4.2.3. Revisión de la aplicación generada .................................................................. 123 
Capítulo 5 Conclusión y recomendaciones ........................................................................ 125 
5.1. Conclusiones ........................................................................................................ 125 
5.2. Recomendaciones ................................................................................................ 125 
Productos académicos ..................................................................................................... 127 
Referencias ......................................................................................................................... 128 
 
III 
 
Índice de tablas 
Tabla 1.1 Características de las APIs ..................................................................................... 7 
Tabla 2.1 Análisis comparativo ............................................................................................ 22 
Tabla 2.2 Análisis de la propuesta de solución .................................................................... 23 
Tabla 3.1 UIDPs Social Media por reputación ..................................................................... 29 
Tabla 3.2 UIDPs Sociale Media por interacción .................................................................. 30 
Tabla 3.3 UIDPs e-Commerce.............................................................................................. 34 
Tabla 3.4 Composiciones de UIDPs para e-Commerce ....................................................... 36 
Tabla 3.5 Composiciones de UIDPs para Social Media ....................................................... 43 
Tabla 3.6 UIDPs simples ideales y no ideales ...................................................................... 48 
Tabla 3.7 Composiciones de UIDPs Reales en blanco y negro, y reales a color ................. 49 
Tabla 3.8 Resultados de la prueba 1 ..................................................................................... 52 
Tabla 3.9 Resultados de la prueba 2 ..................................................................................... 52 
Tabla 3.10 Resultados de la prueba 3 ................................................................................... 53 
Tabla 3.11 Resultados de la prueba 4 ................................................................................... 53 
Tabla 3.12 Tabla de entrenamiento para AlexNet con 9 patrones y 200 instancias c/u ....... 55 
Tabla 3.13 Tabla de entrenamiento para AlexNet con 9 patrones y 400 instancias c/u ....... 56 
Tabla 3.14 Tabla de entrenamiento para AlexNet con 17 patrones y 400 instancias c/u ..... 57 
Tabla 3.15 Tabla de entrenamiento para AlexNet con 27 patrones (1) ................................ 59 
Tabla 3.16 Resultados de Entrenamiento para Inception_V3 con 9 patrones y 200 instancias 
c/u ......................................................................................................................................... 72 
Tabla 3.17 Tabla de entrenamiento para Inception_V3 con 9 patrones y 400 instancias c/u
 .............................................................................................................................................. 73 
Tabla 3.18 Tabla de entrenamiento para Inception_V3 con 17 patrones y 400 instancias c/u 
(1).......................................................................................................................................... 74 
Tabla 3.19 Tabla de entrenamiento de Inception_v3 con 27 patrones (1) ........................... 76 
 
  
IV 
 
Índice de Figuras 
Fig. 3.1 Proceso de generación de software a partir de técnicas Deep Learning. ................ 25 
Fig. 3.2 UIDPs Social Meda por reputación: leaderboards y Achievements ....................... 29 
Fig. 3.3 contiene la representación de: Gallery, Reaction y Friend ...................................... 32 
Fig. 3.4 UIDPs Social Meda por Interacción: Gallery, Reaction y Friend ........................... 33 
Fig. 3.5 UIDPs Social Meda por Interacción: Comments, Follow y Picker......................... 33 
Fig. 3.6 UIDPs Social Meda por Interacción: Chat, Menu Vertical y Activity Stream ....... 33 
Fig. 3.7 UIDPs Social Meda por Interacción: Friend List y Panel ....................................... 34 
Fig. 3.8 UIDPs e-commerce: Coupon, Shopping Cart y Pricing Table................................ 35 
Fig. 3.9 UIDPs e-Commerce: Product Page y Stats ............................................................. 36 
Fig. 3.10 Composiciones: Bus-men-pro-com, Bus-men-pro-pla y Bus-men-pro-gal .......... 40 
Fig. 3.11 Composiciones:  Bus-men-pro-tip y Bus-men-sho-cou ........................................ 40 
Fig. 3.12 Composiciones: Bus-men-pro-com, Bus-men-pro-pla y Bus-men-pro-gal .......... 41 
Fig. 3.13 Composiciones: Bus-men-sho-pro-com, Bus-men-pan-pri y Bus-men-pro-sta .... 41 
Fig. 3.14 Composiciones: Bus-men-pro-sta-com, Bus-men-pro-sta-com y Men-sho-gal-pri
 .............................................................................................................................................. 42 
Fig. 3.15 UIDPs de composición e-Commerce: Men-sho-pla-pri, Men-sho,pri,sta y Bus-
men-pri-sta ............................................................................................................................ 42 
Fig. 3.16 UIDPs de composición e-Commerce: Bus-men-gal-pla y Bus-men-pla-pri ......... 43 
Fig. 3.17 Composiciones Social Media: Bus-men-log,Bus-men-com-rea y Bus-men-pan-fin
 .............................................................................................................................................. 45 
Fig. 3.18 UIDPs de composición Social Media: Bus-men-log,Bus-men-com-rea y Bus-
men-pan-fin .......................................................................................................................... 46 
Fig. 3.19 Composiciones Social Media: Bus-men-fin-fli, Bus-men-fin-fri y Bus-men-act . 46 
Fig. 3.20 Composición Social Media: Bus-men-ran ............................................................ 47 
Fig. 3.21 Ejemplo de la eliminación del ruido de una imagen real a color, a) imagen real a 
color, b) imagen real aplicación en la  eliminación de sombras, c) imagen real aplicación 
eliminación de ruido. ............................................................................................................ 51 
Fig. 3.22 Arquitectura de la red neuronal convolucional con 5 capas convolucionales, 1 
capa flattening, 1 capa fully-con y capa de salida. ............................................................... 54 
Fig. 3.23 Arquitectura de la red neuronal convolucional Inception_v3 ............................... 71 
V 
 
Fig. 3.24 Diagrama de clases para el entrenamiento ............................................................ 86 
Fig. 3.25 Diagrama de clases para cargar el servicio REST ................................................. 87 
Fig. 3.26 Arquitectura de TensorFlow Serving .................................................................... 93 
Fig. 3.27 Respuesta del servicio ........................................................................................... 94 
Fig. 3.28 Estructura del generador XML .............................................................................. 98 
Fig. 3.29 Estructura de la carpeta ProjectBase ..................................................................... 99 
Fig. 3.30 Estructura de la carpeta para el proyecto Web .................................................... 100 
Fig. 3.31 Estructura de la carpeta para el proyecto Android™ .......................................... 100 
Fig. 3.32 Estructura de la carpeta para el proyecto macOS® .............................................. 101 
Fig. 4.1 UIDP para el caso de estudio 1 ............................................................................. 104 
Fig. 4.2 UIDP no ideal para el caso de estudio 1................................................................ 105 
Fig. 4.3 Menú del generador pestaña Freehand .................................................................. 105 
Fig. 4.4  Pestaña Freehand selección de imagen ................................................................ 106 
Fig. 4.5 Pestaña Freehand selección de imagen ................................................................. 106 
Fig. 4.6 Pestaña Freehand subiendo archivo ...................................................................... 107 
Fig. 4.7 Pestaña Freehand UIDPs identificados ................................................................. 107 
Fig. 4.8 Pestaña Freehand Select Patterns .......................................................................... 108 
Fig. 4.9 Pestaña Freehand Select Patterns .......................................................................... 108 
Fig. 4.10 Pestaña Freehand Select Domain ........................................................................ 109 
Fig. 4.11 Pestaña Freehand Select Template ...................................................................... 109 
Fig. 4.12 Pestaña Freehand Select the type of Entertainment Application ........................ 110 
Fig. 4.13 Pestaña Freehand Select Device and Platform .................................................... 110 
Fig. 4.14 Pestaña Freehand Configure Application ............................................................ 111 
Fig. 4.15 Pestaña Freehand Configure Application ............................................................ 112 
Fig. 4.16 Pestaña Freehand Download ............................................................................... 112 
Fig. 4.17 Archivo zip .......................................................................................................... 113 
Fig. 4.18 Revisión del Proyecto del caso de estudio 1 ....................................................... 113 
Fig. 4.19 UIDP para el caso de estudio 2 ........................................................................... 115 
Fig. 4.20 UIDP no ideal para el caso de estudio 2 .............................................................. 115 
Fig. 4.21 Menú del generador pestaña Freehand ................................................................ 116 
Fig. 4.22 Pestaña Freehand selección de imagen ............................................................... 117 
VI 
 
Fig. 4.23 Pestaña Freehand selección de imagen ............................................................... 117 
Fig. 4.24 Pestaña Freehand subiendo archivo .................................................................... 118 
Fig. 4.25 Pestaña Freehand UIDPs identificados ............................................................... 118 
Fig. 4.26 Pestaña Freehand Select Patterns ........................................................................ 119 
Fig. 4.27 Pestaña Freehand Select Patterns ........................................................................ 119 
Fig. 4.28 Pestaña Freehand Select Domain ........................................................................ 120 
Fig. 4.29 Pestaña Freehand Select Template ...................................................................... 120 
Fig. 4.30 Pestaña Freehand Select the type of Entertainment Application ........................ 121 
Fig. 4.31 Pestaña Freehand Select Device and Platform .................................................... 121 
Fig. 4.32 Pestaña Freehand Configure Application ............................................................ 122 
Fig. 4.33 Pestaña Freehand Configure Application ............................................................ 122 
Fig. 4.34 Pestaña Freehand Download ............................................................................... 123 
Fig. 4.35 Archivo zip .......................................................................................................... 123 
Fig. 4.36 Revisión del Proyecto Caso de estudio 2 ............................................................ 124 
 
Índice de Código 
Listado de código. 3.1 Clase Transformacion.py ................................................................. 87 
Listado de código. 3.2 Clase Entrenamiento.py ................................................................... 89 
Listado de código. 3.3 Clase ExportarModelo.py ................................................................ 92 
Listado de código. 3.4 Comando para la terminal en linux .................................................. 94 
código. 3.5  Clase Servidor.py .............................................................................................. 95 
Listado de código. 3.6 Servicio.php ................................................................................... 102 
 
  
VII 
 
Resumen 
El aprendizaje profundo incrementa progresivamente su uso día con día, tanto en las 
computadoras y dispositivos móviles para automatizar las aplicaciones. Gracias al 
aprendizaje profundo que permite el apoyo en varias áreas como transporte o salud, se 
incrementó considerablemente el uso de las redes neurales que implica aprendizaje de 
percepción de objetos, traducción y reconocimiento. El aprendizaje profundo genera una gran 
ayuda en los ámbitos médicos, traducción de textos o hasta la identificación de caminos, ya 
que se usan inclusive para coches autónomos. Algo a tomar en cuenta del aprendizaje 
profundo es la precisión al momento de identificar objetos, por la tanto, la precisión satisface 
la necesidad de los usuarios en el ámbito de consumo electrónico. 
El objetivo del presente trabajo de investigación es desarrollar un módulo para la generación 
automática de interfaces de usuario las cuales se desplieguen en diferentes dispositivos, esto 
es, a partir de una imagen digital identificar mediante técnicas de aprendizaje profundo los 
elementos en la imagen para aplicaciones de dominios e-Commerce y Social media.   
Como principal beneficio que conlleva el trabajo al desarrollar el módulo, es tener 
aplicaciones dinámicas que permitan integrarse en el dominio e-Commerce y Social media. 
La aplicación del aprendizaje profundo como parte de la inteligencia artificial corresponde a 
una transformación digital, que permite ser más eficiente para el usuario final y el 
desarrollador de software, además de reducir errores humanos y costo de desarrollo. 
VIII 
 
Abstract 
Deep learning is gradually increasing the use day by day on computers and mobile device to 
automate applications. Thanks to deep learning that significantly increased the use of the 
neuronal networks to compete to learn object perception, translate an recognize. Deep 
learning gives a huge help on medical checks, translations of text or even identification of 
roads for autonomous cars. To take deep learning into account is the precision when 
identifying, therefore, the precision satisfies the needs of the users on improving the 
performance of electrical consumption.  
The goal for this paper propones is a develop module for automatic generation of user 
interfaces which are deployed on different devices from a digital image for e-Commerce and 
Social Media domains through deep learning techniques. 
The main benefit of develop the module, it is working a dynamic application that can be fully 
integrated into e-Commerce y Social Media domains. The application of deep learning as 
part of artificial intelligence corresponds to the digital transformation because it allows be 
more efficient to the end user and the software developer in addition to reducing human errors 
and development cost.   
IX 
 
Introducción 
Día a día se generan nuevos y variados métodos en el desarrollo de software más rápidos, 
certeros y confiables. Desde el punto de vista de la ingeniería del software y de forma 
específica dentro de la etapa de diseño de software, los UIDPs son una solución recurrente 
que resuelve problemas comunes de diseño, como son: las resoluciones de diferentes 
dispositivos, el diseño responsivo o problemas de navegación; todas estas soluciones se 
plantean a través de un lenguaje común para los diseñadores. Por su parte, el uso de 
aplicaciones de dominios como e-Commerce y Social medi, cuentan con una gran demanda 
para los usuarios, debido a que se exapenden los nichos de mercado cada vez más al entorno 
social.  
Por otra parte, el Deep Learning es un subconjunto de técnicas de inteligencia artificial que 
permite diseñar modelos computacionales compuestos de múltiples capas para aprender un 
conjunto de datos etiquetados, con el contenido de varias capas permiten el reconocimiento 
del lenguaje, la detección de algún objeto e inclusive la traducción. Dentro del Deep Learning 
encontramos las CNN (Convolutional Neural Networks, Red Neuronal Convolucional), las 
cuales son redes neuronales para procesar datos que llegan en forma de múltiples arreglos, y 
generar una rápida detección de bordes, líneas, entre otras características simples.  
De acuerdo a la literatura revisada en este documento existen generadores de software 
similares y se encuentra orientados a otros dominios, existen también procesos poco 
orientados para las aplicaciones e-Commerce y Social Media que manipulen técnicas de Deep 
Learning y ayuden en el reconocimiento de UIDPs en imágenes. Desde esta perspectiva, la 
identificación de cada UIDP es importante para clasificar y determinar el tipo de dispositivo 
adecuado para su funcionamiento. Tal situación, motiva a plantear un proceso de generación 
automática de aplicaciones basado en técnicas de Deep Learning.  
El primer pilar de tres en esta investigación, es generar software y aplicar el uso de una 
imagen o un boceto generado a mano alzada. El segundo pilar, es el desarrollo de software 
basado en el aprendizaje profundo, donde una de las características principales que se 
aprovechó en el desarrollo de software es el aprendizaje a través del entrenamiento, el cual 
mejora el tiempo de desarrollo. El tercer pilar son los UIDPs, ya que permiten identificar y 
restaurar ciertos errores de una aplicación, tales como mantener una resolución estándar y 
X 
 
rectificar errores generados de diseño por el desarrollador, cumpliendo con una aplicación 
fácil de usar para el usuario. 
Como contribuciones para la ingeniería de software, se tienen cuatro aspectos importantes: 
(1) generar beneficios para que el proceso de desarrollo de software sea mucho más intuitivo 
y que sea tan bueno como lo hace un ser humano, (2) diseñar un modelo de machine learning 
y un conjunto de reglas que permitan la generación automática de código, (3) tener un mejor 
desempeño para aumentar la precisión en la clasificación de imágenes que mejore los ciclos 
de desarrollo del software y (4) enriquecer las aplicaciones que se sumen a las actividades 
diarias y aumente la motivación para el desarrollo de software.  
Este documento está estructurado de la siguiente manera, en el capítulo 1 se detallan los 
antecedentes y su marco conceptual, en el capítulo 2 se presenta el estado del arte referente 
a los diversos trabajos relacionados para la generación automática de software, divido en dos 
partes: herramientas para la generación de aplicaciones o desarrollo de software y técnicas 
Deep Learrning en el desarrollo de software. En el capítulo 3 la propuesta de solución, que 
incluye una descripción de los UIDPs identificados, analizados y aplicados para la generación 
automática de aplicaciones del dominio e-Commerce y Social Media. Se describe lo que 
implica el proceso de generación de software. En el capítulo 4 se definen dos casos de estudio 
que hacen uso del generador de aplicaciones y la utilización de loa red neuronal utilizada. 
Finalmente, el capítulo 5 se presentan las conclusiones y recomendaciones del trabajao de 
investigación. 
 
 
 
 
 
 
 
 
XI 
 
Capítulo 1 Antecedentes 
1.1. Marco Conceptual 
En la siguiente sección se abordan los términos destacados y relacionados con el trabajo de 
investigación. Cada término tiene una breve descripción que permita comprender mejor.   
 
1.1.1. Inteligencia Artificial 
La A.I. (Artificial Intelligence, Inteligencia Artificial) en términos amplios es la forma de 
cómo las máquinas desempeñan tareas humanas, tales como aprender, razonar y resolver 
problemas. Por tal motivo, son sofisticados algoritmos que reconocen patrones en registro de 
datos no estructurados como las imágenes, el texto y el lenguaje [1].   
 
1.1.1.1. Aprendizaje Automático 
Machine Learning o Aprendizaje Automático es derivado como subconjunto de la A.I. [2]. 
El aprendizaje automático ofrece técnicas y modelos que se seleccionan en función de la 
aplicación, dependiendo del tamaño de datos para procesar y el tipo de problema a resolver.  
 
1.1.1.2. Aprendizaje Profundo 
Derivado como un subconjunto de la A.I. y del aprendizaje automático que utiliza redes 
neuronales artificiales, el aprendizaje profundo soporta modelos computacionales 
compuestos de múltiples capas procesadas para aprender representaciones de datos con 
contenido de varias capas, que permiten el reconocimiento del lenguaje, la detección de algún 
objeto e inclusive la traducción. El aprendizaje profundo descubre una estructura intricada 
sobre un conjunto de datos, el usar el algoritmo de retro propagación para indicar cómo la 
máquina cambia sus parámetros internos para la representación en cada capa desde la 
representación en una capa previa. Los métodos mantienen un mejoramiento en el 
reconocimiento del lenguaje, reconocimiento de objetos visuales, detección de objetos y 
muchos otros dominios tales como descubrimiento de medicamentos y genómicas [3]. 
Gracias a las grandes cantidades de datos etiquetados y la potencia de cálculo de las GPU 
(Graphics Processing Unit, Unidad de Procesamiento Gráfico) se logra una eficiencia para 
1 
 
cubrir el aprendizaje profundo. Algunas técnicas de aprendizaje profundo actualmente 
aplicadas son: 
• Conducción autónoma: detección de objetos y personas, contribuye a reducir 
accidentes. 
• Sector aeroespacial y de defensa: identificar objetos desde los satélites en ciertas 
áreas seguras o no seguras. 
• Investigación médica: detección de células cancerígenas. 
• Electrónica (CES): audición automatizada y la traducción del habla. 
 
1.1.1.2.1. Redes Neuronales Convolucionales 
Las ConvNet o CNN [3] (Convolucional Neural Networks, Redes Neuronales 
Convolucionales) son diseños para procesar datos que llegan en forma de múltiples arreglos, 
por ejemplo, una imagen a color compuesta de tres arreglos 2D que contiene intensidades de 
pixeles en los tres canales de color. Las modalidades de los datos están en la forma de 
múltiples arreglos: 1D para señales y secuencias para agregar el lenguaje; 2D para imágenes 
o espectrogramas de audio y 3D para video o imágenes volumétricas. Se mantiene cuatro 
ideas claves detrás de los ConvNets que toman ventaja de las propiedades de señales locales: 
conexiones locales, pesos compartidos, agrupación y el uso de muchas capas. 
 
1.1.1.2.1.1.  Inception_V3 
Inception V3 creada por Google es la tercera versión en una serie de arquitecturas para redes 
neuronales convolucionales. La red neuronal esta entrenada en usar una colección de 1000 
clases que originalmente contiene un millón de instancias para entrenar, la versión de 
TensorFlow contiene 1001 clases, la cual contiene una clase adicional que no incluye el 
entrenamiento por ImageNet. Derivado a su gran entrenamiento Inception V3 mantiene el 
conocimiento de aprendizaje incluso para aprender nuevas clases y aplicar en nuevos 
pequeños conjuntos de datos, como resultado mantiene una alta clasificación sin necesidad 
de un extenso entrenamiento y poder computacional.  
 
2 
 
1.1.1.2.1.2.  AlexNet 
AlexNet es el nombre de una red convolucional, diseñada por Alex Krizhevsky. La red logra 
el top-5 de error de 15.3%, más de 10.8 de porcentaje en puntaje menor que los demás. 
Además, es factible la utilización de unidades de procesamiento gráfico durante el 
entrenamiento. 
 
1.1.2. User Interface Design Pattern, Patrones de Diseño de Interfaz de Usuario 
(UIDPs) 
Los UIDPs son una solución recurrente que resuelve problemas comunes de diseño, como 
son: las resoluciones de diferentes dispositivos, el diseño responsivo o problemas de 
navegación; todas estas soluciones se plantean a través de un lenguaje común para los 
diseñadores. [4]. 
 
1.1.2.1. Composición de Interfaces de Usuarios 
La composición de interfaces de usuario es el conjunto de interfaces de usuario que permiten 
englobar y enlazar los UIDPs que involucra una rápida respuesta para la creación final de 
una aplicación sobre un proyecto en general. 
 
1.1.3. Aplicaciones de Social Media 
Los Social Media o Medios Sociales permiten la creación e intercambio de contenido 
generado por el usuario y el diseño de una gama de aplicaciones basadas en Internet [5]. 
Ejemplos: Facebook®, Twitter®, entre otras. 
 
1.1.3.1.Tipos de aplicación 
Para el dominio de Social Media se especifican algunos tipos de aplicaciones como: 
• Redes Sociales: se basan en la forma de compartir la información y, además permiten 
compartir imágenes, videos, entre otras actividades multimedia, un ejemplo de ello 
es Facebook®. 
3 
 
• Microblogging: se basa en enviar y publicar información reducida un ejemplo claro 
es Twitter®. 
• Streaming: basadas en el envío de información de audio o video en fragmentos y este 
se reproduce al momento, un ejemplo claro es Spotify®. 
1.1.4. Aplicaciones de Comercio Electrónico 
Las aplicaciones de e-Commerce (Eletronic Commerce, Comercio Electrónico) son 
soluciones de comercio electrónico o comercio por Internet, las cuales son seguras y permiten 
satisfacer las necesidades de los clientes y empresas. Permiten interactuar con los clientes a 
través de productos y ofertas personalizados, procesar información de forma rápida y segura. 
Para enfocarse en el cumplimiento y en dar servicio al cliente se dan soluciones por medio 
de redes sociales o páginas Web [6]. 
 
1.1.4.1. Tipos de aplicación 
Para el dominio de e-Commerce se especifican algunos tipos de aplicaciones como: 
• B2C (Bussiness to Consumer, Negocio a Consumidor): donde las aplicaciones se 
basan en servicios y productos para el cliente final, un ejemplo claro son la venta de 
los productos por medio de una página de internet como Dell® o Asus®.  
• C2C (Consumer to Consumer, Consumidor a Consumidor): se basa en aplicaciones 
para dirigidas para que un cliente final se vincule con otro cliente final, algunos 
ejemplos específicos son Amazon® o Ebay®.  
 
1.1.6. APIs de aprendizaje profundo 
A continuación, se explican algunas APIs (Application Programming Interface, interfaz de 
programación de aplicaciones) que soportan algoritmos de aprendizaje profundo, el uso de 
bibliotecas o lenguajes de programación que se utilizan para las diferentes herramientas de 
desarrollo. 
 
4 
 
1.1.6.1. TensorFlow 
Es una biblioteca de código abierto para el cálculo numérico y utilizar gráficos de flujo de 
datos. Desarrollado por Google en la organización de Inteligencia Artificial para el uso del 
aprendizaje automático y la investigación de redes neuronales profundas, pero se usa de 
forma general permitiendo una gran variedad de dominios [7].  
TensorFlow es multiplataforma por lo que permite su aplicación en diferentes sistemas GPU 
(Graphics Processing Unit, Unidad de Procesamiento gráfico) y CPUs (Central Processing 
Unit, Unidad Central de Procesamiento). Distribuye la ejecución de motores abstractos que 
soporta muchos dispositivos y provee un alto rendimiento en el núcleo del lenguaje en C++. 
Además, es compatible con el lenguaje Python. Las capas de la API proveen una interfaz 
simple para el uso cómodo de modelos de aprendizaje profundo.  
TensorFlow es capaz de construir un gráfico computacional. El gráfico es una estructura de 
datos que describe completamente el cálculo que se desea realizar, permite muchas ventajas 
como: portabilidad de ejecutar en cualquier momento, es optimizable para diferentes 
versiones y soporte para la distribución ejecutable. 
Algunos modelos son: 
• The Object Detection API: modelo con un núcleo de aprendizaje automático con el 
reto de crear modelos de aprendizaje automático compatibles para localizar e 
identificar múltiples objetos una sola imagen. 
• Tf-seq2seq: un framework de Google® que anunció Google Neural Machine 
Translation, un modelo que permite la traducción de secuencia por secuencia y lograr 
resultados de última generación.  
• ParseySaurus: son un conjunto de pre-entrenamientos, los cuales son nuevos 
modelos de uso de base de caracteres que se ingresan y predicen el resultado de 
nuevas palabras a base de deletreo usados en contexto. 
• Multistyle Pastiche Generator: este modelo amplía la transferencia de imagen al 
crear una red única que realiza más de una imagen al mismo tiempo. 
 
5 
 
1.1.6.2. Keras  
Keras es una API para redes neuronales de alto nivel, escrito en Python y optimizado para correr con 
Tensorflow, CNTK o Theano, desarrollada con un control para establecer una rápida 
experimentación. Keras permite conservar el menor tiempo posible para un resultado sin retraso que 
es la clave para una buena investigación. Algunas características de Keras son las siguientes: 
• Optimizado para CPU y GPU 
• Permite un prototipo fácil y rápido, ya que es amigable, modulable y es extensible 
• Soporta redes convolucionales y redes recurrentes, incluso combinaciones.  
6 
 
En la tabla 1.1 se analizan algunas APIs identificadas por plataforma, lenguaje, tipo de biblioteca de GPU, código abierto y si maneja 
redes convolucionales.  
Tabla 1.1 Características de las APIs 
API Plataforma Lenguaje Biblioteca Código Desarrollado Compañías que Redes 
GPU Abierto por la usan Convolucionales 
TensorFlow Windows® Python C++  CUDA Sí Google® Google® Sí 
Linux® Java  Ebay® 
macOS®  Intel® 
iOS® DropBox® 
Android® SAP® 
Uber® 
Twitter® 
IBM® 
NVIDIA® 
Keras Windows® Python CUDA, Sí Open-ended Google ® Sí 
Linux® OPENCL Neuro-  
® Electronic macOS   
Intelligent 
Robot 
Operating 
System 
 
7 
 
1.1.7. Lenguaje de programación con soporte para Deep Learning 
A continuación, se explica el lenguaje de programación principal que soporta el desarrollo 
de las técnicas Deep Learning. 
 
1.1.7.1. Python 
Python es un intérprete, orientado a objetos y un lenguaje de programación de alto nivel con 
semántica dinámica. Construido con una estructura de alto nivel, en combinar un tipado 
dinámico y un enlace dinámico, crear un atractivo desarrollo rápido de aplicaciones. Se usa 
comúnmente un script o conexión de diálogo para conectar componentes ya existentes. 
Python es simple, su sintaxis es fácil de aprender, enfatiza legibilidad y por lo tanto reduce 
el costo de mantenimiento. Soporta además módulos y paquetes, con modularidad de 
programas y reutilización de código. Contiene disponibilidad de una gran cantidad de 
bibliotecas y su código es abierto para su libre distribución [11]. Contiene extensiones como: 
py, pyc, pyd, pyo y pyw. 
 
1.1.8. IDEs 
Los IDEs (Integrated Development Environment, Entorno de Desarrollo Integrado) son 
editores de código fuente y proporcionan un servicio integral para facilitar el desarrollo de 
software al desarrollador o programador. A continuación, se explica el IDE principal que 
soporta el desarrollo del proyecto de investigación aquí descrito. 
 
1.1.7.1. Spyder 
Spyder es un IDE de código abierto para programación científica en el lenguaje Python. 
Integra un número de paquetes prominentes del repositorio de Python, incluye NumpPy, 
Scipy, Matplotlib, pandas, IPython, entre otros; contiene la licencia MIT. Pierre RayBaut 
creó Spyder en 2009, desde el 2012 es mantenido por la comunidad de Python y por 
desarrolladores científicos. Está disponible para la plataforma Anaconda, a través de 
Windows ®, macOS ® y Linux ®. Contiene además controladores de Primeros y Terceros con 
8 
 
soporte de inspección de datos y una cantidad de instrumentos introspectivos tales como 
Pyflakes y Rope 
 
1.1.9. Servidor de aplicaciones Web 
A continuación, se explica el servidor de aplicaciones Web principal. 
 
1.1.9.1. Apache HTTPS Server 
Apache es el software para servidor Web más utilizado, desarrollado y con soporte por 
Apache Software Foundation, creado dentro del proyecto HTTP Server (httpd). Apache es 
un software de código abierto disponible de forma gratuita. Funciona en el 67% de todos los 
servidores web del mundo. Es rápido, confiable y seguro, es altamente personalizado para 
satisfacer las necesidades de muchos entornos diferentes mediante el uso de extensiones y 
módulos. La mayoría de los proveedores de alojamiento de WordPress usan Apache como 
su software de servidor web [18].  
 
1.1.10. Metodología para el desarrollo de software  
A continuación, se explica la metodología para el desarrollo del proyecto.  
 
1.1.9.1. Prototipado 
Esta metodología de desarrollo de software que permite obtener una versión preliminar del 
software con el fin de demostración o evaluación. Desde esta perspectiva, para los clientes y 
usuarios, el obtener una implementación parcial del sistema da la posibilidad de experimentar 
y retroalimentar con su opinión las ventajas y desventajas del sistema, se realiza una 
documentación para una posterior revisión y se pone en marcha el desarrollo de una nueva 
versión que se acerca más a la versión final. De tal manera que un prototipo desarrollado de 
forma rápida para su ejecución [21]. Algunas características de esta metodología son las 
siguientes.  
• Método informal para el desarrollo. 
• El Prototipo alcanza el producto final. 
9 
 
Las fases del prototipado son las siguientes: 
• Investigación preliminar: Define los problemas, cuenta con el análisis y 
especificaciones, diseño y construcción, evaluación y modificación. 
• Diseño técnico: Documentación y diseño detallado. 
• Programación y prueba. Se encarga de ver las especificaciones del diseño de prueba 
e implementación. 
• Operación y mantenimiento: Etapa de instalación y modificaciones posteriores  
 
 
1.2. Planteamiento del Problema 
El uso continuo y creciente de las e-Commerce tales como Amazon®, ebay®, Blue Nile®, 
Costco®, Mercado Libre® y las Social media como Facebook®, Twitter®, Linkedin®, 
Google+®, Instagram®, Flickr™ YouTube®, entre otras, se demuestra que los usuarios se 
adaptaron al uso de estos tipos de aplicaciones, por lo que este incremento de usuarios, busca 
nuevas fuentes para comunicarse o nuevas formas de compartir información. Por otra parte, 
en la ingeniería de software, de manera específica en el desarrollo de software, la búsqueda 
de la reducción del tiempo de desarrollo y además el costo que este involucre, es un reto cada 
vez mayor, se mejora cuando se involucran nuevas técnicas y tecnologías que van más allá 
del desarrollo tecnológico. De modo que, en esta propuesta se plantea generar de forma 
automática código fuente de interfaces de usuarios multidispositivo, a partir de una imagen 
digital que represente una interfaz de usuario (previamente delimitada), para lo cual se 
identifican composiciones de UIDPs a través de técnicas de aprendizaje profundo. En este 
sentido, el aprendizaje profundo permite un conjunto de modelos computacionales que imitan 
el funcionamiento del sistema nervioso humano, los modelos computacionales están 
compuestos de múltiples capas de procesamiento para aprender representaciones de datos 
con múltiples niveles de abstracción. El uso de métodos de aprendizaje profundo tiene 
diversas contribuciones en áreas de procesamiento de imágenes, reconocimiento de voz, 
audio, video y de manera general en sistemas de aprendizaje automático. Por otra parte, el 
uso de UIDPs para el desarrollo de interfaces de usuario garantiza una solución a los 
principales problemas de diseño como las restricciones del tamaño de pantalla para desplegar 
10 
 
el contenido o una navegación adecuada, además de garantizar una adecuada interacción con 
el usuario. En este mismo sentido, la composición de patrones se refiere a un patrón de diseño 
que se combine con otro o en su defecto se acompañe de uno o más patrones de diseño.        
 
1.3. Objetivo General 
Desarrollar un componente de software que permita la generación automática de interfaces 
de usuario a través de imágenes con composición de UIDPs y técnicas de aprendizaje 
profundo. 
 
1.3.1. Objetivos Específicos   
 
1. Estudiar y analizar los diferentes algoritmos de Deep Learning reportados en la 
literatura. 
2. Analizar e identificar los UIDPs válidos para la composición en interfaces de 
aplicaciones de e-Commerce y Social media.  
3. Seleccionar los algoritmos adecuados para el reconocimiento de UIDPs 
compuestos en imágenes generadas a mano alzada. 
4. Diseñar el conjunto de prestaciones o servicios para la implementación de los 
algoritmos basados en técnicas de Deep Learning aplicados para el 
reconocimiento de UIDPs compuestos. 
5. Desarrollar un módulo de generación de interfaces de usuario para los dominios 
e-Commerce y Social media basada en técnicas Deep Learning. 
6. Evaluar el módulo desarrollado a través de diferentes casos de estudio como 
prueba de concepto.  
 
1.4. Justificación  
Debido al impacto del crecimiento de las redes sociales y las tiendas en línea a nivel mundial, 
en especial las e-Commerce y Social Media, ha provocado que en la ingeniería de software y 
de manera específica en el desarrollo de software se busquen nuevas formas de disminuir 
11 
 
costos y mejorar los tiempos de desarrollo, tanto para el usuario final como para los 
desarrolladores. Partiendo de lo anterior, en esta investigación se plantea usar técnicas de 
Deep Learning para identificar UIDPs en una imagen que represente una interfaz de usuario 
y generar código fuente de aplicaciones e-Commerce y Social Media. El Deep Learning 
representa una solución para realizar una tarea específica y detectar diferentes tipos de la 
visión para un campo especial para detección de imágenes en mejorar considerablemente su 
calidad y desempeño. 
Dicho lo anterior, los principales pilares en esta investigación se resumen en tres: el primer 
pilar de la investigación, es el uso de los generadores para desarrollar software para usar una 
imagen o un boceto generado a mano alzada, el segundo pilar es el desarrollo de software 
con las técnicas Deep Learning, que mejora considerablemente el desarrollo de software por 
el aprendizaje que conlleva, finalmente, el tercer pilar donde los UIDPs son parte 
fundamental ya que permiten solventar ciertos errores de diseño en una aplicación. 
La investigación plantea una novedosa alternativa para la generación automática de código a 
través de imágenes o bocetos que permitan seleccionar el mejor algoritmo de Deep Learning 
para la identificación de elementos de una interfaz de usuario para aplicaciones de los 
dominios e-Commerce y Social Media. Las nuevas interfaces generadas se adaptan a las 
necesidades de más de un dispositivo sin perder calidad y por ende los usuarios mantengan 
una adecuada interacción. El generar código fuente por medio de las técnicas de Deep 
Learning, mediante interfaces de usuario a partir de una imagen digital proveniente de una 
cámara o escáner, proporciona a la ingeniería de software una alternativa más para 
automatizar el desarrollo de software. 
  
12 
 
Capítulo 2 Estado de la Práctica 
A continuación, para este capítulo se aborda a detalle los temas de generación de 
aplicaciones, la interfaz de usuario y el aprendizaje profundo. En la siguiente revisión se 
detalla una breve reseña de cada uno de los trabajos revisados, se presenta una tabla 
comparativa que permite identificar las principales características que son objeto de estudio 
en esta investigación. Finalmente, se presenta la conclusión resultado del análisis 
comparativo de los trabajos estudiados.  
 
2.1. Trabajos relacionados 
En esta sección se clasificó en dos partes los trabajos relacionados, por el trabajo previo para 
la generación de aplicaciones o desarrollo de software y técnicas de Deep Learning en el 
desarrollo de software. 
 
2.1.1. Herramientas para la generación de aplicaciones o desarrollo de software  
Cabe mencionar que las herramientas para la generación de aplicaciones son indispensables 
por lo que en la literatura se reportan diferentes estudios como en Rosales-Morales et al. [24], 
donde analizó las herramientas para el desarrollo automático de software y la generación 
automática de código fuente, con el fin de evaluar y determinar si cumple o no con un 
conjunto de características y funcionalidades en términos de calidad. Dichas características 
incluyen eficacia, productividad, seguridad y satisfacción, todo a través de una evaluación 
cualitativa y cuantitativa. Estas herramientas son 1) herramientas CASE, 2) frameworks y 3) 
los Ambientes de Desarrollo Integrado. La evaluación se llevó acabo con el fin de medir no 
sólo la capacidad de uso, sino también el apoyo que brindan para el desarrollo de software 
automático y la generación automática de código fuente. Por último, los resultados 
concluyeron que Visual Paradigm es una de las mejores herramientas que contiene un buen 
diseño GUI (Graphical User Interface, Interfaz Gráfica de Usuario), una herramienta de 
usabilidad, que promueve el uso de características, cuenta con soporte para integración 
heterogénea de fuente de datos, y además tiene soporte y documentación. 
 
13 
 
Cortes-Camarillo et al. [25], realizó un análisis comparativo de patrones de diseño de interfaz 
de usuario (ya que facilitan el desarrollo de aplicaciones, ya que cada plataforma tiene su 
propia interacción entre el usuario y el dispositivo) basado en contextos de uso orientado al 
ámbito educativo. Se diseñó un conjunto de contextos de uso para establecer que patrones de 
diseño de interfaz de usuario son recomendables para un dispositivo en específico, facilitar 
el desarrollo de aplicaciones educativas multi-dispositivo. Por lo tanto, se propuso un diseño 
de interfaz de usuario de una aplicación educativa para el aprendizaje electrónico para utilizar 
un MOOC (Massive Online Open Courses, Curso en Línea Masivo y Abierto). Se aplicó el 
contexto de uso que se estableció y se seleccionó en los patrones de interfaz de usuario para 
la plataforma de dispositivo móvil. Posteriormente a partir de un bosquejo se procedió a 
construir la interfaz gráfica de usuario. Por lo tanto, el bosquejo facilitó el desarrollo de una 
aplicación educativa gracias a los beneficios que ofrecen los patrones de diseño de interfaz 
de usuario por los contextos de uso.  
 
En otra investigación, Cortes-Camarillo et al. [26] planteó el diseño de una arquitectura para 
el desarrollo de aplicaciones educativas que se basa en un conjunto de UIDPs (User Interface 
Design Pattern, Patrones de Diseño de Interfaz de Usuario) para facilitar el desarrollo de 
aplicaciones laboriosos y tareas de consumo-tiempo. Como prueba de concepto se propusó 
EduGene, un generador de aplicaciones compatible con cuatro sistemas operativos, 
AndroidTM, FirefoxTM OS, macOS y WindowsTM Phone, incluyendo Web. EduGene además 
es compatible con tres tipos de dispositivos: móviles (teléfonos inteligentes y tabletas), 
escritorio y televisión. Los resultados de evaluación demuestran que EduGene es un 
generador de aplicaciones educativo amigable, ya que provee una interfaz intuitiva que 
facilita la interacción del usuario, en lograr un alto puntaje en el diseño, con un contenido de 
la presentación y es fácil de usar. Además, logra metas educativas tales como el incremento 
del acceso de la información y motivar al estudiante y profesor. Las Herramientas e-learning 
seleccionadas para comparar el desempeño de Edugene fueron Moodel, Sakai y ATutor. Las 
contribuciones son: 1) el diseño en capa para los generadores de aplicaciones educativas 
basados en los UIDPs, 2) una representación lógica y estructurada de una aplicación 
14 
 
educativa a través de un documento XML y 3) el uso de los UIDPs para generar aplicaciones 
educativas. 
 
Adicionalmente, Cortes-Camarillo et al. [27] presentó Atila, un generador de aplicación 
educativo basado en UIDPs (User Interface Design Pattern, Patrones de Diseño de Interfaz 
de Usuario). La aplicación desarrollada soporta cuatro sistemas operativos: AndroidTM, 
FireFoxTM OS, macOSTM, WindowsTM Phone y Web. Ya que los UIDPs facilitan la 
interacción entre la aplicación y el usuario, además provee la oportunidad de generar software 
de alta calidad.  Como resultados se propuso generar una aplicación para las plataformas 
macOSTM y WindowsTM Phone, primero se necesita activar y desactivar las características 
requeridas para la aplicación a desarrollar. Segundo, se hace una selección de las opciones 
en la herramienta y se genera un archivo XML. Tercero se descarga el proyecto generado. 
Para generar la aplicación, solamente se necesita indicar el nombre de la UIDP y su posición 
en la aplicación. Atila permite al usuario modificar libremente la aplicación del diseño de 
interfaz de usuario. Otro de los beneficios es la velocidad y la facilidad para desarrollar 
aplicaciones educativas para dispositivos móviles a través del uso de UIDPs. 
 
Sánchez-Morales et al. [28] presentaron un componente de software para generar interfaces 
de usuario para aplicaciones móviles en usar el reconocimiento de patrones, procesamiento 
de imagen, y técnicas de redes neuronales. El proceso de generación de interfaces de usuario 
consiste en tres fases: 1) análisis de la imagen, 2) configuración y 3) generación de código 
fuente. Partiendo de esto, novedosos y nuevos enfoques para procesos de desarrollo para 
aplicaciones móviles requeridos de modo que las técnicas de inteligencia artificiales aplican 
el propósito de agilizar, facilitar e interactuar desarrollos a través de métodos 
computacionales que involucren redes neuronales, procesamiento de imagen digital, y 
técnicas de reconocimiento de patrones. Como resultado se presentó la prueba del módulo 
mediante una imagen a mano alzada que representa una interfaz de usuario para transformar 
al código fuente de una aplicación móvil. El porcentaje de eficiencia en reconocimiento de 
elementos de la interfaz usada para el caso de estudio fue de 94.3% Por lo tanto, la 
15 
 
identificación elementos de interfaz de usuario en una imagen generada a mano alzada a 
través de redes neuronales es totalmente posible. 
 
Da-Costa et al. [29] aplicó un reciente MDD (Model-Driven Development, el Desarrollo 
Dirigida por Modelos), que es un paradigma para brindar el reúso y ocupar las brechas de 
productividad, por medio de modelos abstractos y la generación automática de software a 
través de transformaciones de modelos para avanzar en la investigación de la UI (User 
Interface, Interfaz de usuario), dicho lo anterior, se propuso el estereotipo UI para la 
ingeniería UI en el dominio de sistema Web. El estereotipo de la UI captura los siguientes 
puntos: 1) las especificaciones de la UI, 2) el modelado recurrente de la presentación de la 
UI y 3) el comportamiento de las interacciones y tareas del usuario. Se aplica este concepto 
para describir un estereotipo de un portal web de la UI como un patrón de interacción 
recurrente que permite la generación automática de muchos componentes basados en 
prácticas impulsadas por el modelo para portales Web de la UI. Este enfoque de generar la 
UI es compatible con recientes avances en la construcción de la UI, tales como la interacción 
IFML (Interaction Flow Modeling Language, Lenguaje de Modelado de Flujo de 
Interacción), es un reciente modelo de la UI estandarizado por la OMG. Los resultados 
obtenidos de los portales web de la UI reducen el desarrollo de software time-to-market, 
esfuerzo y costo, contribuyendo ambos en la calidad y en el mejorar la mantenibilidad de las 
aplicaciones Web. 
 
Sánchez-Morales et al. [30], propuso el desarrollo de un componente de software que utiliza 
técnicas de procesamiento de imágenes y reconocimiento de patrones para la generación 
automática de aplicaciones multi-dispositivo. Ya que existen diferentes esquemas de 
generación automática de software como son MDA (Model Driven Architecture, 
Arquitectura Dirigida por Modelos), FDD (Feature-driven Development, Desarrollo basado 
en funcionalidades) y RAD (Rapid Application Development, Desarrollo rápido de 
aplicaciones). Sin embargo, hasta el momento no se aborda la generación de software 
mediante técnicas de inteligencia artificial y reconocimiento de patrones. Por lo tanto, para 
lograr ese objetivo se propuso identificar elementos de una imagen y generar el código de 
16 
 
una aplicación multi-dispositivo con los elementos detectados previamente seleccionados en 
dicha imagen. Como resultado se planteó un caso de estudio como prueba de concepto del 
módulo, se representó la generación de código de la portada principal de una página Web a 
partir de la presentación de la interfaz en una imagen. Los autores concluyeron que la 
aplicación de un componente de software facilita la tarea de crear prototipos de aplicaciones 
para presentarlas al usuario antes de iniciar un desarrollo, permitiendo ahorrar tiempo y 
dinero. 
 
2.1.2. Técnicas Deep Learning en el desarrollo de software 
Dentro del desarrollo del software el uso de técnicas de Deep Learning son importantes y 
tienen diversas aplicaciones. A. Halbe y Dr. A. R. Joshi [31] sugirieron un enfoque novedoso 
para crear automáticamente páginas HTML (HyperText Markup Language, Lenguaje de 
Marcas de Hipertexto) por medio de un diseño GUI (Graphical User Interface, Interfaz 
Gráfica de Usuario) dibujado sobre el papel considerado como un diseño GUI, ya que 
contiene varios controles HTML tales como radio button, checkbox, textbox, command 
button y label. Al escanear una imagen de un diseño GUI esta se ingresa al sistema, el sistema 
segmenta la imagen en varios controles y el segmento de control HTML es identificado. Una 
vez identificado los controles estos se almacenan en una base datos en XML. El XML 
contiene el nombre y la posición del componente sobre el diseño de la GUI, y este archivo 
XML es analizado para generar una página HTML. En conclusión, los resultados obtenidos 
de un caso de estudio recopilan datos empíricos, para ello se procesan y escanean 30 diseños 
GUI dibujados a mano en diferentes técnicas propuestas. Por último, se concluye que los 
diseños GUI permite ser convertidos a páginas funcionales HTML con bastante exactitud. 
 
En Baveye et al. [32] se presentó un modelo refinado computacional de aprendizaje profundo 
para la predicción de la memorabilidad de la imagen, el desempeño de este modelo es 
superior significativamente y obtiene relativamente un 32.78% de incremento en 
comparación a los modelos mencionados en el estado del arte sobre el mismo conjunto de 
datos. Además, se investigó el modelo que generalizó un nuevo conjunto de datos de 150 
imágenes, para cada memorabilidad y la investigación del puntaje efectivo que recolectaron 
17 
 
más de 50 participantes. Dicho lo anterior el rendimiento de la predicción fue más débil sobre 
este nuevo conjunto, destaca el problema de la representatividad en los conjuntos de datos. 
En particular, el modelo obtuvo un gran desempeño de predicción para imágenes negativas 
activas que las imágenes neutras o imágenes positivas activas, el recodar qué tan importante 
es el conjunto de memorabilidad en la consistencia de imágenes que estén adecuadamente 
distribuidas dentro del espacio emocional. Los resultados sugirieron que al tomar en cuenta 
el efecto en el conjunto de datos de imágenes etiquetadas como las puntuaciones de 
memorabilidad para asegurarse que se induce una gran variedad de emociones, de hecho, la 
información emocional y la memorabilidad se encuentran relacionadas, el desempeño de un 
modelo de memorabilidad depende de la información emocional inducida por las imágenes 
utilizadas para entrenar el modelo. También se sugirió que la información emocional, es una 
valiosa cualidad para aumentar el rendimiento del modelo para imágenes neutrales y 
positivas, ya que infiere computacionalmente la información emocional. 
 
Por otra parte, en Bianco et al. [33] se planteó un método para el reconocimiento de logos en 
imágenes o videos para aplicar el aprendizaje profundo. El reconocimiento está compuesto 
por una región localizada del logo seguido por una CNN (Convolutional Neural Network, 
Red Neuronal Convolucional) específicamente entrenada para la clasificación del logo, 
incluso si no están localizados con precisión. Los experimentos del método ocuparon la base 
de datos FlickrLogos-32, y se evaluaron los efectos del desempeño del reconocimiento del 
aumento de datos sintéticos contra los datos reales y el pre-procesamiento de imagen. 
Además, se investigaron los beneficios y las diferentes elecciones de los entrenamientos, 
como son: las clases balanceadas, ponderación de la muestra y modelado explícito de la clase 
de fondo (la región que no contiene logo). En conclusión, los resultados del experimento 
confirmaron la factibilidad del método propuesto que mejora los métodos presentados en el 
estado del arte. Otro punto a comentar, es que el reconocimiento del logo es fundamental en 
muchos dominios de aplicación, el problema recurrente es que el logo sobre la imagen tiende 
a aparecer en diferentes posiciones y escalas o sobre cualquier otro lugar de la vista de la 
imagen. Incluso al reconocer el logo sobre las imágenes susceptibles a ser corrompidas por 
diferentes mecanismos de la imagen y distorsiones. 
18 
 
 
Por su parte, Liu et al. [34] presentó una revisión sistemática de la literatura de fusión de 
imágenes a nivel de pixel basada en el aprendizaje profundo. Específicamente, se detallaron 
las principales dificultades que existen en la investigación de fusión de imágenes 
convencionales y se discutieron las ventajas que el aprendizaje profundo ofrece para 
direccionar cada uno de estos problemas. De tal modo que, los recientes logros de la fusión 
de imágenes basado en el aprendizaje profundo es revisado a detalle. Actualmente, más de 
una docena de métodos propuestos de fusión de imágenes basadas y analizadas en técnicas 
de aprendizaje profundo incluyendo las CNN (Convolutional Neural Networks, Red 
Neuronal Convolucional), CSR (Convolutional Sparse Representation, Representación 
dispersa Convolucional) y SAE (Stacked Autoencoders, Codificadores Automáticos 
Apilados). Por último, los existentes métodos de fusión de imágenes basados en aprendizaje 
profundo en varios framewoks genéricos y en presentación de un potencial framework basado 
en aprendizaje profundo para desarrollar métricas de evaluación objetivas. Las 
contribuciones desarrolladas son las siguientes: 1) las pertinentes dificultades se resumen 
dentro de cuatro puntos específicos en términos de métodos de fusión y métricas de 
evaluación objetiva; 2) se presentan las ideas básicas, los pasos principales, las aplicaciones 
específicas y las características principales de los métodos; 3) los principales problemas y 
retos que existen en cada framework se discuten.  
 
En Pang et al. [35] se expuso un nuevo enfoque para hacer frente a tareas de seguimiento de 
objetivos visuales. El método usa una red neuronal convolucional que permite clasificar una 
serie de parches dependiendo de qué tan bien se encuentra centrado. Para cubrir las posibles 
interferencias se pretende entrenar la red con parches ubicados sobre el entorno detectado del 
objeto centrado, y con diferentes tamaños, así toma en cuenta cambios eventuales de escala. 
Por otro lado, al entrenar la red, se crean un conjunto de datos ad-hoc con ejemplos positivos 
y negativos para la extracción del objeto centrado desde la base de datos de detección de 
Imagenet. Los ejemplos positivos son aquellos que tienen el objeto centrado correctamente, 
mientras que los negativos son aquellos que están centrados incorrectamente. Finalmente, se 
seleccionan los parches más prometedores, al usar la función de emparejamiento basado en 
19 
 
las características de profundidad que es proveída por la red AlexNet. Por lo tanto, es rápido 
y útil para el seguimiento visual en tiempo real. Los resultados muestran que los métodos son 
muy competitivos con respectos a los algoritmos descritos en el estado del arte, siendo muy 
robustos contra interferencias típicas durante el proceso de seguimiento de objetivos visuales. 
 
Krishevsky et al. [36] entrenaron una gran red neuronal convolucional para clasificar 1.2 
millones de imágenes de alta resolución en ImageNet LSVRC-2010 en contienda de 1000 
diferentes clases. Sobre los datos de prueba, se archivaron las tazas de error de top-1 y top-5 
de 37.5% y 17.0% que es considerablemente muy bueno en lo mencionado en el estado del 
arte. La red neuronal, cuyos parámetros son de 60 millones y 650,000 neuronas, consiste de 
5 capas convolucionales, algunos de los cuales están compuestos por capas max-pooling y 
tres capas totalmente conectadas con una 1000-way softmax. Además, para entrenar con 
rapidez, se usaron neuronas no saturadas y un eficiente GPU para la operación de 
convolución. Para reducir el sobreajuste en las capas totalmente conectadas se empleó un 
método llamado “dropout” que es muy efectivo. Asimismo, se ingresó una variante de la 
competencia ILSVRC-2012 obteniendo una tasa de error de prueba entre los top-5 con 15.3% 
en comparación con los 26.2% de resultado dado por la segunda revisión del entrenamiento. 
Como conclusión se demuestra que una gran profunda red neuronal convolucional es capaz 
de lograr resultados récord para un conjunto de datos altamente desafiantes en utilizar 
puramente el aprendizaje supervisado. 
 
Huang et al. [37] desarrollaron técnicas de recuperación de imagen para imágenes de base de 
datos Web de gran escala. Dicho lo anterior, es un avanzado sistema de recuperación, 
denominado MRBDL (Multi-concept Retrieval using Bimodal Deep Learning, Multi-
concepto de Recuperación al usar Aprendizaje Profundo Bimodal) es propuesto e 
implementado el uso de las redes neuronales convolucionales, que efectivamente guardan 
correlaciones semánticas entre imágenes visuales y etiquetas de contextos libres. La cual 
difiere de los enfoques existentes que utilizan conceptos múltiples e independientes en una 
consulta. MRBDL considera múltiples conceptos como una escena holística para el 
aprendizaje modelo de recuperación. Particularmente, se usa en una red neuronal 
20 
 
convolucional bimodal para entrenar una escena de clasificación holística en dos 
modalidades, y entonces una correlación semántica de inclusión de sub-conceptos en las 
imágenes que  fuerzan el impulso del reconocimiento de la escena holística. El récord de 
predicción semántica obtenido desde la clasificación de la escena holística combinada con 
información complementaria de imágenes Web para mejorar el desempeño de recuperación. 
Los resultados detallaron que el enfoque propuesto mejora favorablemente a comparación 
con diferentes métodos del estado del arte. 
 
Nedzved et al. [38] proponen un esquema para desarrollar procesamiento de imágenes y el 
análisis de software basado en la generación de tablas de tesauros en la interpretación del 
núcleo. El esquema está basado en la combinación de características de bibliotecas dinámicas 
y de un intérprete con un conjunto de funciones para el procesamiento de imagen. Como 
resultado, el programa se divide en dos partes: el primero apunta a un desarrollo de software 
profesional y el segundo a usuarios. Por último, se propone un procesamiento histológico de 
imágenes por especie donde la tecnología de desarrollo de software basado en generación 
automática de letras, incluye un conjunto de funciones de procesamiento de imágenes simples 
para diferentes problemas de análisis de tejido histológico. El propósito de la arquitectura del 
software facilita el desarrollo de programas para análisis de imagen medico en particular, 
análisis histológicos. 
 
2.2.Análisis comparativo 
En la siguiente tabla, el análisis se realizó al considerar los siguientes aspectos: dominio, 
generación de código, el soporte de UIDPs, multidispositivo y el uso del Deep Learning. El 
aspecto de dominio se encuentra enfocada al ámbito de aplicación del artículo, la generación 
de código fuente se refiere a si dentro del trabajo se soporta la generación de código fuente, 
la característica de soporte de UIDPs hace referencia al uso de los patrones de diseño, 
respecto a la característica multidispositivo, se refiere a si en el trabajo se toma en cuenta la 
compatibilidad de diferentes dispositivos. Finalmente, el uso del Deep Learning se refiere a 
la aplicación de alguna de estas técnicas conocidas. 
21 
 
Tabla 2.1 Análisis comparativo del estado del arte 
Autor Dominio Generación de Soporta Multidispositivo Uso del Deep  
Código Fuente UIDPs Learning 
Rosales-Morales et al., Ingeniería de Sí No Sí No 
2015 [24] Software  
Cortes-Camarillo et al., UIDPs No Sí Sí No 
2016 [25] 
Cortes-Camarillo et al., UIDPs Sí Sí Sí No 
2018 [26] 
Cortes-Camarillo et al., Ingeniería de Sí Sí Sí No 
2017 [27] Software 
Sánchez-Morales et al., UIDPs Sí Sí Sí No 
2017 [28] 
Larissa-da-Costa et al., Ingeniería de Sí No Sí No 
2014 [29] Software 
Sánchez-Morales et al., Multidispositivo Si No Sí No 
2015 [30] 
Halbe& Joshi, 2015 [31] Procesamiento Sí No Sí No 
de imágenes 
para GUI, IA 
Baveye et al., 2015 [32] I.A. No No Sí Sí 
Bianco et al. 2017 [33] I.A. No No Sí Sí 
Liu et al., 2018 [34] I.A. No No Sí Sí 
Pang et al., 2017 [35] I.A. No No Sí Sí 
Krizhevsky et al., 2012 I.A. No No Sí Sí 
[36] 
H2uang et al., 2017 [37] I.A. No No Sí Sí 
Nedzved et al., 2013 I.A. No No Sí No 
[38] 
22 
 
Como conclusión se observa que los artículos revisados no consideran todas las 
características analizadas al mismo tiempo. Todos los trabajos soportan el desarrollo 
multidispositivo, pero no necesariamente permiten la generación de código fuente, o la 
implementación de UIDPs en el desarrollo de sus interfaces, y además el uso de técnicas de 
Deep Learning como parte de las técnicas en el proceso de desarrollo. Por tal motivo se 
observa la oportunidad de abordar estas técnicas para plantear un proceso de desarrollo de 
software basado en técnicas de Deep Learning, que parta del uso de imágenes generadas a 
mano alzada que representen interfaces de usuario.  
 
2.3. Solución propuesta 
En este punto se presenta la propuesta de solución para el desarrollo de la investigación, el 
valor que representa la solución está sustentado en desarrollo confiable, gratuito y mantiene 
estándares de desarrollo óptimos. En la tabla 2.2 se muestra la propuesta de la solución que 
se seleccionó. 
Tabla 2.2 Análisis de la propuesta de solución 
Propuesta 
 Solución  
Lenguaje de Python 
Programación 
Servidor de Apache 
Aplicaciones HTTP Server 
Metodología para el Prototipado 
desarrollo de software 
Entorno de desarrollo Anaconda, Spyder 
 
De acuerdo a la solución propuesta de la tabla 2.2 y partiendo directamente del uso de 
técnicas de Deep Learning hay información favorable y concentrada para el lenguaje de 
programación en Python, por lo que se toma como primera opción Python como lenguaje de 
programación. Además, se propone un servidor Apache HTTP Server en caso de requerir 
ajustar detalles del servidor. Se integra también la metodología Prototipado cuyas cualidades 
23 
 
son principalmente, mantener calidad, disciplina y retroalimentación continúa durante el 
proyecto. Y por último se encuentra el entorno de desarrollo compuesto por la plataforma de 
Anaconda, que dispone del IDE Spyder, una herramienta muy versátil con características 
especiales a favor de las técnicas y modelos de datos científicos. 
 
2.4. Justificación de la solución propuesta 
La solución propuesta de la tesis considera tecnologías habituales como también las más 
factibles, es necesario comprender que el lenguaje de programación tiene que ser una opción 
que más se adapte a las necesidades de las técnicas y sustente de información a las API de 
Deep Learning. De acuerdo a la propuesta elegida, se justifica la elección de Python, que es 
un lenguaje base para el desarrollo de técnicas y algoritmos de Deep Learning, provee una 
documentación más específica a la hora de programar dicha técnica, su comunidad y la 
facilidad del lenguaje de programación provee un sin fin de oportunidades a desenvolver en 
las técnicas de Deep Learning. Por otro lado, como servidor de aplicaciones se elige Apache, 
porque permite la edición de código fuente, cuenta con la ventaja de permitir el desarrollo de 
su propio núcleo o la ampliación de otras funciones. Apache es portable lo que permite usarlo 
en diferentes sistemas operativos, además el costo que se maneja resulta económico o maneja 
la licencia de software libre, mantiene una amplia contribución y colaboración de usuarios 
con un gran soporte técnico, suma una gran variedad extensiones y con soporte para el 
lenguaje Python. La elección de la metodología prototipado es un punto importante ya que 
como es un proceso iterativo, prototipado ya que no se conocen los objetivos generales y en 
caso no se conoce la eficacia de un algoritmo esto ayudaría en gran parte, ya que una red 
neuronal puede variar por las características de entrenamiento, de cantidad de instancias y  
configuración Como punto final, se aplicó en la plataforma Anaconda el entorno de 
desarrollo de Spyder por dos motivos, tiene una gran variedad de extensiones que proveen 
una compatibilidad con el lenguaje en curso y además se obtiene un repositorio de bibliotecas 
y herramientas para un desarrollo eficiente, tales como: la cobertura de código fuente, análisis 
de código, entre otras. 
  
24 
 
Capítulo 3 Aplicación de la metodología 
A continuación, se presenta una descripción de cómo está conformado el proceso generación, 
revisión de los UIDPs para los dominios e-Commerce y Social Media, al final se presentan 
algunos casos de uso que se implementaron como prueba de concepto del proceso y técnicas 
implementadas.  
 
3.1.Proceso de generación de software 
En esta sección se aborda claramente el proceso de generación automática de aplicaciones 
basado en técnicas de Deep Learning para la identificación de UIDPs que determinan el 
desarrollo de una aplicación para e-Commerce y Social Media. En la figura 1 el proceso 
consta de tres etapas principales: análisis de la imagen, la configuración y posteriormente la 
generación de código. A continuación, se describen cada una de las etapas.  
 
 
 
 
 
 
 
. 
Fig. 3.1 Proceso de generación de software a partir de técnicas Deep Learning. 
 
Análisis de la imagen: esta etapa considera la realización de un análisis de las imágenes que 
soportan los métodos para posteriormente generar el código fuente de aplicaciones de e-
Commerce y Social Media.  
1. Entrada de la imagen a procesar: las imágenes soportadas son interfaces de usuario 
dibujadas a mano alzada y digitalizadas a través de una cámara fotográfica o escáner y 
25 
 
cargadas en memoria. Hasta el momento se soporta solo el formato PNG dado que permite 
una mayor calidad de los datos. Las imágenes tienen dimensiones de 1050x650 pixeles. Es 
importante mencionar que el algoritmo no está limitado a esta única resolución de imágenes, 
es posible adaptar el algoritmo para diferentes resoluciones de forma automática. Sin 
embargo, para fines de pruebas se aplicó una única resolución. 
2. Validación de la imagen de entrada: la validación de la imagen consiste verificar que el 
formato de la imagen sea PNG. Si el formato es correcto, se procede con el paso de 
transformación.  
3. Transformación: Este paso consiste en aplicar un conjunto de algoritmos de procesamiento 
de imágenes con el objetivo de extraer y verificar que al menos un elemento en la imagen de 
entrada representa a un Patrón de Diseño de Interfaz de Usuario. Es importante mencionar 
que la transformación permite mejorar la identificación de elementos en la imagen. Para 
lograrlo, el modelo de la red neuronal convolucional aplica una transformación a la imagen 
que permite eliminar sombras y ruidos de la imagen para que después el modelo clasifique 
los elementos encontrados en la imagen.  
4. Identificación de elementos: a través de los algoritmos de Deep Learning como 
Inception_V3 se obtienen distintos componentes de la imagen. Los componentes son 
representaciones de patrones de diseño de interfaz de usuarios, y además válidos para el 
desarrollo de aplicaciones e-Commerce y Social Media. Los algoritmos de Deep Learning se 
implementan a través de una red neuronal convolucional. El proceso de la red neuronal 
convolucional consiste en tomar un núcleo de la imagen para la siguiente capa y clasificar, 
así consecutivamente hasta la clasificación completa del patrón en la capa de salida. El 
modelo de Inception_v3 es una red neuronal que satisface la clasificación de las imágenes y 
muestra en formato JSON los elementos identificados ordenados por porcentajes desde el 
más alto hasta el más bajo, para este punto se toman los cuatro primeros porcentajes más 
cercanos a cada UIDP. 
Configuración: el objetivo principal de esta etapa es, permitir la configuración del tipo de 
aplicación a generar en este caso, e-Commerce y/o Social Media; después de la identificación 
de los UIDPs en la imagen durante el proceso anterior. Los pasos de este proceso son los 
siguientes. 
26 
 
1. Selección del dominio: la selección del dominio de la aplicación a generar está basado en 
los UIDPs identificados en la etapa anterior, ya que no todos los UIDPs serán válidos para 
los dominios e-Commerce y Social Media. El tipo de aplicaciones e-Commerce soportadas 
son B2C Y C2C mientras que para Social Media se consideran aplicaciones de Microbloggin, 
Streaming, y Redes sociales.  
2. Selección del tipo de aplicación a generar: En este caso, se permite generar aplicaciones 
Web, aplicaciones para dispositivos móviles e inclusive de TV. Esta decisión se toma con la 
finalidad de que la generación de código se realice según las características de cada una de 
estas aplicaciones. Para la selección del tipo de aplicación se toma en cuenta los UIDPs 
identificados, ya que no todos los UIDPs son válidos para cualquier dispositivo y/o 
plataforma.  
3. Configuración de la aplicación: de acuerdo con el dominio y tipo de aplicación 
seleccionada en los pasos previos, se selecciona la configuración general de la aplicación. 
Algunos de los datos de configuración incluyen título principal, una cadena compuesta para 
50 caracteres; lenguaje de desarrollo una cadena de 20 caracteres, los lenguajes soportados 
son para Web con HTML5, Android® con Java y iOS® con Objetive –C. Otro dato de 
configuración es la versión de la aplicación, donde se aceptan solo números, puntos y 
guiones. Finalmente, datos del autor de la aplicación como nombre, apellidos, e-mail, 
empresa y e-mail de la empresa.  
Generación de código: durante esta etapa se realiza la transformación de la información 
recolectada a lo largo del proceso de identificación y configuración necesarios para generar 
el código fuente de las aplicaciones. Este proceso consta de un conjunto de pasos necesarios 
para lograr su objetivo, los pasos se describen a continuación. 
1. Generación de un documento XML: se genera un documento XML que contenga etiquetas 
para almacenar el conjunto de datos obtenidos durante la configuración, dichos datos serán: 
nombre de la aplicación, autor (s), etiquetas con la configuración de acuerdo a cada tipo de 
aplicación y lenguaje seleccionado, resolución, orientación y elementos de plantilla (header, 
body, footer, left y right). Finalmente, un conjunto de etiquetas con la representación de cada 
uno de los elementos identificados en la imagen. 
27 
 
2. Transformación del documento XML a código fuente: la transformación consiste primero 
en procesar el documento XML por medio de un documento XML Schema con el objetivo 
de validar la estructura y garantizar la correcta generación del código fuente de la aplicación. 
Si la estructura es correcta se genera el equivalente en código por plataforma de los UIDPs 
descritos en el documento XML. La estructura generada se agrupa en clases y se almacenan 
en una carpeta por plataforma de acuerdo con el lenguaje de programación seleccionado por 
el usuario. 
3. Archivo ZIP con el código fuente generada: con el código fuente generado se empaquetan 
las carpetas con los proyectos generados por plataforma y se crea un único archivo ZIP, el 
usuario descarga el código fuente que se modifique o adecue conforme a sus requerimientos 
y como mejor le convenga. En este sentido, los proyectos generados tienen la ventaja de 
exportarse a entornos de desarrollo de acuerdo a la plataforma de desarrollo. Los entornos de 
desarrollo válidos para exportar los proyectos son Dreamweaver u otro entorno de desarrollo 
similar en HTML5; para iOS® el entorno de XcodeTM y por último Android StudioTM para 
el proyecto Android. 
 
3.2. Elementos identificados de UIDPs 
En esta sección se identifican y analizan los UIDPs adecuados y válidos para el desarrollo de 
aplicaciones e-Commerce y Social Media. El análisis consistió en seleccionar un conjunto de 
aplicaciones de e-Commerce y Social Media estas aplicaciones elegidas por la mayor 
calificación dada por los usuarios, además de ser las más usadas, con el objetivo de identificar 
los UIDPs más cualificados en cada aplicación. 
 
3.2.1. Análisis de UIDPs en Social Media 
En este punto se presentan los resultados del análisis de los UIDPs del dominio Social Media. 
En este sentido, se identificaron dos tipos de UIDPs y se dividen en UIDPs por reputación e 
interacción. En la Tabla 3.1 se describen los UIDPs por reputación, estos permiten construir 
prestigio a los usuarios mediante el contenido, información compartida, la relación con más 
personas y seguir sus actividades.  
28 
 
Tabla 3.1 UIDPs Social Media por reputación 
Reputación Descripción Imagen 
Leaderboards Se usan para mostrar usuarios 
  altamente competitivos de las 
actividades que desarrollan. 
 
Achievements Se aplica para desplegar las metas o 
el logro alcanzado en alguna 
actividad y compartirlo con tu círculo 
de amigos. 
 
 
En la siguiente figura se muestra la representación real de los UIDPs de tipo Social Media: 
leaderboards y achievements (ver Fig. 3.2). 
 
  L eaderb oards     Achievements 
  
 
 
 
 
 
 
Fig. 3.2 UIDPs Social Meda por reputación: leaderboards y Achievements 
 
En la Tabla 3.2 se listan los UIDPs por interacción social, los cuales permiten compartir 
información, conectarse con más personas y seguir sus actividades.  
 
 
 
29 
 
Tabla 3.2 UIDPs Sociale Media por interacción 
Interacciones Descripción Imagen 
Sociales 
Frient list Ofrece una manera de explorar a los 
usuarios de tu círculo cercano, da 
oportunidad de encontrar contactos 
frecuentes o la forma de compartir la 
información con los demás. 
 
Chat Permite a los usuarios contactar con  
otros usuarios de su mismo círculo o 
externos y provee una forma de 
comunicación privada de persona a 
persona. 
Friend Permite ver la información del 
contacto, como funciones 
importantes es enviar amistad y 
hablar información 
 
Follow Permite seguir al contacto 
seleccionado además de ver las 
ultimas actualizaciones de sus 
actividades. 
 
Reaction Permite calificar o realizar un cambio 
producido bajo un estímulo del 
usuario sobre el contenido de 
usuarios 
 
Invite friends Permite invitar a más amigos a 
consultar o visitar un sitio o 
información específica. 
 
 
  
 
30 
 
Tabla 3.3 UIDPs Sociale Media por interacción 
Interacciones Descripción Imagen 
Sociales 
Activity Stream Actualiza las actividades de los 
contactos que respondan a las 
acciones como reacciones y 
recordatorios 
 
Horizontal Menu  Muestra en forma de lista las 
opciones de la aplicación en forma 
horizontal. 
 
Vertical Menu Muestra en forma de lista las 
opciones de la aplicación en forma 
vertical. 
 
Gallery Permite ver imágenes de modo 
secuencial, de principio a fin o 
cuando se desea ver una imagen lo 
más posiblemente reservada de 
resolución.  
 
Panel Permite ver las características o 
propiedades del aspecto, como un 
producto o actividad. 
 
Ranking Permite valorar o calificar por parte 
de un usuario un aspecto que 
contenga la aplicación. 
 
 
31 
 
Tabla 3.4 UIDPs Sociale Media por interacción 
Interacciones Descripción Imagen 
Sociales 
Picker Permite seleccionar los ajustes de un  
calendario, paleta de color, entre 
otros. 
 
Music Player Reproduce música y sonidos  
seleccionados. 
 
 
Comment Permite escribir memorias o historias 
con brevedad sobre algún contenido. 
 
 
Login Permite ingresar un nombre de  
usuario y una contraseña para iniciar 
sesión. 
 
A continuación, se muestra la representación real de UIDPs de Social Media: Horizontal 
Menu, Ranking, Music Player y Login, Gallery, Reaction y Friend (ver Fig. 3.3 y 3.4). 
 
Menu-Horizontal Login  
 
 
Ranking Music Player 
 
 
 
 
 
 
 
Fig. 3.3 contiene la representación de: Menu-Horizontal, Ranking y Music Player y Login 
32 
 
 
Gallery Reaction Friend 
 
 
 
 
 
 
Fig. 3.4 UIDPs Social Meda por Interacción: Gallery, Reaction y Friend 
 
En la Fig. 3.5 se representa ejemplos de los UIDPs: Comments, Follow y Picker. 
 Comments Follow Picker 
 
 
 
 
 
 
Fig. 3.5 UIDPs Social Meda por Interacción: Comments, Follow y Picker 
La Fig. 3.6 se cuenta con la representación real de Chat, Vertical Menu, y Activity Stream. 
 Chat Menu-Vertical Activiy Stream 
 
 
 
 
 
 
 
Fig. 3.6 UIDPs Social Meda por Interacción: Chat, Menu Vertical y Activity Stream 
33 
 
Por último, en la Fig. 3.7 se representan ejemplos de los UIDPs: Friend List y Panel. 
 
 Friend List Panel 
 
 
 
 
 
 
 
 
Fig. 3.7 UIDPs Social Meda por Interacción: Friend List y Panel 
 
3.2.2. Análisis de UIDPs en e-Commerce 
En la tabla 3.3 se describen los UIDPs para las aplicaciones de tipo e-Commerce, donde este 
tipo de UIDPs permiten al usuario interactuar con el producto que se selecciona o pretende 
comprar.   
 
Tabla 3.5 UIDPs e-Commerce 
Reputación Descripción Imagen 
Product Page Muestra información en un sitio 
comercial sobre un producto y la 
disponibilidad de este. 
 
 
Coupon Crea atención a un producto o 
servicio, incentiva a los clientes y Free 
anuncia los descuentos. 
 % 
 
 
 
 
 
34 
 
Tabla 3.6 UIDPs e-Commerce 
Reputación Descripción Imagen 
Pricing table Permite dar información de sus 
características y precios de uno o $ $ $ 
más versiones de un producto.  
 
Shopping Cart Permite comprar uno o más 
productos, además de almacenar la 
compra para continuar 
posteriormente 
 
 
Stats Permite ver las estadísticas de 
valores estáticos o dinámicos 
 
 
La figura 3.8 muestran de representaciones reales de los UIDPs: Coupon, Shopping Cart y 
Pricing Table. 
 
Coupon Shopping Cart Pricing Table 
 
 
 
 
 
 
 
 
 
Fig. 3.8 UIDPs e-commerce: Coupon, Shopping Cart y Pricing Table 
35 
 
En la Fig. 3.9 se observa la representación real de los UIDPs: Product Page y Stats. 
 
Product Page Stats 
 
 
 
 
 
 
Fig. 3.9 UIDPs e-Commerce: Product Page y Stats 
 
Los patrones revisados para las aplicaciones e-Commerce y Social Media permite conocer 
más afondo la estructura y funcionalidades principales que permiten interpretar de forma 
correcta el desarrollo de aplicaciones de tipo e-Commerce y Social Media a través del 
adecuado uso de UIDPs en el diseño de interfaces de usuario que garantice su buena 
aplicación en la vida real. 
 
3.2.3. Análisis de Composiciones de UIDPs 
En este punto se presenta el análisis de las composiciones generadas por las UIDPs simples 
que se presentan en la sección 3.2.1 y 3.2.2 organizadas por dominio: e-Commerce y Social 
media. En la Tabla 3.4 se especifican los detalles de cada composición de tipo e-Commerce.  
 
Tabla 3.7 Composiciones de UIDPs para e-Commerce 
Composición Descripción UIDPs Icono 
Bus-men-pro- Aplicación que Search 
com permite mostrar Menu 
información de uno Product page  
o más productos Comment 
 
 
36 
 
Tabla 3.8 Composiciones de UIDPs para e-Commerce 
Composición Descripción UIDPs Icono 
Bus-men-pro-pla Aplicación de Search 
información del Menu 
producto con Product page  
reproducción Player 
multimedia 
 
Bus-men-pro-tip Aplicación de Search 
información del Menu 
producto que permite Product page  
compartir la Tip a friend 
información 
 
Bus-men-pro-gal Aplicación de Search 
información del Menu 
producto con distintas Product page  
imágenes de un Gallery 
producto 
 
Bus-men-sho-cou Aplicación para la Search 
compra de un producto Menu 
y para aplicar descuento Shopping Cart 
 Coupon 
 
Bus-men-sho- Aplicación para la Search 
pro-gal compra de un producto Menu 
y con distintas Shopping Cart 
imágenes Product page  
 Gallery 
 
Bus-men-sho- Aplicación para Search 
pro-pla comprar un producto y Menu 
visualizar los archivos Shopping Cart 
multimedia Product page  
 Player 
 
Bus-men-sho- Aplicación para Search 
pro-tip comprar un producto y Menu 
compartir el producto Shopping Cart 
 Product page  
Tip a friend 
 
 
37 
 
Tabla 3.9 Composiciones de UIDPs para e-Commerce 
Composición Descripción UIDPs Icono 
Bus-men-sho- Aplicación para Search 
pro-com comprar productos y Menu 
hacer observaciones u Shopping Cart 
opiniones de este Product page  
 Comment 
 
Bus-men-pan-pri Aplicación para Search 
mostrar información Menu 
del costo de uno o más Panel 
productos  Pricing Table 
 
Bus-men-pro-sta Aplicación para Search 
mostrar información Menu 
del producto y las Product page  
estadísticas de ventas o Stats 
visitas del producto 
 
Bus-men-pro-sta- Aplicación para Search 
com mostrar información Menu 
del producto con la Product page  
oportunidad de agregar Stats 
comentarios y Comment 
consultar estadísticas 
 
de ventas o visitas al 
producto 
Bus-men-sho- Aplicación para Search 
pro-sta-com mostrar información Menu 
del producto, comprar, Shopping 
comentar y consultar Cart 
estadísticas del Product page  
producto visitado Stats 
 Comment  
Men-sho-gal-pri Aplicación que permite Menu 
comprar productos, y Shopping 
elegir algún plan Cart 
propuesto  Gallery 
Pricing Table 
 
 
 
38 
 
Tabla 3.10 Composiciones de UIDPs para e-Commerce 
Composición Descripción UIDPs Icono 
Men-sho-pla-pri Aplicación que permite Menu 
comprar productos, Shopping 
visualizar multimedia y Cart 
elegir algún plan Player 
propuesto Pricing 
Table 
 
Men-sho-pri-sta Aplicación que permite Menu 
elegir, comprar y ver Shopping 
sus estadísticas del Cart 
producto. Pricing 
Table 
Stats 
 
Bus-Men-pri-sta Aplicación que permite Search 
observar información y Menu 
estadísticas de cierto Pricing 
producto seleccionado Table 
servicio. Stats 
 
Bus-men-gal-pla Aplicación acerca del Search 
producto o servicio Menu 
contiene visualización Gallery 
multimedia de videos e Player 
imágenes 
 
Bus-men-pla-pri Aplicación tipo Search 
informativo que Menu 
permite elegir y ver Player 
información Pricing 
multimedia  Table 
 
 
 
Prosiguiendo con el análisis se detallan las imágenes reales de las composiciones de UIDPs. 
En la Fig. 3.10 se muestran ejemplos reales de las composiciones propuestas en la Tabla 3.4, 
tales como: Bus-men-pro-com, Bus-men-pro-pla y Bus-men-pro-gal. 
 
 
 
39 
 
 
Bus-men-pro-com Bus-men-pro-pla Bus-men-pro-gal 
 
 
 
 
 
 
 
Fig. 3.10 Composiciones: Bus-men-pro-com, Bus-men-pro-pla y Bus-men-pro-gal  
 
En la Fig 3.11 están representados las siguientes composiciones: Bus-men-pro-tip y Bus-
men-sho-cou. 
 
 
Bus-men-pro-tip Bus-men-sho-cou 
 
 
 
 
 
 
Fig. 3.11 Composiciones:  Bus-men-pro-tip y Bus-men-sho-cou 
Para la Fig. 3.12 las siguientes composiciones son: Bus-men-sho-pro-gal, Bus-men-sho-pro-
pla y Bus-men-sho-pro-tip. 
 
 
 
40 
 
 
 Bus-men-sho-pro-gal Bus-men-sho-pro-pla Bus-men-sho-pro-tip 
 
 
 
 
 
 
 
Fig. 3.12 Composiciones: Bus-men-pro-com, Bus-men-pro-pla y Bus-men-pro-gal 
 
Para la Fig. 3.13 se representan las composiciones tales como: Bus-men-sho-pro-gal, Bus-
men-sho-pro-pla y Bus-men-sho-pro-tip. 
 
 Bus-men-sho-pro-com Bus-men-pan-pri Bus-men-pro-sta 
 
 
 
 
 
 
Fig. 3.13 Composiciones: Bus-men-sho-pro-com, Bus-men-pan-pri y Bus-men-pro-sta 
 
Al continuar con la Fig. 3.14 las composiciones representadas son: Bus-men-pro-sta-com, 
Bus-men-sho-pro-sta-com y Men-sho-gal-pri 
 
41 
 
 
 Bus-men-pro-sta-com Bus-men-sho-pro-sta-com Men-sho-gal-pri 
 
 
 
 
 
 
 
Fig. 3.14 Composiciones: Bus-men-pro-sta-com, Bus-men-pro-sta-com y Men-sho-gal-pri 
 
La siguiente Fig. 3.15 muestra las composiciones: Men-sho-pla-pri, Men-sho-pri-sta y Bus-
men-pri-sta 
 
Men-sho-pla-pri Men-sho-pri-sta Bus-men-pri-sta 
 
 
 
 
 
 
 
Fig. 3.15 UIDPs de composición e-Commerce: Men-sho-pla-pri, Men-sho,pri,sta y Bus-men-pri-sta 
 
Por último, la fig. 3.16 representa los ejemplos de las composiciones: Bus-men-gal-pla y 
Bus-men-pla-pri. 
 
42 
 
 Bus-men-gal-pla Bus-men-pla-pri 
 
 
 
 
 
 
 
 
Fig. 3.16 UIDPs de composición e-Commerce: Bus-men-gal-pla y Bus-men-pla-pri 
 
A continuación, en la Tabla 3.5 se describen las composiciones de UIDPs propuestas para 
Social Media. 
 
Tabla 3.11 Composiciones de UIDPs para Social Media 
Composición Descripción UIDPs Icono 
Bus-men-gal-fol- Aplicación que Search 
rea contiene las Menu 
publicaciones de Gallery 
imágenes con Follow 
capacidad de Reaction 
reaccionar y seguir 
al usuario  
Bus-men-pla-fol- Aplicación que Search 
rea contiene Menu 
publicaciones de Player 
videos con Follow 
capacidad de Reaction 
reaccionar y seguir 
al usuario  
Bus-men-cha-rea Aplicación que Search 
permite ver los Menu 
chats publicados Chat 
por los amigos y Reaction 
permite reaccionar  
 
43 
 
Tabla 3.12 Composiciones de UIDPs para Social Media 
Composición Descripción UIDPs Icono 
Bus-men-log Aplicación que Search 
permite iniciar sesión Menu 
del usuario Logging 
 
Bus-men-com- Aplicación que Search 
rea permite comentar y Menu 
reaccionar en base a la Comment 
publicación  Reaction 
 
Bus-men-pan-fin Aplicación que Search 
permite compartir Menu 
información de la Panel 
publicación  Friend Invite 
 
Bus-men-fin-fli Aplicación que Search 
permite invitar a más Menu 
usuarios  Friend Invite 
Friend List 
 
Bus-men-fin-fri Aplicación para Search 
agregar e invitar a más Menu 
usuarios  Friend Invite 
Friend  
 
Bus-men-act Aplicación que Search 
permite ver las Menu 
actividades de los Activity 
usuarios  Stream 
 
 
 
 
44 
 
Tabla 3.13 Composiciones de UIDPs para Social Media 
Composición Descripción UIDPs Icono 
Bus-men-ran Aplicación que Search 
permite ver el ranking Menu 
de los usuarios de una Ranking 
aplicación  
 
 
Una vez definidas las composiciones de UIDPs para Social Media se presenta la visualización 
que corresponde a las interfaces reales.  
En la Fig. 3.17 se visualiza las siguientes composiciones Social Media: Bus-men-gal-pla y 
Bus-men-pla-fol-rea y Bus-men-cha-rea. 
   
Bus-men-gal-pla Bus-men-pla-fol-rea Bus-men-cha-rea 
 
 
 
 
 
 
 
Fig. 3.16 UIDPs de composición Social Media: Bus-men-gal-pla y Bus-men-pla-fol-rea y Bus-men-cha-rea 
 
Fig. 3.17 Composiciones Social Media: Bus-men-log,Bus-men-com-rea y Bus-men-pan-fin 
 
En la Fig. 3.18 se encuentran representadas las siguientes composiciones: Bus-men-log,Bus-
men-com-rea y Bus-men-pan-fin. 
 
 
 
45 
 
 Bus-men-log Bus-men-com-rea Bus-men-pan-fin 
 
 
 
 
 
 
 
 
Fig. 3.18 UIDPs de composición Social Media: Bus-men-log,Bus-men-com-rea y Bus-men-pan-fin 
 
Al continuar con la ejemplificación de las composiciones, en la Fig. 3.18 se observan las 
composiciones: Bus-men-fin-fli, Bus-men-fin-fri y Bus-men-act 
 
 Bus-men-fin-fli Bus-men-fin-fri Bus-men-act 
 
 
 
 
 
 
Fig. 3.19 Composiciones Social Media: Bus-men-fin-fli, Bus-men-fin-fri y Bus-men-act 
 
 
 
 
46 
 
Por último, se observa en la Fig. 3.20 la composición: Bus-men-ran. 
 Bus-men-ran 
fli 
 
 
 
 
 
 
 
Fig. 3.20 Composición Social Media: Bus-men-ran 
 
Los patrones compuestos de e-Commerce y Social Media analizados permiten saber cuántas 
conexiones y relaciones existen con los UIDPs. Permite en lo general saber cómo se 
encuentran estructurados ciertas ventanas y tener una solución específica a la necesidad que 
interpreta cada UIDP compuesta. 
 
3.3.Proceso de identificación de elementos en interfaces mediante Deep Learning  
En esta sección se describen las instancias para entrenar el modelo de Deep Learning, y la 
descripción del modelo que especifica sus características. 
 
3.3.1. Conjunto de imágenes 
El conjunto de imágenes con que se cuentan actualmente suma un total de 47 UIDPs, los 
cuales se clasificaron en 4 tipos: imágenes ideales, no ideales, reales en blanco y negro y 
reales a color con un total de más de 18,800 instancias. Las imágenes ideales son imágenes 
generadas mediante cualquier herramienta de dibujo y no presentan deformaciones. Las 
imágenes no ideales son aquellas generadas a mano alzada, desde cualquier aplicación o 
herramienta de dibujo o bien a través de una tableta digitalizadora. Las imágenes reales en 
47 
 
blanco y negro son imágenes generadas a mano alzada en hojas de papel y digitalizadas a 
través de una cámara o un scanner. Finalmente, las imágenes reales a color son imágenes 
generadas a mano alzada, en hojas de papel de diferentes colores y utilizar bolígrafos de 
diferentes colores. 
La resolución de todas las imágenes es de 1050 * 650 pixeles listas para probar, cada UIDP 
contiene un total de 400 instancias, es decir 100 por cada tipo de imagen. Cabe mencionar 
que de las 47 UIDPs, 32 pertenecen al dominio de Social Media y de las cuales 12 son UIDPs 
simples y 20 son UIDPs compuestos. Para el dominio e-Commerce se tienen 15 UIDPs, de 
los cuales 5 son UIDPs simples y 10 son UIDPs compuestos.  
En la tabla 3.6 se observan diferentes ejemplos de UIDPs simples divididos por imágenes 
ideales y no ideales. Es importante mencionar que algunos UIDPs son válidos para ambos 
dominios: e-Commerce y Social Media.  
 
Tabla 3.14 UIDPs simples ideales y no ideales 
UIDP Imágenes ideales UIDP Imágenes no ideales 
Chat Gallery 
Social Media Social Media 
E-Commerce E-Commerce 
 
 
Menu- Ranking 
Horizontal Social Media 
Social Media E-Commerce 
E-Commerce 
  
 
 
 
 
48 
 
Tabla 3.15 UIDPs simples ideales y no ideales 
UIDP Imágenes ideales UIDP Imágenes no ideales 
Picker Reaction 
Social Media Social 
E-Commerce Media 
  
Follow Shopping 
Social Media cart 
 e-Commerce 
  
 
En la tabla 3.7 se presenta ejemplos de composiciones divididos por imágenes reales en 
blanco y negro, e imágenes a color.  
 
Tabla 3.16 Composiciones de UIDPs Reales en blanco y negro, y reales a color 
Composició Real Blanco y Negro Composició Real a Color 
n n 
Bus-men- Men-sho-
fin-fri  pri-sta 
Social e-
Media Commerce 
 
 
Bus-men- Bus-Men-
act pri-sta 
Social e-
Media Commerce 
  
 
 
49 
 
Tabla 3.17 Composiciones de UIDPs Reales en blanco y negro, y reales a color 
Composición Real Blanco y Negro Composición Real a Color 
Bus-men-ran Bus-men-gal-
Social Media pla 
e-Commerce 
  
Bus-men-fin- Bus-men-pla-
fli pri 
Social Media e-Commerce 
  
 
3.4. Proceso de transformación de la imagen 
Una vez creadas y definidas las instancias (imágenes) para el entrenamiento se aplicó un 
proceso de transformación de las instancias para las redes neuronales convolucionales. El 
proceso de transformación se basa en la configuración del tipo de red neuronal a utilizar. En 
este sentido, los estándares óptimos para la alimentación de una red neuronal incluyen valores 
en pixeles con un mínimo de 200 y un máximo de hasta 299 pixeles, para una óptima solución 
en las redes neuronales como AlexNet que requiere una resolución de la imagen de 256 * 
256 pixeles, mientras que Inception_v3 requiere una resolución de la imagen de 255 * 255 
pixeles para cada imagen. Desde esta perspectiva las imágenes pasan por un proceso de 
reorientación de la resolución para embonar en el proceso neuronal convolucional y en 
mejorar la calidad de precisión de las imágenes.  
Para obtener un estándar específico y limpio se recomienda pasar las imágenes de color a 
imágenes en blanco y negro, esto ayuda completamente a disminuir el consumo 
computacional. 
Previo al entrenamiento de la red neuronal el proceso de transformación en ambas redes 
neuronales consistió en: (1) se obtiene una imagen original con una dimensión total de 1050 
* 650 pixeles y se redimensiona a 256 * 256 (ver Fig. 3.21-a). (2) La instancia pasa por el 
primer cambio que determina eliminar el ruido por medio de métodos y funciones de 
50 
 
procesamiento de imágenes ya implementados, los algoritmos aplicados son: mediaBlur que 
es una función que suaviza la imagen, dilatación que permite el aumento de los objetos a 
primer plano y por último la normalización, que se encarga de optimizar los valores altos y 
bajos de una matriz (ver Fig. 3.21-b). Al final, se implementa la función Local Otsu, 
encargada de optimizar un umbral del pixel para aclarar y maximizar los pixeles en dos 
clases, primer plano y fondo (ver Fig. 3.21-c). 
 
 
Fig. 3.21 Ejemplo de la eliminación del ruido de una imagen real a color, a) imagen real a color, b) imagen real 
aplicación en la eliminación de sombras, c) imagen real aplicación eliminación de ruido. 
 
Estos métodos y funciones que se implementan por las APIs scikit-image versión 0.15.0 y 
opencv versión 2.4.13.1, que son bibliotecas especiales y esenciales que contienen miles de 
algoritmos para el procesamiento de imágenes. Una vez realizado este proceso de 
transformación, se continua con ejecución de los entrenamientos de las redes neuronales 
convolucionales.  
 
3.4.1. Descripción del entrenamiento  
Para la utilización de las redes neuronales convolucionales en este punto se hace una breve 
descripción específica de las redes neuronales convolucionales utilizadas para la elaboración 
de los resultados obtenidos. 
 
51 
 
3.4.1.1.Entrenamiento con diferentes modelos de redes neuronales 
Las siguientes pruebas generadas permitieron conocer ampliamente las características que 
conforman las rede convolucionales tales como: los atributos, métodos y funciones que se 
requieren para madurar una red convolucional. 
Para la prueba 1 (ver la Tabla 3.8) se contó con un total de 250 imágenes, con una 
configuración de 256 batch y 3 épocas. Esta prueba se realizó con un modelo clásico 
específico llamado LeNet, esta red cuenta con 6 capas convolucionales y una de salida, esta 
prueba generada en la API DeepLearning4Java permite probar con el lenguaje Java una 
pequeña red neuronal, la primera característica de desarrollar esta prueba permitió entender 
las características de cómo se instruye una red neuronal y como funciona. 
 
Tabla 3.18 Resultados de la prueba 1 
UIDPs Precisión Tiempo (seg) 
Acordeon 0.45 21.32 
Barra de etiqueta 0.45 21.32 
Login 0.45 21.32 
Master Detalle 0.45 21.32 
Tarjeta 0.45 21.32 
 
Para la prueba 2 (ver la Tabla 3.9) se usó la API TensorFlow, con un modelo que cuenta con 
2 capas convolucionales y 1 capa de salida, tiene un total de 600 imágenes, con una 
configuración de la red neuronal convolucional con 1699 batch y 100 épocas. La prueba 
realizada sobre una red neuronal convolucional binominal que solamente clasifica dos 
imágenes, la característica importante de esta red es entender las propiedades y atributos 
importantes de la API TensorFlow en el lenguaje Python. 
 
Tabla 3.19 Resultados de la prueba 2 
UIDPs  Precisión Tiempo (seg) 
Gallery  1 30 
Music Player  3.1575022e-13 45 
 
52 
 
La prueba 3 (ver la Tabla 3.10) se desarrolló con la API TensorFlow con un total de 800 
imágenes, la importancia del entrenamiento y la prueba realizada fue utilizar el modelo 
anterior (prueba 2) y aumentar al doble la clasificación de los UIDPs, la red utiliza una 
configuración de 1401 batch y 10 épocas.  
 
Tabla 3.20 Resultados de la prueba 3 
UIDPs Precisión Tiempo (seg) 
Gallery 0.4339219 23.407269 
Menu Horizontal 0.422323233 23.407269 
Menu Vertical 0.123212333232 23.407269 
Panel 0.0221412 23.407269 
 
Para la prueba 4 (ver la Tabla 3.11) se contó con un total de 800 imágenes, con una 
configuración de 699 batch y 10 épocas. En esta prueba se realizó una transformación en las 
imágenes del entrenamiento y el resultado de la transformación se implementó con la red 
neuronal convolucional AlexNet que se detalla en la siguiente sección. Cuenta con 800 
imágenes, y su configuración se basa en 699 batch y 10 épocas, los resultados obtenidos se 
observan en la Tabla 3.13. 
 
Tabla 3.21 Resultados de la prueba 4 
UIDPs Precisión Tiempo (seg) 
Gallery 0.99983644 8.24 
Menu Horizontal 0.56006614 8.32 
Menu Vertical 0.99995962 8.40 
Music Player 0.9624471 8.18 
Panel 0.9980167 7.98 
Picker 0.8734556 7.91 
Ranking 0.98580235 7.85 
 
Como se observa, los resultados obtenidos en la prueba 4 fueron mucho más exactos, 
obteniendo un 99% de eficiencia en la clasificación de los UIDPs y con un tiempo de 
respuesta de 8 segundos en promedio. 
53 
 
3.4.1.2. Entrenamiento con AlexNet  
AlexNet es un tipo red convolucional lineal que se implementa con la API de tensorFlow 
1.12 en la versión de Anaconda 1.9.6 junto con Spyder 3.6. En la Fig. 3.22 se muestra la 
estructura del modelo, el cual cuenta con una configuración estandarizada de 5 capas 
convolucionales, además de la capa flattening, una capa fully-connected y la capa de salida. 
La elección este modelo se basa en la premisa de obtener una tasa de error que comprende 
del 26% al 15.3%, además soporta algoritmos como max-pooling, dropout, data 
argumentation y ReLu, que permiten obtener una estandarización de los datos, no cuenta con 
restricciones de tamaño o dimensiones para cada capa convolucional.  
 
 
Fig. 3.22 Arquitectura de la red neuronal convolucional con 5 capas convolucionales, 1 capa flattening, 1 capa fully-con 
y capa de salida. 
 
El modelo permite calcular las probabilidades de la extracción de las características del 
patrón resultante y usar valores gradiente, en otras palabras, se reducen los pesos generados 
del kernel para clasificar la imagen que corresponda a su matriz resultante. 
A continuación, se abordan las pruebas realizadas para obtener el modelo final con AlexNet. 
Prueba 1: En la Tabla 3.12 se registran los resultados obtenidos del entrenamiento con una 
configuración de 1199 batch con un total de 10 épocas y un tiempo de entrenamiento de 8.7 
horas, da una precisión de 88%. La importancia de hacer esta prueba es observar los 
resultados y validar el alcance que tiene el modelo con respecto de más de siete UIDPs que 
se hicieron en la sección pasada, otro punto a resaltar es la implicación del proceso de 
transformación que ayuda a mejorar y concentrar las imágenes necesarias para entrenar.
54 
 
Con nueve patrones y con 200 instancias el modelo AlexNet cumple con los resultados de precisión, derivado a que se tomarán los 
cuatro primeros resultados, en la tabla los valores subrayados en rojo denotan los resultados obtenidos, donde 1 se toma como un 
correcto acercamiento de los cuatro primeros lugares cercanos al 100% y 0 donde no se encuentra en los cuatro primeros lugares de 
clasificación al 100%. 
Tabla 3.22 Tabla de entrenamiento para AlexNet con 9 patrones y 200 instancias c/u 
  Chat Gallery Picker Panel Comment Menu Menu Music Ranking 
horizontal vertical player 
Chat 1 0.0001625 0.1935297 0.0004734 0.0681363 0.0023344 1.16E-05 0.0352040 0.0033498
06 3 71 94 41 8 91 
Gallery 0.0130608 1 0.0012026 4.30E-05 0.0077412 0.0010502 5.16E-05 0.0069036 0.0105445
46 69 66 86 45 25 
Picker 0.0004592 8.85E-05 1 4.91E-05 0.1055307 0.0001172  0.0033498 0.0023734 0.0005238
86 3 58 91 13 53 
Panel 0.0005575 3.29E-05 0.0056483 1 0.0231063 0.3015046 0.0002069 0.0006740 0.0004475
1 95 37 59 08 44 64 
Comment 0.0005144 0.0016699 0.1448295 0.0001264 1 0.4500056 4.71E-06 0.2661301  0.000487 
63 27 4 92 78 8 
Menu 0.0022870 0.0009256 0.0019180 0.0010229 0.0127738 0 0.0004154 0.0002104 0.0021453
horizontal 21 24 43 49 99 36 59 37 
Menu  0.0000544  0.0004578 0.0005324 0.0005659 0.0012385 0.2486046 1   0.0013202
vertical 96 31 59 1 93 
Music 0.0002092 0.0006269 0.0348803 2.61E-05 0.0187478 0.0058453 2.07E-05 1 0.0014458
player 94 44 44 07 7 27 
Ranking 0.0001826 0.0022659  .0044776  .001279 0.0010686 0.0031402 4.57E-05 0.0013552 1 
33 77 67 03 91 
55 
 
Prueba 2: En esta segunda prueba se utilizó un conjunto de 9 patrones con 400 imágenes cada uno, por lo tanto, un total de 3600 imágenes 
el doble de la prueba anterior, esto fue gracias a una nueva versión del proceso de transformación de la imagen. En la Tabla 3.13 se 
registran los resultados del entrenamiento que se obtuvo con una configuración de 1199 batch con un total de 10 épocas con un tiempo 
de entrenamiento de 11.6 horas, da una precisión del 100%. La importancia de hacer esta prueba fue ver el comportamiento de usar la 
misma cantidad de patrones de la prueba 1.  
Tabla 3.23 Tabla de entrenamiento para AlexNet con 9 patrones y 400 instancias c/u 
  Chat Gallery Picker Panel Commen Menu Chat Gallery Picker 
t horizontal 
Chat 1 0.244582 0.092216 0.009311 0.077810 0.19702998 0.012670 0.000776 0.007370
38 11 597 146 485 279 127 
Gallery 0.038561 1 0.050907 0.002415 0.005094 0.041085303 0.006743 3.76E-05 0.001321
948 224 942 664 959 756 
Picker 0.018224 0.000546 4 0.006819 0.045885 0.012618925 0.000145 0.000177 0.005822
648 897 6 164 965 974 
Panel 0.006833 0.027818 0.139852 1 0.272508 0.061365534 0.000859 0.000224 0.009056
378 032 93 68 995 905 208 
Comment 0.005135 0.014125 0.052823 0.051087 1 0.019245375 0.000551 1.04E-05 0.006095
891 279 12 1 739 901 
Menu 0.197972 0.069336 0.004170 0.001078 0.012612 1 0.002419 0.000106 0.001091
horizontal 77 59 35 468 53 511 045 085 
Menu 0.006887 0.056866 0.055002 0.003285 0.005871 0.06844314 1 0.000152 0.163531
vertical 948 48 443 562 234 222 18 
Music player 0.005039 0.002415 0.109438 0.000455 0.000866 0.010981618 0.018856 1 0.001316
374 473 75 572 247 758 326 
Ranking 0.000763 0.002366 0.004325 0.000673 0.001089 0.004886695 0.000449 7.39E-05 1 
028 882 727 173 388 571 
56 
 
Prueba 3: para esta prueba se utilizaron 17 patrones con 400 imágenes cada uno, es decir un total de 6800 instancias. En la Tabla 3.14 
se registran los resultados obtenidos del entrenamiento con una configuración de 1499 lotes con un total de 10 épocas con un tiempo de 
entrenamiento de 19.4 horas, da una precisión de 52%. El motivo de esta prueba es aumentar 10 UIDPs, para saber el comportamiento 
de la red neuronal, y como se observa la precisión cae considerablemente. A pesar que se cuentan con más imágenes, la cantidad de 
UIDPs que también incrementa, hace que la precisión no sea óptima. 
 
Tabla 3.24 Tabla de entrenamiento para AlexNet con 17 patrones y 400 instancias c/u 
  Composición Composición Composición Composición Composición Composición Chat 
1 2 3 4 5 6 
Composición 1 0.24458238 0.09221611 0.009311597 0.077810146 0.19702998 0.01267048
1 5 
Composición 0.038561948 0 0.050907224 0.002415942 0.005094664 0.041085303 0.00674395
2 9 
Composición 0.018224 0.000546648 0 0.006819897 0.0458856 0.012618925 0.00014516
3 4 
Composición 0.006833378 0.027818032 0.13985293 1 0.27250868 0.061365534 0.00085999
4 5 
Composición 0.005135891 0.014125279 0.05282312 0.0510871 0 0.019245375 0.00055173
5 9 
Composición 0.19797277 0.06933659 0.00417035 0.001078468 0.01261253 0 0.00241951
6 1 
Chat 0.006887948 0.05686648 0.055002443 0.003285562 0.005871234 0.06844314 1 
 
 
57 
 
 
 
Tabla 3.25 Tabla de entrenamiento para AlexNet con 17 patrones y 400 instancias c/u 
  Gallery Picker Panel Comment Menu Menu Music Ranking 
horizontal vertical player 
Gallery 1 0.0013163 6.29E-05 0.0091310 0.00077163 6.96E-05 0.00872514 0.0129698
26 86 24 
Picker 7.39E-05 1 5.29E-05 0.1105407 5.36E-05  .000547877 0.00272435 0.0004363
5 17 
Panel 2.20E-05 0.0040388 1 0.0210363 0.000931349 0.000236409 0.00057979 0.0004096
93 36 2 68 
Comment 0.0013741 0.1302709 0.0001516 1  0.027818032 4.98E-06 0.24293001 0.0001934 
14 6 63 
Menu 0.0006370 0.0012962 0.0010562 0.0096009 0 0.00058558 0.00017455 0.0020066
horizontal 18 12 42 7 9 37 
Menu vertical   0.0004090 0.0009045 0.0011317 0.16476302 1   0.0012816
19 08 09 88 
Music player 0.0006151 0.0341845 3.42E-05 0.0199783 0.000356791 2.25E-05 1 0.0013321
63 2 78 99 
Ranking 0.0024393   .0024757 3.20E-05 0.0012595 0.002316048 6.23E-05 0.00145763 1 
73 05 3 
58 
 
Prueba 4: En esta prueba se utilizaron 27 patrones con 400 imágenes cada uno, por lo tanto, se cuenta con un total de 10,800 imágenes. 
En la Tabla 3.15 se registraron los resultados obtenidos del entrenamiento con una configuración de 2993 batch, un total de 10 épocas y 
un tiempo de entrenamiento de 37.3 horas, da una precisión de 43.3%. Se observa que la precisión sigue disminuyendo mientras más 
UIDPs se clasifiquen, por lo tanto, AlexNet en esta última prueba no logra un resultado satisfactorio para reconocer los patrones 
 
Tabla 3.26 Tabla de entrenamiento para AlexNet con 27 patrones (1) 
  Com Com Com Com Com Com Com Com Ch Gal Pic Pan Co Men Men Mu Ra
posic posic posic posic posic posic posic posic at lery ker el mm u u sic nki
ión ión ión ión ión ión ión ión ent horiz vert play ng 
1-s 2-s 3-s 4-s 5-s 6-s 7-s 8-s ontal ical er 
Com 1 0.092 0.069 0.003 0.024 0.031 0.014 0.006 0.01 0.00 0.00 0.00 0.00 0.133 0.00 9.42 0.00
posic 3282 0347 9042 2505 2753 1203 8902 127 073 329 033 055 9235 031 E- 057
ión 9 1 6 37 73 7 82 594 639 104 662 417 5 734 05 598 
1-s 7 4 9 8 9 1 
Com 0.017 0 0.004 0.002 0.003 0.015 0.092 0.000 0.00 0.00 0.00 2.32 0.01 0.010 5.36 0.00 0.00
posic 7782 9083 8915 9513 0013 4605 6503 819 022 175 E- 190 2246 E-05 013 287
ión 3 03 28 99 82 1 52 108 932 655 05 351 56 029 941
2-s 6 7 4 4 4 9 
Com 0.013 0.001 0 0.006 0.029 0.004 0.001 0.006 0.00 0.00 0.00 3.41 0.00 0.019 8.12 0.00 0.00
posic 3765 0219 8792 1133 7169 2931 5077 037 048 373 E- 217 9633 E-05 019 245
ión 11 19 18 58 69 31 12 061 995 450 05 446 93 933 533
3-s 2 1 9 7 8 9 
Com 0.004 0.018 0.016 0 0.054 0.021 0.048 0.003 0.00 0.00 0.00 3.99 0.01 0.001 2.97 0.00 0.00
posic 2076 8518 6366 5076 1611 4729 3909 095 043 794 E- 354 5305 E-06 025 061
ión 02 61 2 84 91 63 08 049 940 825 05 297 93 445 601
4-s 9 3 8 1 7 7 
 
59 
 
Tabla 3.27 Tabla de entrenamiento para AlexNet con 27 patrones (1) 
  Com Com Com Com Com Com Com Com Ch Ga Pic Pa Co Menu Men Mus Ran
posici posici posici posici posic posici posici posici at ller ker ne mm horiz u ic kin
ón 1-s ón 2-s ón 3-s ón 4-s ión ón 6-s ón 7-s ón 8-s y l ent ontal verti play g 
5-s cal er 
Co 0.003 0.008 0.002 0.020 1 0.00669 0.077 0.003 0.0 2.7 0.0 1.8 0.00 0.000 2.35 9.87 0.00
mp 31273 78274 09723 01338 2737 12532 03118 005 0E- 054 9E 366 26851 E-06 E- 024
osi 5 4 3 8 6 8 671 05 506 - 088 7 05 071
ció 43 26 05 5 9 
n 
5-s 
Co 0.055 0.049 0.003 0.001 0.0 0 0.047 0.000 0.0 0.0 0.0 2.0 0.00 0.000 1.31 0.00 0.00
mp 77554 47731 46896 19103 07 57481 36018 024 00 015 3E 067 92020 E-05 041 177
osi 6 5 2 47 7 306 16 335 - 068 8 630 474
ció 69 61 64 04 05 6 9 
n 75 62 
6-s 
Co 0.002 0.018 0.000 0.000 0.0 0.03154 1 0.000 0.0 3.9 0.0 5.8 0.00 0.001 0.00 1.71 0.00
mp 30558 84681 36990 16281 00 6798 24924 007 0E- 002 2E 120 62608 8101 E- 029
osi 9 9 5 35 2 066 06 931 - 136 3 461 05 562 
ció 46 19 11 07 5 
n 92 
7-s 
Co 0.007 0.003 0.071 0.015 0.0 0.03080 0.001 1 0.0 1.8 7.9 0.0 0.00 0.149 7.72 2.05 0.00
mp 36999 29495 92188 74792 81 1853 16141 004 4E- 7E- 00 019 84247 E-05 E- 063
osi 3 1 9 96 5 671 05 05 54 598 05 175 
ció 10 23 65 9 
n 5 15 
8-s 
 
60 
 
Tabla 3.28 Tabla de entrenamiento para AlexNet con 27 patrones (1) 
  Com Com Com Com Com Com Com Com Ch Ga Pic Pa Co Menu Men Mus Ran
posici posici posici posici posi posi posici posici at ller ker nel mm horiz u ic king 
ón 1-s ón 2-s ón 3-s ón 4-s ción ción ón 7-s ón 8-s y ent ontal verti play
5-s 6-s cal er 
Ch 0.004 0.041 0.006 0.001 0.00 0.02 0.001 5.42E 1 0.0 0.0 0.0 0.03 0.001 1.11 0.01 0.00
at 36719 29565 61078 88419 1434 9469 98691 -05 00 583 00 0441 02559 E-05 935 485
9 2 1 354 792 2 43 708 16 832 6 448 952 
79 85 34 1 
33 63 
Ga 0.001 0.001 0.013 0.000 0.00 0.00 7.75E 1.27E 0.0 1 0.0 3.1 0.00 0.000 5.87 0.00 0.01
ller 71210 43546 05518 31032 0238 4192 -05 -06 109 004 0E 2743 43470 E-05 462 764
y 2 9 2 6 446 975 586 388 - 303 9 401 701
17 67 05 4 9 
Pic 0.000 0.002 0.000 0.000 0.00 0.00 0.002 1.38E 0.0 0.0 0 2.9 0.05 5.17E 1.42 0.00 0.00
ker 80096 74907 24815 80885 0574 3728 07176 -05 005 00 8E 8692 -05 E-06 263 049
3 5 5 844 546 3 981 21 - 82 075 505
84 54 05 8 8 
22 
Pa 0.000 0.001 0.008 0.002 0.00 0.00 0.000 5.08E 0.0 7.6 0.0 1 0.01 0.001 0.00 0.00 0.00
nel 42930 05682 00842 60976 2348 7961 23127 -05 008 1E- 025 0644 71456 0717 046 053
4 3 5 7 591 731 7 814 05 118 656 2 219 736 758
34 41 4 5 
Co 0.000 0.001 0.000 0.000 0.00 0.00 0.000 4.10E 0.0 0.0 0.1 9.5 0 4.35E 6.26 0.25 0.00
m 42355 51988 95145 34116 0332 3164 68312 -06 008 04 066 7E -05 E-06 125 028
me 8 1 6 541 45 291 33 047 - 784 112
nt 79 99 2 05 2 
3 
 
 
61 
 
Tabla 3.29 Tabla de entrenamiento para AlexNet con 27 patrones (1) 
  Com Com Com Com Com Com Com Com Ch Ga Pic Pa Co Menu Men Mus Ran
posici posici posici posici posi posi posici posici at ller ker nel mm horiz u ic king 
ón 1-s ón 2-s ón 3-s ón 4-s ción ción ón 7-s ón 8-s y ent ontal verti play
5-s 6-s cal er 
Me 0.000 0.000 0.017 0.000 0.00 0.00 7.69E 0.000 0.0 0.0 0.0 0.0 0.00 0 0.00 8.30 0.00
nu 33423 19434 23277 72923 5799 3524 -05 69619 015 00 004 00 2897 1257 E-05 183
hor 5 5 5 484 236 6 499 78 517 57 626 752 819
izo 27 60 58 10 2 
nta 86 59 
l 
Me 0.000 0.000 0.005 0.001 0.00 0.00 9.66E 4.50E 0.0 2.5 0.0 0.0 0.00 0.178 1 4.13 0.00
nu 34236 22047 33479 19497 2093 1196 -05 -05 001 1E- 002 01 0739 51332 E-05 178
ver 6 9 2 3 856 733 151 05 662 62 078 224
tic 29 23 25 2 
al 68 
Mu 0.001 0.000 0.002 0.001 0.00 0.00 0.000 1.07E 0.0 0.0 0.0 2.6 0.01 0.000 2.24 0 0.00
sic 79305 89866 56202 45740 0845 3100 43427 -05 004 02 267 9E 3851 25163 E-05 160
pla 6 7 7 2 035 361 206 03 371 - 255 2 067
yer 51 75 2 05 8 
22 
Ra 0.000 7.31E 0.000 6.46E 5.50 0.00 4.68E 1.19E 0.0 0.0 0.0 2.8 0.00 0.002 9.50 0.00 1 
nki 13363 -05 93439 -05 E-05 0474 -04 -06 006 08 002 0E 0811 29303 E-05 142
ng 2 8 62 033 72 582 - 252 1 691
29 07 19 05 3 
16 
 
 
 
62 
 
Tabla 3.30 Tabla de entrenamiento para AlexNet con 27 patrones (1) 
  Com Com Com Com Com Com Com Com Ch Ga Pic Pa Co Menu Men Mus Ran
posici posici posici posici posi posi posici posici at ller ker nel mm horiz u ic king 
ón 1-s ón 2-s ón 3-s ón 4-s ción ción ón 7-s ón 8-s y ent ontal verti play
5-s 6-s cal er 
Co 0.108 0.079 0.067 0.003 0.00 0.15 0.017 5.10E 0.0 0.0 0.0 8.1 0.00 0.016 0.00 0.00 0.00
mp 81881 71123 04838 70420 1711 2000 12563 -05 091 04 004 8E 0303 74330 0118 011 196
osi 4 6 6 241 8 6 139 36 377 - 966 2 941 738 425 
ció 22 32 77 06 5 
n 59 
1-e 
Co 0.068 0.027 0.010 0.004 0.00 0.02 0.007 3.92E 0.0 0.0 0.0 4.6 0.01 0.011 0.00 5.20 0.00
mp 83622 32702 10791 28653 0416 2535 01835 -05 027 01 014 4E 0791 85047 0392 E-05 636
osi 5 8 1 996 408 4 202 66 642 - 726 7 441 875 
ció 1 47 17 05 
n 64 
2-e 
Co 0.006 0.000 0.051 0.003 0.01 0.00 0.000 0.003 0.0 0.0 0.0 1.7 0.00 0.017 4.86 0.00 0.00
mp 51681 51992 42821 38299 3177 8136 62055 18605 002 00 026 9E 1412 18010 E-05 014 297
osi 1 4 1 947 072 4 8 332 51 641 - 592 4 048 176
ció 62 09 93 05 5 
n 44 
3-e 
Co 0.004 0.014 0.019 0.175 0.04 0.01 0.047 0.003 0.0 0.0 0.0 3.7 0.01 0.001 3.36 0.00 0.00
mp 24569 58559 06332 93181 8690 7894 64857 33644 008 00 090 8E 6308 74916 E-06 027 050
osi 9 7 2 904 188 1 029 34 125 - 514 3 155 779
ció 83 26 73 05 9 8 
n 12 
4-e 
 
63 
 
Tabla 3.31 Tabla de entrenamiento para AlexNet con 27 patrones (1) 
  Com Com Com Com Com Com Com Com Ch Ga Pic Pa Co Menu Men Mus Ran
posici posici posici posici posi posi posici posici at ller ker nel mm horiz u ic king 
ón 1-s ón 2-s ón 3-s ón 4-s ción ción ón 7-s ón 8-s y ent ontal verti play
5-s 6-s cal er 
Co 0.002 0.008 0.001 0.016 0.07 0.00 0.053 0.002 0.0 2.7 0.0 1.5 0.00 0.000 1.83 8.48 0.00
mp 38524 07921 91578 67592 1430 6437 04356 54646 005 0E- 048 2E 2775 20042 E-06 E-05 018
osi 5 5 6 5 9 207 7 215 05 644 - 092 7 738 
ció 09 3 05 
n 
5-e 
Co 0.098 0.081 0.005 0.001 0.00 0.11 0.064 0.000 0.0 0.0 0.0 1.2 0.00 0.001 1.90 0.00 0.00
mp 21650 56671 84473 79352 9101 6314 16419 29998 027 00 017 5E 0710 15321 E-05 054 212
osi 4 4 5 255 74 3 765 34 708 - 387 3 681 367
ció 6 26 2 05 4 
n 06 
6-e 
Co 0.013 0.010 0.004 0.007 0.00 0.01 0.000 0.000 0.0 0.0 0.0 0.0 0.00 0.005 .002 0.00 0.00
mp 08052 81210 04028 26324 2626 8380 86151 12692 008 00 142 55 7707 77308 3124 025 020
osi 3 9 9 2 874 58 4 535 62 519 99 791 5 5 223 537
ció 03 44 59 38 9 6 
n 96 
7-e 
Co 0.016 0.039 0.000 0.003 0.00 0.01 0.015 0.000 0.0 8.2 0.0 1.0 0.00 0.000 0.00 0.00 0.00
mp 08332 68190 96411 17336 3594 2707 61844 26641 002 0E- 012 2E 1742 77055 0314 014 087
osi 6 4 5 5 871 172 4 7 817 05 228 - 876 49 434 668
ció 04 56 05 2 5 
n 
8-e 
 
64 
 
Tabla 3.32 Tabla de entrenamiento para AlexNet con 27 patrones (1) 
  Com Com Com Com Com Com Com Com Ch Ga Pic Pa Co Menu Men Mus Ran
posici posici posici posici posi posi posici posici at ller ker nel mm horiz u ic king 
ón 1-s ón 2-s ón 3-s ón 4-s ción ción ón 7-s ón 8-s y ent ontal verti play
5-s 6-s cal er 
Co 0.021 0.048 0.094 0.161 0.02 0.08 0.013 0.000 0.0 0.0 0.0 6.0 0.08 0.000 9.73 0.00 0.00
up 72192 93888 56854 31629 4479 1249 55337 10599 132 00 072 0E 2480 85898 E-05 309 193
on 7 5 039 92 8 801 30 934 - 88 3 893 271 
69 85 55 05 4 
43 
Pri 0.006 0.002 0.079 0.075 0.10 0.02 0.001 0.001 0.0 0.0 0.0 3.3 0.00 0.014 0.00 0.00 0.00
cin 58993 50041 6556 6525 6818 6287 10982 91084 008 01 014 9E 4796 40554 0339 030 297
g 3 9 795 112 9 2 465 76 800 - 793 1 79 567 906
Ta 68 79 65 05 7 3 
ble 27 
Pr 0.034 0.024 0.095 0.014 0.00 0.08 0.005 0.000 0.0 0.0 0.0 9.0 0.00 0.161 0.00 0.00 0.02
od 51763 45214 2573 95513 8279 2117 22711 23215 563 03 030 5E 9502 4817 2305 043 666
uct 5 4 616 74 8 2 592 16 672 - 688 698 611 924
Pa 28 52 28 05 8 9 
ge 53 
Sh 0.001 0.004 0.016 0.005 0.01 0.04 0.000 0.000 0.0 0.0 0.0 0.0 0.00 0.001 6.12 0.00 0.00
op 00847 66453 53029 67667 2975 9101 75217 36475 071 02 611 03 5802 51670 E-05 740 287
pin 1 3 4 9 872 23 1 6 605 06 751 80 624 2 864 440
g 89 04 8 17 4 4 
Ca 49 67 
rt 
Tip 0.020 0.021 0.004 0.001 0.00 0.02 0.005 8.95E 0.0 0.0 0.2 5.3 0.31 0.001 3.98 0.13 0.00
a 16737 95081 26350 29190 1461 2462 52359 -06 587 71 885 2E 4135 97970 E-05 596 328
Tip 7 9 5 2 774 184 4 244 40 469 - 9 4 803 211
03 73 2 05 7 
26 
65 
 
Tabla 3.15 Tabla de entrenamiento de AlexNet con 27 patrones (2) 
 
Compo Compo Compo Compo Compo Compo Compo Compo Cou Pricin Prod Shopp Tip a 
sición sición sición sición sición sición sición sición pon g uct ing Tip 
1-e 2-e 3-e 4-e 5-e 6-e 7-e 8-e Table Page Cart 
Compo 0.0012 0.0084 0.0002 0.0028 0.0002 0.0488 0.2125 0.0023 0.00 5.25E 0.011 0.0013 0.000
sición 22212 98555 15067 36069 29817 49013 0871 97288 032 -05 57643 70623 3645
1-s 37 7 82 
Compo 0.0084 0.0071 0.0028 0.0172 0.0060 0.0047 0.0019 0.0007 0.00 0.000 0.003 0.0002 0.000
sición 54538 16523 80617 3857 27459 00975 59268 81094 946 32591 75869 70088 3059
2-s 63 4 73 
Compo 0.0035 0.0241 0.0025 0.0128 0.0046 0.0009 0.0132 0.0073 0.00 0.003 0.000 0.0002 0.000
sición 02943 0948 1941 42772 44138 64578 75475 89479 027 51080 33671 24094 2649
3-s 95 9 1 11 
Compo 0.0067 0.0013 0.0102 0.0046 0.0180 0.0001 0.0050 0.0035 0.21 0.003 2.33E 0.0005 4.69E
sición 86767 24369 80787 37126 96015 64309 26802 97574 091 74797 -05 43934 -05 
4-s 72 1 
Compo 0.0089 0.0021 0.0463 0.0061 0.0133 0.0001 0.0029 0.0039 0.18 0.001 0.011 6.07E- 9.80E
sición 20413 99738 43703 63945 66538 43894 65571 7718 474 23871 57765 05 -06 
5-s 62 5 7 
Compo 0.0011 0.0035 0.0118 0.0008 0.0011 0.0037 0.0196 0.0002 0.00 6.69E 0.000 0.0013 1.14E
sición 11792 92488 72754 62901 86524 49183 87437 19391 074 -05 16704 41972 -05 
6-s 28 3 
Compo 0.0002 0.0003 0.0219 0.0030 0.0005 0.0489 0.0003 1.90E- 0.02 9.97E 1.10E 0.0002 9.471
sición 63427 32229 78298 96926 47146 09252 799 05 954 -05 -05 52415 82-07 
7-s 78 
Compo 0.0012 0.0087 0.0002 0.0004 0.0003 0.0011 0.0010 0.0003 0.00 0.000 0.002 0.0002 8.86E
sición 89974 72186 4078 73908 17529 3867 55921 83838 046 19493 55516 69062 -06 
8-s 92 3 3 
Chat 0.1686 0.0693 0.1240 0.0199 0.0178 0.0022 0.0307 0.0006 0.00 0.004 0.003 0.0012 0.006
8266 5984 7381 92307 09797 36657 5584 29054 824 79131 62118 5251 1703
97 3 2 76 
66 
 
Tabla 3.15 Tabla de entrenamiento de AlexNet con 27 patrones (2) 
 Compo Compo Compo Compo Compo Compo Compo Compo Cou Pricin Produ Shoppi Tip a 
sición sición sición sición sición sición sición sición pon g ct ng Tip 
1-e 2-e 3-e 4-e 5-e 6-e 7-e 8-e Table Page Cart 
Gall 0.03107 0.00646 0.00355 0.00667 0.0059 0.00512 0.00034 0.00010 9.50 0.009 0.1752 0.0004 0.196
ery 5047 7854 9057 2331 0452 0111 8792 5513 E- 0024 9613 20665 9991
05 9 
Pick 0.00255 0.00153 0.01884 0.00070 0.0050 0.00010 0.00066 8.02E- 0.04 0.000 1.01E- 0.0004 8.93E
er 2322 1312 6426 5575 27881 1329 649 05 171 74413 05 90869 -05 
74 1 
Pan 0.00056 0.00417 0.00052 0.00107 0.0008 0.00758 0.01061 0.00016 0.00 0.001 0.0013 0.0010 4.67E
el 2693 4547 7666 1659 39345 0689 434 6724 058 43321 97139 9801 -05 
38 7 
Co 0.00420 0.00507 0.02365 0.00094 0.0101 0.00141 0.00237 0.00013 0.00 0.000 7.76E- 0.0022 0.002
mm 3074 7907 4275 883 36013 5114 0329 232 790 22917 05 43017 5404
ent 52 2 76 
Me 0.00062 0.00909 0.00019 0.01173 0.0033 0.00745 0.00242 0.00516 0.00 0.042 0.0054 0.0012 0.000
nu 6785 5392 937 5376 38289 432 4878 0174 014 05263 27169 1245 2363
hori 23 8 73 
zont
al 
Me 0.00014 0.00444 5.02E- 0.00278 0.0002 0.02512 0.02092 0.00458 9.37 0.000 0.0024 0.0001 1.89E
nu 3034 3634 05 95 30323 6405 0135 4726 E- 42846 89994 3683 -05 
vert 05 3 
ical 
Mus 0.00235 0.00339 0.00151 0.00106 0.0045 0.00056 0.00214 4.03E- 4.23 0.000 0.0003 0.0009 0.001
ic 1448 9683 6045 3561 4646 8046 2363 05 2E- 46951 09979 00845 0711
play 05 7 2 
er 
 
67 
 
Tabla 3.15 Tabla de entrenamiento de AlexNet con 27 patrones (2) 
 Compo Compo Compo Compo Compo Compo Compo Comp Cou Pricin Produ Shoppi Tip a 
sición sición sición sición sición sición sición osició pon g ct ng Tip 
1-e 2-e 3-e 4-e 5-e 6-e 7-e n 8-e Table Page Cart 
Ran 0.00066 0.00233 0.00053 0.00119 0.00028 0.00064 0.00019 1.14E- 0.00 0.0083 0.0050 0.0003 0.001
king 0585 7842 3077 4976 9639 6346 3118 05 0470 86015 01901 70232 8218
1 08 
Co 0 0.08202 0.01079 0.05539 0.01186 0.05525 0.01737 0.0007 0.00 0.0015 0.0283 0.0004 0.003
mpo 814 4097 7544 005 4135 3513 51836 0119 65359 98156 93001 9231
sició 9 69 
n 1-
e 
Co 0.01120 0 0.00438 0.01322 0.02722 0.00793 0.00593 0.0001 0.00 0.0026 0.0298 0.0001 0.001
mpo 3741 4674 0945 5675 0527 4994 47061 3509 74006 6511 114 0461
sició 4 89 
n 2-
e 
Co 0.00193 0.01278 0 0.00860 0.00300 0.00054 0.00627 0.0039 0.00 0.0029 0.0002 0.0001 0.000
mpo 9175 5941 987 8344 6343 8422 43317 0144 84697 6868 93247 1826
sició 2 18 
n 3-
e 
Co 0.00617 0.00146 0.00977 0 0.01848 0.00017 0.00589 0.0036 0.10 0.0039 2.31E- 0.0005 5.05E
mpo 0199 8711 3295 7513 3705 0452 60766 0617 63298 05 34539 -05 
sició 7 
n 4-
e 
 
 
 
68 
 
Tabla 3.15 Tabla de entrenamiento de AlexNet con 27 patrones (2) 
 Compo Compo Compo Compo Com Comp Compo Compo Cou Pricing Produ Shoppi Tip 
sición sición sición sición posi osición sición sición pon Table ct ng a 
1-e 2-e 3-e 4-e ción 6-e 7-e 8-e Page Cart Tip 
5-e 
Co 0.00618 0.00154 0.02748 0.00444 0 9.05E- 0.00156 0.00301 0.14 0.0012 1.71E 0.00142 7.06
mpo 9026 7917 1943 096 05 5817 4107 2279 10387 -06 4923 E-06 
sició 6 
n 5-
e 
Co 0.00182 0.00577 0.01917 0.00148 0.00 1 0.02865 0.00030 0.00 0.0001 0.000 0.00127 2.00
mpo 0942 3742 6602 9398 1695 2415 191 0994 07239 24273 3446 E-05 
sició 659 4 9 
n 6-
e 
Co 0.00230 0.01128 0.00120 0.03987 0.00 0.2687 0 0.00049 0.00 0.0002 0.012 0.00330 0.00
mpo 7526 3241 4547 8763 5167 211 5149 0708 8401 81516 0189 0219
sició 937 3 4 851 
n 7-
e 
Co 0.03498 0.02021 0.02193 0.26377 0.15 0.0026 0.03144 1 0.00 0.0012 1.60E 0.00016 5.43
mpo 1206 6295 2047 65 1382 49222 8323 1253 40397 -05 1003 E-05 
sició 8 5 
n 8-
e 
Cou 0.11141 0.06242 0.18111 0.01644 0.16 0.0037 0.00125 0.00038 0 0.0151 0.002 0.00057 0.00
pon 771 381 774 7896 4633 87947 288 7939 8501 38481 7009 1039
14 3 606 
 
 
69 
 
Tabla 3.15 Tabla de entrenamiento de AlexNet con 27 patrones (2) 
 Compo Compo Compos Compo Compos Compos Compos Compo Cou Pric Produ Shoppi Tip 
sición sición ición 3- sición ición 5- ición 6- ición 7- sición pon ing ct ng a 
1-e 2-e e 4-e e e e 8-e Tab Page Cart Tip 
le 
Pric 0.01390 0.04128 0.00327 0.10608 0.00981 0.00029 0.00519 0.19870 0.00 0 6.36E- 0.00292 6.34
ing 6231 359 6981 325 0957 8047 3083 315 1056 05 8054 E-05 
Tab 9 
le 
Pro 0.03100 0.08600 0.00494 0.00444 0.08930 0.00825 0.00954 0.00287 0.00 0.04 0 0.00260 0.00
duc 0808 34 0166 4527 9745 8119 0436 7597 0814 069 5956 2674
t 5 454 726 
Pag 2 
e 
Sho 0.00341 0.00441 0.00624 0.00126 0.00299 0.00298 0.21376 0.00283 0.00 0.00 0.001 1 0.00
ppi 6761 7317 7829 6395 8278 3385 601 8019 0520 184 19871 0711
ng 1 918 3 557 
Car 8 
t 
Tip 0.08044 0.04718 0.00129 0.08085 0.06581 0.04638 0.03645 0.00185 0.01 0.00 0.016 0.00483 1 
a 1624 3674 5769 692 27 522 029 8326 0740 719 11805 4933 
Tip 1 679 5 
4 
 
 
Debido a la baja precisión que se obtienen como resultado en las últimas pruebas de AlexNet se diseñó un nuevo modelo llamado 
Inception con la versión 3 que reducen principalmente el margen de error, esto permite mejorar los resultados derivados en AlexNet.
70 
 
3.4.1.3.Entrenamiento con Inception_v3  
Inception_v3, red neuronal convolucional modular se implementó con la API TensorFlow 
1.14, Keras 2.2.5 y Anaconda 1.9.6 junto con la versión de Spyder 3.6. La red es ganadora 
del reto ImageNet 2014, esta red proporciona una mejoría con respecto a AlexNet. Además, 
la red cuenta con 22 capas profundas, esto es 8 capas más que AlexNet. Tiene mejor 
eficiencia con respecto al poder computacional, casi dos veces menor al proceso en AlexNet, 
una mayor precisión, menor uso de la memoria, contiene menos parámetros, es muy usada 
para dispositivos móviles, además de ser modular, permite escoger automáticamente el 
kernel convolucional y mejorar el poder computacional. La red usa filtros de reducción de 
dimensiones de capas convolucionales 1*1 para convertir automáticamente una imagen RGB 
de 256*256*3 a 256*256*1, además viene acompañado de capas convolucionales de 3*3, 
5*5 y de 7*7 dependiendo la elección del kernel convolucional, al final se aplica Max-
Pooling para mejorar los filtros de los algoritmos (ver Fig 3.23).  
 
 Filtro 
 
 
Convolución 1x1 Convolución 3x3 Convolución 5x5 Convolución 1x1 
 
 
Convolución 1x1 Convolución 1x1 Max-Pooling 1x1 
 
 
Capa 
 convolucional 
 
Fig. 3.23 Arquitectura de la red neuronal convolucional Inception_v3 
A razón de obtener el mejor desempeño de las redes neuronales convolucionales se detallaron 
diferentes pruebas, ya que representan diferentes arquitecturas por lo que los resultados y el 
71 
 
desempeño cambia. A continuación, se describen las pruebas realizadas y los resultados obtenidos. 
Prueba 1: En esta prueba se utilizaron 9 patrones con 200 imágenes cada uno con un total de 1800 instancias. En la Tabla 3.16, se 
registran los resultados obtenidos del entrenamiento con una configuración de 500 bach, un total de 100 épocas y un tiempo de 
entrenamiento de 6.3 horas, da una precisión de 88%. El objetivo de realizar esta prueba en la red neuronal convolucional de 
Inception_V3 es observar el comportamiento con respecto a AlexNet, los resultados obtenidos verifican que tiene la misma taza de error 
que la prueba 1 de AlexNet, los valores marcados en rojo son las precisiones correctas basados en encontrarse en los primeros cuatro 
lugares más cercanos a 100%. 
 
Tabla 3.33 Resultados de Entrenamiento para Inception_V3 con 9 patrones y 200 instancias c/u 
 
Chat Comment Gallery Menu- Menu- Music Panel Picker Ranking 
horizontal vertical player 
Chat 1 0.16358 0.04076 0.10806 0.06382 0.01578 0.15495 0.14627 0.08844 
Comment 0.03356 1 0.03502 0.01721 0.03612 0.04643 0.13155 0.12357 0.07479 
Gallery 0.03578 0.11136 1 0.07059 0.03841 0.02072 0.02647 0.11297 0.22975 
Menu- 0.05365 0.0202 0.0357 1 0.0262 0.00527 0.04673 0.04739 0.50558 
horizontal 
Menu- 0.02378 0.07978 0.12727 0.09396 0 0.02127 0.13903 0.11171 0.30199 
vertical 
Music 0.00811 0.62126 0.04349 0.00424 0.0149 1 0.09181 0.07292 0.03582 
player 
Panel 0.07911 0.32926 0.05673 0.08863 0.1117 0.02002 1 0.11249 0.08259 
Picker 0.0317 0.3057 0.09098 0.04878 0.02888 0.01698 0.0281 1 0.04972 
Ranking 0.05903 0.12544 0.0694 0.0685 0.06121 0.01539 0.05159 0.15177 1 
72 
 
Prueba 2: En esta prueba se utilizaron 9 patrones con 400 imágenes cada uno con un total de 3800 imágenes. En la Tabla 3.17 se registran 
los resultados obtenidos del entrenamiento con una configuración de 500 bach, un total de 100 épocas y un tiempo de entrenamiento de 
8.7 horas, da una precisión de 100%. Como objetivo principal de esta prueba es comparar los resultados con respecto a la anterior prueba 
de este modelo y del modelo con AlexNet. Es importante resaltar que en esta prueba se obtuvo una precisión del 100% con respecto a 
AlexNet, otro punto a resaltar es que se usó el proceso de transformación de la imagen. 
 
Tabla 3.34 Tabla de entrenamiento para Inception_V3 con 9 patrones y 400 instancias c/u 
 
Chat Comment Gallery Menu- Menu- Music Panel Picker Ranking 
horizontal vertical player 
Chat 1.0000 0.1099 0.0154 0.0741 0.1613 0.0248 0.3284 0.0428 0.1255 
Comment 0.0110 1.0000 0.0202 0.0168 0.1982 0.0830 0.1502 0.0620 0.0327 
Gallery 0.0209 0.0703 1.0000 0.0183 0.0493 0.0156 0.0414 0.0239 0.6514 
Menu- 0.0379 0.0077 0.0124 1.0000 0.0734 0.0155 0.0566 0.0130 0.4272 
horizontal 
Menu- 0.0128 0.0435 0.0368 0.0382 1.0000 0.0198 0.3943 0.0196 0.2611 
vertical 
Music 0.0037 0.5016 0.0189 0.0021 0.0456 1.0000 0.1216 0.0299 0.0260 
player 
Panel 0.0222 0.0710 0.0090 0.0266 0.1887 0.0149 1.0000 0.0115 0.0317 
Picker 0.0067 0.3957 0.0251 0.0357 0.1394 0.0459 0.0441 1.0000 0.0219 
Ranking 0.0463 0.0519 0.0267 0.0168 0.0712 0.0144 0.1262 0.0308 1.0000 
 
 
73 
 
Prueba 3: En esta prueba se utilizaron 17 patrones con 400 imágenes cada uno, cuenta con un total de 6800 instancias en total. En la 
Tabla 3.18 se registran los resultados obtenidos del entrenamiento con una configuración de 500 bach, un total de 100 épocas y un tiempo 
de entrenamiento de 17.3 horas, da una precisión de 83%. Con respecto a AlexNet y se observa que a pesar de que se aumentaron los 
UIDPs  la precisión no fue tan negativa con respecto a AlexNet, esto es por la disminución de errores que existe con la red neuronal de 
Inception_v3, por lo tanto se menciona que la prueba resalta una buena precisión con respecto a AlexNet. 
 
Tabla 3.35 Tabla de entrenamiento para Inception_V3 con 17 patrones y 400 instancias c/u (1) 
 
Chat Comment Gallery Menu- Menu- Music player Panel Picker 
horizontal vertical 
Chat 0.00000 0.08880 0.01870 0.05369 0.10847 0.02138 0.18422 0.03406 
Comment 0.01160 1.00000 0.02795 0.01246 0.10337 0.07369 0.11080 0.05399 
Gallery 0.02634 0.07821 1.00000 0.02130 0.04466 0.02238 0.04868 0.02750 
Menu- 0.04045 0.01183 0.01511 1.00000 0.06968 0.01361 0.05984 0.01513 
h orizontal 
Menu- 0.01634 0.04984 0.03953 0.03876 1.00000 0.02447 0.29296 0.02329 
 vertical 
Music 0.00430 0.46879 0.03094 0.00195 0.03220 1.00000 0.10284 0.03282 
 player 
Panel 0.01786 0.06664 0.01285 0.02054 0.11705 0.01557 1.00000 0.01199 
Picker 0.00648 0.25056 0.03011 0.01811 0.07232 0.04055 0.03278 1.00000 
74 
 
 
Tab.3.18 Tabla de entrenamiento para Inception_V3 con 17 patrones y 400 instancias c/u (2) 
 
Ranking smcompos smcompos smcompos smcompos smcompos smcompos smcompos smcompos
icion1 icion2 icion3 icion4 icion5 icion6 icion7 icion8 
Ranking 1.00000 0.03395 0.01339 0.00869 0.00784 0.01237 0.03815 0.01903 0.01710 
smcompos 0.21545 1.00000 0.04459 0.02661 0.01480 0.01628 0.04332 0.02547 0.02157 
icion1 
smcompos 0.07749 0.09150 0.00000 0.00996 0.01944 0.05044 0.08482 0.08136 0.04509 
icion2 
smcompos 0.02678 0.07313 0.07401 1.00000 0.02536 0.03803 0.04841 0.06709 0.02168 
icion3 
smcompos 0.03589 0.03395 0.01339 0.00869 1.00000 0.01237 0.03815 0.01903 0.01710 
icion4 
smcompos 0.21545 0.01911 0.04459 0.02661 0.01480 1.00000 0.04332 0.02547 0.02157 
icion5 
smcompos 0.07749 0.09150 0.02168 0.00996 0.01944 0.05044 0.00000 0.08136 0.04509 
icion6 
smcompos 0.49122 0.02814 0.01520 0.01650 0.00578 0.00793 0.02172 1.00000 0.00848 
icion7 
smcompos 0.34856 0.02146 0.02168 0.04673 0.01455 0.00659 0.00672 0.00755 1.00000 
icion8 
75 
 
Prueba 4: En esta prueba se utilizaron 27 patrones con 400 imágenes cada uno por lo tanto da un total de 10,800 imágenes. En la Tabla 
3.19 se registran los resultados obtenidos del entrenamiento con una configuración de 500 bach, un total de 100 épocas y con un tiempo 
de entrenamiento de 34.3 horas, da una precisión de 74%. Para esta prueba 4 se observan varios detalles, una excelente mejora con 
respecto a la misma cantidad entrenada en el modelo AlexNet, ya que a pesar de que se cuentan con la misma cantidad de imágenes para 
cada UIDP la precisión se sigue manteniendo con respecto a la tercera prueba generada en Inception_v3. Por lo tanto, esta red funciona 
mucho mejor con respecto a AlexNet. 
 
Tabla 3.36 Tabla de entrenamiento de Inception_v3 con 27 patrones (1) 
 
Ch Com Gal Menu- Menu- Music Pa Pic Ran smcom smcom smcom smcom smcom
at men ler horizon vertica player nel ker kin posicio posicio posicio posicio posicio
t y tal l g n1 n2 n3 n4 n5 
Chat 0.0 0.08 0.0 0.05369 0.1084 0.0213 0.1 0.0 0.10 0.03590 0.02242 0.01740 0.01664 0.02940 
000 880 187 7 8 842 340 925 
0 0 2 6 
Comme 0.0 1.00 0.0 0.01246 0.1033 0.0736 0.1 0.0 0.03 0.03761 0.05748 0.01738 0.02065 0.03676 
nt 116 000 279 7 9 108 539 768 
0 5 0 9 
Gallery 0.0 0.07 1.0 0.02130 0.0446 0.0223 0.0 0.0 0.49 0.02814 0.01520 0.01650 0.00578 0.00793 
263 821 000 6 8 486 275 122 
4 0 8 0 
Menu- 0.0 0.01 0.0 1.00000 0.0696 0.0136 0.0 0.0 0.34 0.02146 0.02168 0.04673 0.01455 0.00659 
horizon 404 183 151 8 1 598 151 856 
tal 5 1 4 3 
Menu- 0.0 0.04 0.0 0.03876 1.0000 0.0244 0.2 0.0 0.21 0.04172 0.02214 0.01202 0.00559 0.00696 
vertical 163 984 395 0 7 929 232 972 
4 3 6 9 
 
76 
 
Tabla 3.37 Tabla de entrenamiento de Inception_v3 con 27 patrones (1) 
 
Ch Com Gall Menu- Menu- Music Pan Pick Ran smcom smcom smcom smcom smcom
at ment ery horizon vertica player el er king posicio posicio posicio posicio posicio
tal l n1 n2 n3 n4 n5 
Musi 0.00 0.468 0.03 0.00195 0.0322 1.0000 0.10 0.03 0.035 0.01911 0.01268 0.01018 0.00370 0.00528 
c 430 79 094 0 0 284 282 89 
playe
r 
Pane 0.01 0.066 0.01 0.02054 0.1170 0.0155 1.00 0.01 0.038 0.08717 0.02580 0.00922 0.01193 0.01810 
l 786 64 285 5 7 000 199 60 
Pick 0.00 0.250 0.03 0.01811 0.0723 0.0405 0.03 1.00 0.026 0.07313 0.07401 0.01405 0.02536 0.03803 
er 648 56 011 2 5 278 000 78 
Ran 0.04 0.062 0.03 0.01912 0.0656 0.0183 0.11 0.03 1.000 0.03395 0.01339 0.00869 0.00784 0.01237 
king 418 47 536 9 7 153 441 00 
smco 0.01 0.097 0.04 0.04408 0.1166 0.0401 0.07 0.02 0.215 1.00000 0.04459 0.02661 0.01480 0.01628 
mpos 727 31 375 1 9 989 728 45 
icion
1 
smco 0.01 0.019 0.00 0.04201 0.3107 0.0040 0.07 0.01 0.077 0.09150 0.00000 0.00996 0.01944 0.05044 
mpos 415 71 689 4 8 559 574 49 
icion
2 
smco 0.00 0.250 0.03 0.01811 0.0723 0.0405 0.03 0.03 0.026 0.07313 0.07401 1.00000 0.02536 0.03803 
mpos 648 56 011 2 5 278 282 78 
icion
3 
 
 
 
77 
 
Tabla 3.38 Tabla de entrenamiento de Inception_v3 con 27 patrones (1) 
 
Cha Com Gall Menu Menu- Music Pan Pick Ran smcom smcom smcom smcom smcom
t ment ery - vertica player el er king posicio posicio posicio posicio posicio
horiz l n1 n2 n3 n4 n5 
ontal 
smco 0.04 0.062 0.03 0.019 0.0656 0.0183 0.11 0.03 0.035 0.03395 0.01339 0.00869 1.00000 0.01237 
mpos 418 47 536 12 9 7 153 441 89 
icion
4 
smco 0.01 0.097 0.04 0.044 0.1166 0.0401 0.07 0.02 0.215 0.01911 0.04459 0.02661 0.01480 1.00000 
mpos 727 31 375 08 1 9 989 728 45 
icion
5 
smco 0.01 0.019 0.00 0.042 0.3107 0.0040 0.07 0.01 0.077 0.09150 0.02168 0.00996 0.01944 0.05044 
mpos 415 71 689 01 4 8 559 574 49 
icion
6 
smco 0.02 0.078 0.01 0.021 0.0446 0.0223 0.04 0.02 0.491 0.02814 0.01520 0.01650 0.00578 0.00793 
mpos 634 21 971 30 6 8 868 750 22 
icion
7 
smco 0.04 0.011 0.01 0.059 0.0696 0.0136 0.05 0.01 0.348 0.02146 0.02168 0.04673 0.01455 0.00659 
mpos 045 83 511 84 8 1 984 513 56 
icion
8 
mco 0.03 0.011 0.11 0.076 0.0467 0.0479 0.07 0.04 0.076 0.27643 0.08840 0.05869 0.37675 0.03975 
mpos 212 54 234 80 0 8 619 758 86 
icion
1 
 
78 
 
Tabla 3.39 Tabla de entrenamiento de Inception_v3 con 27 patrones (1) 
 Ch Com Gall Menu- Menu- Music Pan Pick Ran smcom smcom smcom smcom smcom
at ment ery horizon vertica player el er king posicio posicio posicio posicio posicio
tal l n1 n2 n3 n4 n5 
mco 0.06 0.094 0.01 0.00645 0.0616 0.1464 0.01 0.01 0.075 0.01647 0.04166 0.04657 0.33254 0.05627 
mpo 322 62 658 5 7 277 640 60 
sicio
n2 
mco 0.01 0.124 0.09 0.02430 0.0246 0.0496 0.04 0.01 0.045 0.03266 0.06580 0.11341 0.00994 0.05846 
mpo 549 57 158 8 8 616 649 73 
sicio
n3 
mco 0.00 0.099 0.06 0.03417 0.0781 0.0677 0.01 0.01 0.076 0.06434 0.05400 0.08601 0.05791 0.02180 
mpo 564 15 514 6 9 654 976 78 
sicio
n4 
mco 0.01 0.046 0.00 0.04457 0.0967 0.1467 0.01 0.01 0.031 0.04357 0.04786 0.02712 0.07024 0.08668 
mpo 225 65 646 9 3 776 550 64 
sicio
n5 
mco 0.04 0.087 0.08 0.01677 0.0746 0.0464 0.07 0.05 0.016 0.04677 0.05639 0.01335 0.05651 0.08636 
mpo 887 85 910 1 7 914 476 47 
sicio
n6 
mco 0.00 0.115 0.01 0.01247 0.0769 0.0467 0.06 0.04 0.016 0.04677 0.03833 0.00751 0.08764 0.08894 
mpo 781 48 345 1 7 477 973 79 
sicio
n7 
 
 
79 
 
Tabla 3.40 Tabla de entrenamiento de Inception_v3 con 27 patrones (1) 
 
Ch Com Gall Menu- Menu- Music Pan Pick Ran smcom smcom smcom smcom smcom
at ment ery horizon vertica player el er king posicio posicio posicio posicio posicio
tal l n1 n2 n3 n4 n5 
mco 0.0 0.048 0.04 0.07799 0.0464 0.0167 0.01 0.09 0.015 0.06756 0.00107 0.06474 0.04630 0.06451 
mpos 004 79 676 5 5 967 183 76 
icion 6 
8 
mco 0.0 0.080 0.01 0.05167 0.0349 0.0479 0.01 0.01 0.046 0.05397 0.03068 0.07057 0.06276 0.03966 
mpos 095 89 654 7 6 673 640 42 
icion 5 
9 
mco 0.0 0.007 0.03 0.03467 0.0154 0.0467 0.01 0.01 0.016 0.03202 0.00305 0.01691 0.04940 0.06432 
mpos 233 80 255 6 5 460 676 46 
icion 5 
10 
 
Tabla 3.19 Tabla de entrenamiento de Inception_v3 con 27 patrones (2) 
 
smcom smcom smcom mcom mcom mcom mcom mcom mcom mcom mcom mcom mcomp
posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio osicion
n6 n7 n8 n1 n2 n3 n4 n5 n6 n7 n8 n9 10 
Cha 0.0585 0.0601 0.0534 0.0876 0.0012 0.0268 0.0567 0.0713 0.0596 0.0258 0.0493 0.0395 0.0760
t 1 9 8 5 1 7 9 2 4 5 1 2 4 
Co 0.0283 0.0568 0.0174 0.0057 0.0930 0.0028 0.0178 0.0562 0.0619 0.0412 0.0078 0.0213 0.0953
mm 2 9 9 8 6 4 9 8 5 5 9 2 6 
ent 
Gall 0.0217 0.0120 0.0084 0.0460 0.0673 0.0099 0.0448 0.0203 0.0366 0.0687 0.0773 0.0397 0.0920
ery 2 5 8 3 4 7 8 6 5 5 4 7 3 
 
80 
 
Tabla 3.19 Tabla de entrenamiento de Inception_v3 con 27 patrones (2) 
 
smcom smcom smcom mcom mcom mcom mcom mcom mcom mcom mcom mcom mcom
posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio
n6 n7 n8 n1 n2 n3 n4 n5 n6 n7 n8 n9 n10 
Men 0.0067 0.0075 0.0620 0.0885 0.0864 0.0277 0.0170 0.0024 0.0700 0.0306 0.0746 0.0313 0.0027
u- 2 5 5 0 7 1 0 6 3 7 8 2 6 
hori
zont
al 
Men 0.0345 0.0204 0.0117 0.0630 0.0648 0.0394 0.0730 0.0834 0.0034 0.0094 0.0773 0.0232 0.0758
u- 0 4 4 0 4 7 6 3 1 6 2 1 9 
verti
cal 
Musi 0.0116 0.0106 0.0072 0.0943 0.0426 0.0069 0.0038 0.0167 0.0156 0.0063 0.0226 0.0263 0.0471
c 0 0 5 7 2 9 9 3 2 2 3 6 8 
play
er 
Pane 0.1465 0.0734 0.0305 0.0980 0.0106 0.0564 0.0262 0.0636 0.0276 0.0973 0.0304 0.0508 0.0388
l 8 4 0 1 1 4 2 8 9 7 0 2 6 
Pick 0.0484 0.0670 0.0216 0.0238 0.0144 0.0066 0.0192 0.0599 0.0990 0.0514 0.0647 0.0941 0.0460
er 1 9 8 4 0 1 4 5 4 6 7 4 9 
Ran 0.0381 0.0190 0.0171 0.0734 0.0887 0.0065 0.0960 0.0657 0.0146 0.0271 0.0691 0.0776 0.0067
king 5 3 0 4 0 8 8 1 2 3 3 8 9 
smco 0.0433 0.0254 0.0215 0.0249 0.0163 0.0748 0.0129 0.0506 0.0674 0.0542 0.0638 0.0049 0.0304
mpo 2 7 7 6 2 3 8 5 9 0 8 4 0 
sicio
n1 
smco 0.0848 0.0813 0.0450 0.0876 0.0585 0.0678 0.0622 0.0060 0.0955 0.0605 0.0244 0.0283 0.0137
mpo 2 6 9 5 4 7 2 1 6 2 5 5 6 
sicio
n2 
81 
 
Tabla 3.19 Tabla de entrenamiento de Inception_v3 con 27 patrones (2) 
 smcom smcom smcom mcom mcom mcom mcom mcom mcom mcom mcom mcom mcom
posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio
n6 n7 n8 n1 n2 n3 n4 n5 n6 n7 n8 n9 n10 
smc 0.0484 0.0670 0.0216 0.0465 0.0823 0.0379 0.0263 0.0741 0.0487 0.0842 0.0418 0.0688 0.0154
omp 1 9 8 4 8 9 1 4 3 9 2 9 0 
osici
on3 
smc 0.0381 0.0190 0.0171 0.0315 0.0172 0.0494 0.0336 0.0838 0.0525 0.0168 0.0787 0.0302 0.0701
omp 5 3 0 0 6 0 4 4 0 9 1 2 9 
osici
on4 
smc 0.0433 0.0254 0.0215 0.0433 0.0465 0.0309 0.0080 0.0851 0.0450 0.0776 0.0025 0.0801 0.0571
omp 2 7 7 3 1 6 9 1 0 5 5 4 3 
osici
on5 
smc 0.0000 0.0813 0.0450 0.0958 0.0607 0.0734 0.0557 0.0132 0.0343 0.0759 0.1404 0.0317 0.0140
omp 0 6 9 2 9 4 6 2 7 9 0 0 7 
osici
on6 
smc 0.0217 1.0000 0.0084 0.0453 0.0714 0.0120 0.0301 0.0815 0.0701 0.0231 0.0579 0.0692 0.0772
omp 2 0 8 9 4 0 3 8 5 4 1 3 5 
osici
on7 
smc 0.0067 0.0075 0.0000 0.0839 0.0489 0.0601 0.0150 0.0906 0.0823 0.0583 0.0788 0.0824 0.0044
omp 2 5 0 9 1 6 9 1 6 9 8 3 8 
osici
on8 
 
 
82 
 
Tabla 3.19 Tabla de entrenamiento de Inception_v3 con 27 patrones (2) 
 smcom smcom smcom mcom mcom mcom mcom mcom mcom mcom mcom mcom mcom
posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio
n6 n7 n8 n1 n2 n3 n4 n5 n6 n7 n8 n9 n10 
mco 0.0174 0.0502 0.0878 1.0000 0.0275 0.0028 0.0147 0.0392 0.0744 0.0721 0.0386 0.0442 0.0959
mpo 3 2 8 0 1 4 0 5 5 0 4 6 4 
sicio
n1 
mco 0.0048 0.0589 0.0516 0.0764 1.0000 0.0914 0.0835 0.0355 0.0115 0.0313 0.0931 0.0667 0.0998
mpo 6 3 8 6 0 1 6 7 8 1 3 8 1 
sicio
n2 
mco 0.0266 0.0507 0.0394 0.0596 0.0570 1.0000 0.0931 0.0907 0.0586 0.0353 0.0976 0.0295 0.0263
mpo 1 8 7 1 8 0 0 7 8 0 6 2 5 
sicio
n3 
mco 0.4346 0.0364 0.1143 0.0923 0.0227 0.0477 1.0000 0.0180 0.0092 0.0053 0.0461 0.0469 0.0920
mpo 3 1 9 6 8 5 0 8 4 7 2 1 1 
sicio
n4 
mco 0.0695 0.0522 0.0049 0.0821 0.0681 0.0235 0.0458 1.0000 0.0808 0.0709 0.0912 0.2673 0.0504
mpo 7 1 1 9 0 2 0 0 4 0 9 1 6 
sicio
n5 
mco 0.0902 0.0613 0.0638 0.0938 0.0319 0.0079 0.0442 0.0900 0.0000 0.0635 0.0109 0.0251 0.0807
mpo 5 8 8 5 2 9 2 7 0 0 6 9 4 
sicio
n6 
 
 
83 
 
Tabla 3.19 Tabla de entrenamiento de Inception_v3 con 27 patrones (2) 
 smcom smcom smcom mcom mcom mcom mcom mcom mcom mcom mcom mcom mcom
posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio posicio
n6 n7 n8 n1 n2 n3 n4 n5 n6 n7 n8 n9 n10 
mco 0.0477 0.0650 0.0428 0.0450 0.0381 0.0988 0.0089 0.0666 0.0824 1.0000 0.0856 0.0739 0.0815
mpo 7 1 8 2 0 4 8 9 1 0 0 6 0 
sicio
n7 
mco 0.0123 0.0255 0.0652 0.0741 0.0946 0.0640 0.0859 0.0619 0.0958 0.0938 0.0000 0.0378 0.0791
mpo 0 2 8 7 9 2 4 5 3 3 0 7 4 
sicio
n8 
mco 0.0227 0.2166 0.0078 0.0631 0.0055 0.0604 0.0096 0.0026 0.0808 0.1442 0.0089 1.0000 0.0074
mpo 2 2 8 1 4 6 4 5 9 1 1 0 7 
sicio
n9 
mco 0.0653 0.0215 0.0399 0.0243 0.0878 0.0943 0.0294 0.0063 0.0165 0.0141 0.0894 0.0685 0.0000
mpo 1 7 1 2 6 0 3 8 8 9 7 4 0 
sicio
n10 
 
En conclusión, se observa que en las diferentes pruebas los datos que cambian son: la cantidad de patrones y el número de instancias. 
Respecto a las primeras pruebas los resultados obtenidos determinaron el correcto funcionamiento de la red neuronal convolucional y se 
garantizó una adecuada clasificación, con lo que se obtuvo un margen de referencia que permitió ampliar la investigación y abrir la 
oportunidad para crear un nuevo estándar o enfoque para el desarrollo de software. Lo anterior, considera que el tiempo promedio de 
respuesta es menor a 60 segundos. Con tal resultado se observó claramente el impacto que genera una red neuronal convolucional para 
la clasificación de imágenes. 
84 
 
Respecto a los datos obtenidos con la red convolucional Inception_V3 se observa una mejoría 
en la clasificación de imágenes con un mínimo de 30.7% más en comparación con AlexNet. 
Además, Inception_v3 tiene una mejoría clara con respecto a su margen de error de 6.67% 
con respecto a AlexNet que cuenta con un 15.3%, la respuesta notable de Inception_V3 es 
de 18% en comparación con AlexNet. Cabe señalar que la implementación de la API Keras 
facilita la programación al contar con módulos de funciones predefinidos. Otro punto a 
considerar es el uso computacional, en Inception_v3 es menor que en AlexNet, se utiliza 
menos recursos de memoria y genera un porcentaje de respuesta más rápido que AlexNet 
conforme a la clasificación. Por otra parte, Inception_v3 cuenta con un mayor soporte a la 
comunidad por ser un modelo más reciente y usado por los científicos. 
 
3.5.Implementación del módulo del procesamiento 
En este punto se describen detalles importantes de la red neuronal convolucional, se 
especifican los diagramas de clase y el código referente a sus funciones principales. 
 
3.5.1. Diagramas de clases 
Para los diagramas de clases se dividen en dos partes: entrenamiento y su exportación, y 
diagrama de ejecución del servicio REST. En la Fig. 7 se presenta el modelo de Inpcetion_V3 
que parte del entrenamiento, donde se observan las diferentes clases tales como: 
EntrenamientoCNN, encargada principalmente de cargar componentes de la red neuronal 
y atributos que se necesitan para manipular y generar un modelo adecuado de entrenamiento. 
Keras, numpy, tensorflow y pyplot son clases que cargan diferentes métodos. En el caso de 
Keras cuenta con los métodos de: inceptionv3 (), activation (), BGD (), 
Dropout (), Flatter () y Dense (), métodos esenciales para el entrenamiento 
de la red.  La clase Transformación importa las clases de cv2, os y sys, además cuenta con 
los métodos de rgb2gray () que solicitan una variable de tipo rgb y leet (). La clase 
ExportarModelo encargada principalmente en generar un modelo basado en keras, un 
archivo del modelo generado el cual se aprovecha para cargar en un servidor, cuenta con las 
clases de tensorflow y numpy para su implementación, cuenta con atributos especiales de 
85 
 
carga del nombre del modelo, la firma generada del modelo, dirección de la exportación y el 
constructor del modelo (ver Fig. 3.24).  
 
 
Fig. 3.24 Diagrama de clases para el entrenamiento 
 
Para el diagrama de clase de servidor encargado específicamente para ejecutar el servicio y 
transformar la instancia cada vez que se solicita la implementación del servicio.  
En la clase Run_server contiene el atributo app y el método image_classifier, 
además se importan diferentes clases de keras, flask, base64, json, io, numpy y request. Se 
cargan los métodos especiales de Inpcetionv3, image, flask y jsonify y BytesIO 
(ver Fig. 3.25). 
 
86 
 
 
Fig. 3.25 Diagrama de clases para cargar el servicio REST 
 
3.5.2. Funcionalidades principales 
En este punto se describen clases importantes del funcionamiento de la red neuronal 
convolucional, compuesto por la clase Entrenamiento.py. En este sentido, el método 
rgb2gray() se encarga principalmente de obtener el arreglo de la imagen, el método 
leet() es el encargado de leer todas las carpetas del conjunto de los datos, una vez que lee 
cada carpeta inicia la creación de una nueva carpeta que contiene  un nuevo conjunto de 
imágenes, genera una nueva matriz conforme a los algoritmos de dilatación, medianBlur, 
normalización y otsu, guarda los archivos en la nueva carpeta e imprime los resultados de 
cada transformación de la imagen (ver Listado de código. 3.1) 
 
Listado de código. 3.1 Clase Transformacion.py 
1. *- coding: utf-8 -*- 
2.   
3. """ 
4. Created on Wed Aug 28 11:47:42 2019 
5. @author: aaron 
6. """ 
7.   
8. import os 
9. import sys 
10. import cv2 
11. import numpy as np 
12.   
87 
 
13. class Transformacion : 
14. def rgb2gray(rgb): 
15.     return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]) 
16.   
17. def leet(): 
18.     try: 
19.         dir_datos  = str(sys.argv[1].rstrip('/'))  #Dirección 
20.         tam_img   = str(sys.argv[2]) 
21.         dir_datos_finales  = str(sys.argv[3].rstrip('/')) #Salida del directorio 
22.         print ("Inicia") 
23.         print ("Conjunto de datos en  %s " % dir_datos) 
24.         tclass = [ d for d in os.listdir( dir_datos ) ] 
25.         contador = 0 
26.         for x in tclass: 
27.            list_dir =  os.path.join(dir_datos, x ) 
28.            list_tuj = os.path.join(dir_datos_finales+'/', x+'/') 
29.             
30.            if not os.path.exists(list_tuj): 
31.                 os.makedirs(list_tuj) 
32.            if os.path.exists(list_tuj): 
33.                for i in os.listdir(list_dir): 
34.                    try: 
35.                        print ("entra") 
36.                        img = cv2.imread(os.path.join(input_dir+'/'+x,i), -1) 
37.                        rgb_planes = cv2.split(img) 
38.                        arr = np.array([]) 
39.                        result_norm_planes = [] 
40.                        for plane in rgb_planes: 
41.                         #Transformación de la imagen 
42.                            dilated_img = cv2.dilate(plane, np.ones((7,7), np.uint8)) 
43.                            bg_img = cv2.medianBlur(dilated_img, 21) 
44.                            diff_img = 255 - cv2.absdiff(plane, bg_img) 
45.                            norm_img = cv2.normalize(diff_img,arr, alpha=0, beta=255, norm
_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1) 
46.                            result_norm_planes.append(norm_img)             
47.                        result_norm = cv2.merge(result_norm_planes) 
48.                        result_norm = rgb2gray(result_norm)  # Normaliza imagen 
49.                        threshold_global_otsu = threshold_otsu(result_norm) 
50.                        global_otsu = img >= threshold_global_otsu 
51.   
52.                        fname,extension = os.path.splitext(i) 
53.                        nuevo_archivo = fname+extension 
54.                        if extension != ".jpg" : 
55.                            newfile = fname + ".jpg" 
56.                        cv2.imwrite(os.path.join(dir_datos_finales+'/'+x,nuevo_archivo), glo
bal_otsu, [int(cv2.IMWRITE_JPEG_QUALITY), 90]) 
57.                        print ("Transformación de la imagen: %s - %s " % (x,i)) 
88 
 
58.                    except Exception: 
59.                         print ("Error al transformar la imagen: %s - %s " % (x,i)) 
60.                         sys.exit(1) 
61.                contador +=1 
62.     except Exception: 
63.         print ("Error, del directorio: ") 
64.         sys.exit(1) 
65. leet() 
66.   
 
De la clase entrenamiento se describen las siguientes características: 
• Utiliza la biblioteca para evaluar las imágenes. 
• Se especifican directorios de las imágenes y se agregan atributos requeridos. 
• El método procesaEntrenamiento es la encargada de validar imágenes y cargar el 
modelo Inception_V3 entrenado en imagenet para ejecutar el entrenamiento. 
• Congela el modelo, es decir permite obtener sus pesos y atributos de la red. 
• Crea modelo y se agregan bases que conformaran la red convolucional. 
• Imprime detalles del modelo. 
• Compila el modelo. 
• Ejecuta el entrenamiento conforme a los atributos específicos como batch y épocas. 
• Guarda el modelo. 
• Imprime estadísticas del proceso de entrenamiento. 
La representación de la clase ejecutada se muestra en el listado código 3.2. 
 
Listado de código. 3.2 Clase Entrenamiento.py 
1. # -*- coding: utf-8 -*- 
2.   
3. """ 
4. Created on Wed Aug 28 11:47:42 2019 
5.   
6. @author: aaron 
7. """ 
8.   
9. from keras.preprocessing.image import ImageDataGenerator 
89 
 
10. import numpy as np 
11. import matplotlib.pyplot as plt 
12. import keras 
13. from keras.applications import InceptionV3 
14. from keras.layers import Activation, Dropout, Flatten, Dense 
15. from keras.optimizers import SGD 
16.   
17. class Entrenamiento: 
18.   
19. dir_entre = 'dataset/' 
20. dir_test = 'test/' 
21. num_bach = 500 
22. img_tam = 255 
23. num_clases = 27 
24.   
25. img_entre = ImageDataGenerator(validation_split=0.3, 
26.                                    shear_range=0.2, 
27.                                    zoom_range=0.2, 
28.                                    horizontal_flip=True) 
29.   
30. gen_entre = img_entre.flow_from_directory( 
31.                         directory=dir_entre, 
32.                         target_size=(img_tam,img_tam), 
33.                         batch_size=num_bach, 
34.                         class_mode='categorical', 
35.                         color_mode='rgb', 
36.                         shuffle=True) 
37.   
38. x_batch, y_batch = gen_entre.next() 
39.   
40. def procesaEntrenamiento() 
41. # Imprime las imagenes, verifica la validación de las imagenes 
42. fig=plt.figure() 
43. columna = 5 
44. fila = 5 
45. for i in range(1, columna*fila): 
46.     num = np.random.randint(num_bach) 
47.     imagen = x_batch[num].astype(np.int) 
48.     fig.add_subplot(fila, columna, i) 
49.     plt.imshow(imagen) 
50. plt.show() 
51.   
52. #Carga el modelo de Inception_v3 
53. modelo_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(i
mg_tam, img_tam, 3)) 
54.   
55. print(modelo_base.summary()) 
90 
 
56.   
57. # Congela el modelo 
58. for capa in modelo_base.layers: 
59.     capa.trainable = False 
60.   
61. # Crea el modelo 
62. modelo = keras.models.Sequential() 
63.   
64. # Agrega el modelo de convolución 
65. modelo.add(modelo_base) 
66.   
67. # Agrega nueva base 
68. modelo.add(Flatten()) 
69. modelo.add(Dense(1024, activation='relu')) 
70. modelo.add(Dense(num_clases, activation='softmax')) 
71.   
72. # Imprime los detalles del modelo 
73. print(modelo.summary()) 
74.   
75. #  Compile the model 
76. modelo.compile(loss='categorical_crossentropy', 
77.           optimizer=SGD(lr=1e-3), 
78.           metrics=['accuracy']) 
79.   
80. #  Inicia el proceso de entrenamiento 
81. historico = modelo.fit_generator( 
82.         gen_entre, 
83.         steps_per_epoch=gen_entre.n/num_bach, 
84.         epochs=100) 
85.   
86. # Guarda el modelo con el siguiente nombre 
87. modelo.save('modelo_final.h5') 
88.   
89. # Imprime el resumen historico del modelo 
90. plt.plot(historico.history['loss']) 
91. plt.title('loss') 
92. plt.ylabel('loss') 
93. plt.xlabel('epoch') 
94. plt.legend(['loss'], loc='upper left') 
95. plt.show() 
 
 
En la clase Exportar Modelo representado en Listado de código.3.3 permite ordenar los 
modelos en diferentes carpetas necesario para el versionado de software, cuando se generen 
91 
 
nuevos reentrenamientos para aumentar las imágenes y tener una recopilación de los modelos 
adquiridos y entrenados.  
Cuenta con la siguiente estructura: 
• Importación de atributos y métodos. 
• Carga el nombre del modelo 
• Firmas de predicción, encargadas de medir los pesos y variables del modelo 
• Genera un modelo de prueba y el modelo conforme a la dirección que se solicita. 
• Guarda el modelo en archivos específicos para su correcta implementación. 
 
Listado de código. 3.3 Clase ExportarModelo.py 
1. # -*- coding: utf-8 -*- 
2. """ 
3. Created on Wed Aug 28 11:47:42 2019 
4.   
5. @author: aaron 
6. """ 
7.   
8. from keras.models import load_model 
9. import numpy as np 
10. from keras import backend as K 
11. import tensorflow as tf 
12.   
13. class ExportarModelo : 
14. modelo = load_model('modelo_final.h5') 
15. signature = tf.saved_model.signature_def_utils.predict_signature_def(   
16.     inputs={'image': modelo.input}, outputs={'scores': modelo.output}) 
17.   
18. dir_export = 'my_image_classifier/1' 
19.   
20. builder = tf.saved_model.builder.SavedModelBuilder('tmp/my_saved') 
21.   
22. def guarda() : 
23.   
24. builder.add_meta_graph_and_variables( 
25.     sess=K.get_session(), 
26.     dir_export,                                       
27.     tags=[tf.saved_model.tag_constants.SERVING],                                       
28.     signature_def_map={                                       
92 
 
29.         tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_D
EF_KEY:                           
30.             signature                       
31.     })                                       
32. builder.save() 
33. print ('Guardado satisfactoriamente') 
 
Para la clase servidor es necesario comprender ciertas definiciones que se le atribuyen a la 
construcción del servicio. Como primer punto se definen ciertos componentes que se 
necesitan para entender la arquitectura. El servicio REST (Representational State Transfer, 
Transferencia de Estado Representacional), permite crear un estilo de arquitectura con ciertas 
restricciones y respetar claramente el protocolo HTTP. TensorFlow Serving es un sistema de 
servicio flexible y de alto rendimiento para modelos de aprendizaje automático, diseñado 
especialmente para entornos productivos. Además, TensorFlow Serving hace mucho más 
sencillo la implementación de nuevos algoritmos y experimentos, manteniendo la misma API 
y arquitectura, provee una alta integración con los modelos generados por la API 
TensorFlow, inclusive con otros tipos de modelos. Servables es la extracción central en 
TensorFlow Serving, se encargan de hacer cálculos entre actividades que marcan: resultados 
de transmisión, experimentos de la API, operación asíncrona y no mantienen su propio ciclo 
de vida. Servable Versions permite cargar más configuraciones de algoritmos. Streams 
Servibles, ordena las versiones, Models representan uno o más servidores, Loaders, gestionan 
el API para cargar y descargar un servidor. Fuente, permite cero o más secuencias de 
servicios de los Loader, Managers manejan el clico de vida de los servidores; y Core, 
gestiona los Servables (ver. Fig. 3.26). 
 Core 
 Servable TensorFlowClient DynamicManager Loader 
Handle Servable 
 Version 
Policy 
 File 
Source 
System 
 
Fig. 3.26 Arquitectura de TensorFlow Serving 
93 
 
Sources crea Loaders para los Servable Versions, mientras que Loaders enviados como 
Aspire Version, quienes atienden las solicitudes de los clientes. Se toma en cuenta que la 
imagen pasa en una cadena codificada en Base64. Ya que JSON no tiene otra forma de 
especificar la imagen ya que es una matriz. La tecnología se aplica en Python 3.6, anaconda 
1.9.6 y TensorFlow al iniciar se aplicará sobre el puerto 8501 y la API REST se localizará en 
el puerto 9000. Al solicitar la respuesta se verifica que se encuentra totalmente estable y 
funcional de la siguiente forma (ver Fig. 3.27). Por último, se necesita ejecutar un comando 
específico en la terminal para iniciar el servicio que cuenta con la siguiente codificación (ver 
Listado de código.3.4).   
 
Listado de código. 3.4 Comando para la terminal en linux 
1.  -$tensorflow_model_server --model_base_path=Dirección de la clase de Python  
2.  –rest_api_port=Puerto --model_name=Nombre del modelo  
 
 
Fig. 3.27 Respuesta del servicio 
Una vez generado esta opción permite mantener activo el servicio y obtener la clasificación 
necesaria conforme a la imagen solicitada (ver Listado de código.3.5). 
La clase cuenta con la siguiente implementación: 
94 
 
• Ruta del clasificador 
• Carga de la imagen,  
• Transformación de la imagen. 
• Generación de la estructura JSON  
• Crea predicción en la ruta con formato utf-8 
• Regresa las cuatro primeras posiciones clasificadas en JSON 
 
Listado de código. 3.5  Clase Servidor.py 
1. # -*- coding: utf-8 -*- 
2. """ 
3. Created on Wed Aug 28 11:47:42 2019 
4.   
5. @author: aaron 
6. """ 
7. import base64 
8. import json 
9. from io import BytesIO 
10.   
11. import numpy as np 
12. import requests 
13. from flask import Flask, request, jsonify 
14. from keras.applications import inception_v3 
15. from keras.preprocessing import image 
16.   
17. # Agrega la biblioteca Flask 
18.   
19. app = Flask(__name__) 
20.   
21. # se hace post sobre el servicio 
22.   
23. @app.route('/imageclassifier/predict/', methods=['POST']) 
24. def image_classifier(): 
25.   
26.     # Decodificaciòn y revisión de la imagen en base 64 
27.     img = image.img_to_array(image.load_img(BytesIO(base64.b64decode(request.f
orm['b64'])), 
28.                                             target_size=(224, 224))) / 255. 
29.     #tranformación por posible error y ejecución de transformación 
30.     img = img.astype('float16') 
31.     dilated_img = cv2.dilate(img, np.ones((7,7), np.uint8)) 
32.      bg_img = cv2.medianBlur(dilated_img, 21) 
95 
 
33.      diff_img = 255 - cv2.absdiff(plane, bg_img) 
34.      norm_img = cv2.normalize(diff_img,arr, alpha=0, beta=255,       norm_type=cv2
.NORM_MINMAX, dtype=cv2.CV_8UC1) 
35.     result_norm_planes.append(norm_img)             
36.     result_norm = cv2.merge(result_norm_planes) 
37.     result_norm = rgb2gray(result_norm)  # Normaliza imagen 
38.     threshold_global_otsu = threshold_otsu(result_norm) 
39.      global_otsu = img >= threshold_global_otsu 
40.     img = global_ otsu 
41.   
42.     # Crea la estructura de Json 
43.     JsonCarga = { 
44.         "instances": [{'input_image': img.tolist()}] 
45.     } 
46.   
47.     # Making POST request 
48.     r = requests.post('http://localhost:9000/v1/models/ImageClassifier:predict', json=J
sonCarga) 
49.   
50.     # Decodificación de los resultados del servicio 
51.     pred = json.loads(r.content.decode('utf-8')) 
52.   
53.     # Regresa la respuesta en JSON al FrontEnd los cuatro primeros 
54.     return jsonify(inception_v3.decode_predictions(pred, top=4))) 
 
En conclusión, conocer los diagramas de clases y el código fuente permite identificar partes 
importantes del desarrollo, como la implementación del entrenamiento y la ejecución de su 
servicio. 
 
3.6. Implementación del módulo de generación de código. 
En este capítulo se describe la constitución del módulo generador de código. 
El generador se encuentra diseñado con el lenguaje de programación PHP, esto permite ser 
desplegado en cualquier tipo de servidor Web, como también la utilización de una posible 
respuesta RESTFul. 
3.6.1. Archivo de configuración basado en XML 
En este segmento se aborda la conformación de la estructura del archivo XML (ver Fig.3.28), 
de acuerdo a al formato y sus características, los datos principales de la aplicación son: 
96 
 
• userName: constituido por el nombre del usuario en la aplicación. 
• name: atributo que describe el nombre de la aplicación. 
• vendor: atributo del nombre de la institución o empresa. 
• shortName: atributo del nombre corto de la aplicación. 
• version: atributo que especifica la versión del proyecto de la aplicación.  
• icon: atributo que corresponde al nombre de la imagen de la aplicación.  
• typeApp: atributo donde se especifica el tipo de aplicación a generar en este caso una 
aplicación e-Commerce o Social Media. 
• authors: etiqueta que permite almacenar los datos del autor de la aplicación como 
nombre, correo, sitio Web y por último el nombre de la compañía. 
• deploySettings: un conjunto de atributos que permiten almacenar las características 
de despliegue de la aplicación. Las principales etiquetas son las siguientes. 
o Build: atributo que contiene las plataformas de cuales se va a generar la 
aplicación.  
o Orientación: atributo que contiene el tipo de orientación de la aplicación se 
cuentan con dos opciones Portrait y Landscape.  
o Template: atributos que especifican la posición del componente en la 
aplicación.   
• navigation: un conjunto de atributos que permite almacenar las características de 
navegación de la aplicación desde un inicio hasta un fin. Las principales etiquetas son 
las siguientes.   
o Id: atributo que hace referencia a un identificador único del componente  
o Name: atributo que especifica el nombre del componente 
o Title: atributo que representa el nombre desplegado del componente  
o Type: atributo que determina si el patrón es simple o compuesto. 
o Next: atributo que especifica el orden de navegación a una página siguiente. 
o Position: atributo que especifica el orden del componente que en la interfaz 
gráfica. 
 
97 
 
 
Fig. 3.28 Estructura del generador XML 
98 
 
3.6.2. Estructura final de los proyectos generados  
En este punto se hace una breve descripción del contenido base de las plataformas que se 
necesita para generar un proyecto, es por eso que la estructura va determinada de acuerdo a 
las siguientes características (ver Fig. 3.29). ProjectBase es la carpeta principal y se divide 
en diferentes plataformas como: Desktop, Mobile y TV. Desktop cuenta con la carpeta Web, 
Mobile cuenta con la estructura de Android™, MacOS® y Web, y TV con Android™. 
 
  
Fig. 3.29 Estructura de la carpeta ProjectBase 
 
Dicho lo anterior, cada carpeta corresponde a un proyecto nuevo, estandarizado para ejecutar 
un proyecto básico que permita la manipulación de este. El proyecto tiene la característica de 
mantener una estructura de tal forma que el usuario lo exporte a un IDE de acuerdo a la 
plataforma de desarrollo, esto es, 1) los proyectos en Web usados desde cualquier tipo IDE 
con soporte para el desarrollo Web, 2) los proyectos en Android™ cuenta con soporte para 
el despliegue en Android™ Studio y 3) los proyectos creados para macOS® cuenta con 
soporte para el despliegue en Xcode. 
La estructura del proyecto base para el desarrollo de aplicaciones Web, son para las siguientes 
plataformas Desktop, Mobile y TV. La estructura raíz de la carpeta se observa en la Fig. 3.30.  
 
99 
 
 
Fig. 3.30 Estructura de la carpeta para el proyecto Web 
 
La estructura del proyecto base para el desarrollo de aplicaciones en Android™, son para las 
siguientes plataformas Mobile y TV. La estructura de la carpeta se observa en la Fig. 3.31.  
 
 
Fig. 3.31 Estructura de la carpeta para el proyecto Android™ 
 
Por otra parte, la estructura del proyecto base para el desarrollo de aplicaciones en macOS™, 
es para la plataforma Mobile. La estructura raíz de la carpeta se observa en la Fig. 3.32.  
 
100 
 
 
Fig. 3.32 Estructura de la carpeta para el proyecto macOS® 
 
3.6.3. Servicio REST del módulo generador de aplicaciones 
En esta subsección se describen las partes fundamentales de la ejecución del servicio REST, 
que genera de acuerdo a las características del archivo de configuración XML el código 
fuente de una aplicación. 
En el Listado de código.3.5 la petición al módulo generador de aplicaciones, se realiza 
mediante los comandos curl, que permite verificar la conectividad URL, transferir el archivo 
XML y ejecutar el método solicitado. 1) en la línea 1 del código se invoca el método 
writeFile () que permite escribir la estructura completa del XML. 2) En la línea 3 y 4 
se especifica la dirección del servidor donde se encuentra el servicio, 3) en la línea 5 se 
inicializa la conexión con el servicio, 4) en la línea 6 se crea un arreglo que envía los 
siguientes parámetros que el servicio solicita para la correcta generación de la aplicación. 
Los parámetros se describen a continuación. 
• projectNameString: variable del nombre proyecto  
• atilaString: variable que contiene el nombre del archivo XML 
• type: nombre del método que permite generar la aplicación basado en las 
características del archivo XML. 
5) En la línea 13, 14 y 15 se ejecuta el comando CURL para enviar y recibir la información 
generada por el servicio. 
 
101 
 
Listado de código. 3.6 Servicio.php 
1. $this->writeFile($xml); 
2. //var_dump($xml); 
3. $actual_link = "http://$_SERVER[HTTP_HOST]"; 
4. $service_url = $actual_link."/Atila-Desarrollo/entities/uploadFiles.php"; 
5. $curl = curl_init($service_url); 
6. $curl_post_data = array( 
7. "projectNameString" => $this->appname, 
8. "atilaString" => $xml, 
9. "type" => "upstring" ); 
10. curl_setopt($curl, CURLOPT_RETURNTRANSFER, true); 
11. curl_setopt($curl, CURLOPT_POST, true); 
12. curl_setopt($curl, CURLOPT_POSTFIELDS, $curl_post_data); 
13. $curl_response = curl_exec($curl); 
14. curl_close($curl); 
15. return $curl_response; 
 
El servicio retorna un archivo ZIP con la estructura de carpetas de los proyectos generados 
por plataforma y por dispositivos especificados en el documento de configuración XML. 
  
102 
 
Capítulo 4 Resultados 
En este capítulo se exponen dos diferentes casos, estas pruebas tiene como objetivo generar 
aplicaciones multidispositivo de tipo e-Commerce y Social Media por medio de una imagen 
que representa una interfaz para uno de estos dos tipos de aplicaciones. El proceso de 
identificación de elementos es generado por una red neuronal convolucional y a partir de los 
resultados obtenidos se realiza la generación automática del código fuente de la aplicación. 
Este proceso de generación de software consiste en un conjunto de pasos a seguir para cada 
caso de estudio.  
El primer caso de estudio consiste en ingresar una imagen que representa una composición 
de UIDPs no ideal y agregar los datos de configuración para generar una aplicación de tipo 
e-Commerce para un dispositivo móvil Android™. El segundo caso de estudio plantea la 
generación de una aplicación Social Media, de forma similar al primer caso de estudio se 
parte de una imagen real a color que representa una composición de UIDPs con datos de 
configuración para un dispositivo Android™ TV. 
  
4.1. Caso de estudio 1: Generación de una aplicación de e-Commerce 
Para el primer caso de estudio, se propone la generación de un proyecto de tipo e-Commerce 
para un dispositivo móvil en AndroidTM, se presenta el funcionamiento del generador de 
aplicaciones, que implican la carga de la imagen, selección de patrones, selección de 
dominio, selección de plantilla, selección del tipo de aplicación, selección del tipo de 
plataforma y dispositivo, datos de configuración general y la descarga del código fuente 
generado. Por último, la aplicación se despliega en el IDE con el objetivo de revisar el 
funcionamiento. 
 
4.1.1. Diseño de la aplicación a generar 
En esta subsección se explican los componentes de diseño para la aplicación a realizar. En 
este sentido, el caso de estudio está constituido por la composición que lleva por nombre 
Bus-men-sho-pro-com, orientado para la compra de uno a varios productos con un formato 
B2C, los UIDPs que la integran son los siguientes: 
103 
 
• Search: localizado en el parte superior derecho permite buscar productos que se 
encuentra almacenados.  
• Menu: Localizado en el parte superior izquierdo permite acceder a otras vistas que 
motivan al usuario para visitar un producto de su interés, comprarlo o comentarlo y 
facilitar la navegación en la aplicación. 
• Product Page: Permite ver las características del producto seleccionado, que incluye 
una imagen del producto y la información de venta. 
• Shopping Cart: Permite al usuario comprobar los productos seleccionados por el 
usuario y ver el total de los productos seleccionados por el usuario.  
• Comment: Permite agregar descripciones u opiniones de los usuarios acerca del 
producto que se desea comprar. 
En la figura 4.1 se observa el diseño de esta composición. 
 
 
Fig. 4.1 UIDP para el caso de estudio 1 
 
Una vez descrita la composición de UIDPs, el siguiente paso es generar una imagen no ideal, 
la imagen cuenta con una resolución de 1050 * 650 pixeles y generado en un editor de dibujo 
que se tomó en cuenta el diseño de la Fig. 4.1 tal como se observa en la Fig. 4.2. 
104 
 
 
Fig. 4.2 UIDP no ideal para el caso de estudio 1 
 
El UIDP dibujado a mano alzada se utilizó en la herramienta para la generación de la 
aplicación. 
 
4.1.2. Generación de aplicación  
En esta subsección se continúa con el caso de estudio, en esta parte se describe el 
funcionamiento de la aplicación para generar un proyecto conforme a la imagen se ingresa y 
se agrega las características al proyecto.  
El primer paso es ingresar a la pestaña Freehand, donde se muestra el formulario para 
seleccionar la imagen y el botón de Upload File para iniciar el proceso de identificación (ver 
Fig. 4.3). 
 
Fig. 4.3 Menú del generador pestaña Freehand 
105 
 
Al darle al botón seleccionar archivo abrirá una ventana de selección y se buscará la imagen 
que representa la composición de UIDPs (ver Fig. 4.4). 
 
 
 
Fig. 4.4  Pestaña Freehand selección de imagen 
Al darle al botón Abrir pre-visualiza la imagen cargada en el seleccionador de imagen. Al 
darle clic al botón Upload File continúa con el siguiente paso (ver Fig. 4.5). 
 
  
Fig. 4.5 Pestaña Freehand selección de imagen 
106 
 
Una vez dado clic en Upload File hará una carga de la imagen y hará un tiempo de espera 
con un promedio de 5 segundos para continuar (ver Fig. 4.6). 
 
  
Fig. 4.6 Pestaña Freehand subiendo archivo 
Al terminar al cargar la imagen, el mensaje Loading imagen desaparecerá, a través de un 
modal se notifica e indica la clasificación de los cuatro primeros UIDPs identificados que 
tengan parecido, para el modal se tendrá dos opciones: Change UIDPs que permite 
seleccionar los UIDPs clasificados y I agree UIDPs que permite pasar al proceso de selección 
de dominio, omitiendo la elección de UIDPs (ver Fig. 4.7).  
 
  
Fig. 4.7 Pestaña Freehand UIDPs identificados 
107 
 
En este caso, se elige la opción Change UIDPs, la pantalla de selección de patrones 
desplegará los cuatro primeros patrones identificados y seleccionados, (ver Fig. 4.8). 
 
  
Fig. 4.8 Pestaña Freehand Select Patterns 
 
Por último, se elegirá un solo patrón de composición que más se parezca al UIDP original, el 
cual es patrón Bus-men-sho-pro-com (ver Fig. 4.9). 
 
  
Fig. 4.9 Pestaña Freehand Select Patterns 
108 
 
Al continuar con el proceso se muestra la sección de Dominio, para este patrón su relación 
corresponde solamente para el dominio entretenimiento, por lo que se selecciona y continúa 
con el proceso (ver Fig. 4.10). 
 
 
Fig. 4.10 Pestaña Freehand Select Domain 
 
El siguiente paso es la selección de plantillas, para este caso se cuenta con una relación ya 
que no todas las plantillas son aplicables para el patrón identificado (ver Fig 4.11)  
 
 
Fig. 4.11 Pestaña Freehand Select Template 
109 
 
Ahora se selecciona el tipo de aplicación e-Commerce, en este caso se cuenta con B2C y 
C2C, este caso de estudio se trata de una aplicación B2C (ver Fig. 4.12). 
 
 
Fig. 4.12 Pestaña Freehand Select the type of Entertainment Application 
 
Ahora, la selección de plataforma y dispositivos, que para este caso se elige la opción 
Tablet/Smartphone y se selecciona la opción para la versión de Android™ (ver Fig. 4.13). 
 
 
Fig. 4.13 Pestaña Freehand Select Device and Platform 
110 
 
Al continuar, en la pantalla de configuración permite agregar las propiedades al proyecto, se 
llena un pequeño formulario con datos generales de la aplicación y datos del autor de la 
aplicación. Para la aplicación se cuenta con el título de aplicación, un nombre corto y la 
versión que requiere. Mientras que para el autor se cuenta con el nombre, la compañía, el 
email y el sitio Web (ver Fig. 4.14). 
 
 
Fig. 4.14 Pestaña Freehand Configure Application 
 
Al enviar los datos, la herramienta solicita validar la información a través de un modal con 
un breve resumen de los datos de configuración que cuenta el proyecto a generar. Se muestra 
la siguiente información: el nombre de la aplicación, el dominio, el tipo de patrón 
seleccionado, la plantilla y el dispositivo seleccionado. En caso de aceptar, cargará la pestaña 
Descarga (ver Fig. 4.15). En caso de que se cancele, permite cambiar la configuración de las 
propiedades.  
111 
 
 
Fig. 4.15 Pestaña Freehand Configure Application 
 
Al terminar con los anteriores pasos, se envía a la descarga del proyecto, mediante un archivo 
ZIP y se descargará automáticamente o en forma manual (ver Fig. 4.16).  
 
 
Fig. 4.16 Pestaña Freehand Download 
Como último paso, se descomprime y se revisa el proyecto generado por la herramienta. 
(ver Fig. 4.17). 
112 
 
 
Fig. 4.17 Archivo zip 
 
4.1.3. Revisión de la aplicación generada 
Para culminar el caso de estudio, se revisa la aplicación en el entorno de desarrollo para 
verificar que las clases y la configuración del proyecto se encuentren de forma adecuada y 
listo para ejecutar. A continuación, se muestran los patrones generados (ver fig. 4.18). 
 
Product Search y 
Page Menu Comments  Shoppoing cart 
 
 
 
 
 
 
 
Fig. 4.18 Revisión del Proyecto del caso de estudio 1 
  
113 
 
Como conclusión se menciona que el proyecto fue totalmente generado, y listo para su uso. 
En este caso se generó una aplicación e-Commerce para agregar productos a la lista de 
compras, escribir y revisar comentarios del producto, buscar productos y revisar las 
estadísticas del producto.  
 
4.2. Caso de estudio 2: Generación de una aplicación Social Media 
Para el segundo caso de estudio, se propone la generación de un proyecto de tipo Social 
Media para un dispositivo Smart TV basado en Android. 
 
4.2.1. Diseño de la aplicación a generar 
En esta subsección se explican los componentes de diseño para la aplicación a realizar. En 
este sentido, el caso de estudio está constituido por la composición que lleva por nombre 
Bus-men-gal-fol-rea, orientado a una aplicación de tipo red social cuyas características 
permite a los usuarios revisar imágenes de la comunidad, buscar imágenes, reaccionar a una 
imagen y ver las últimas imágenes actualizadas por el usuario, los UIDPs requeridos para 
esta aplicación son los siguientes: 
• Search: Localizado en la parte superior derecha, permite buscar imágenes de los 
usuarios. 
• Menu: Localizado en la parte superior izquierda, permite acceder a otras vistas que 
motivan al usuario a visitar otras secciones de su interés, tales como revisar imágenes, 
calificar y seguir a más usuarios. 
• Gallery: Permite ver las imágenes de los usuarios y de la comunidad.  
• Follow: Permite seguir a usuarios y suscribirse a las actualizaciones de sus últimas 
imágenes publicadas. 
• Reaction: Permite reaccionar a las imágenes de los usuarios. 
En la Fig. 4.19 se observa el diseño de esta composición. 
 
114 
 
 
Fig. 4.19 UIDP para el caso de estudio 2 
 
Una vez descrita la composición de UIDPs, el siguiente paso es generar una imagen real a 
color con dimensión de 1050 * 650 pixeles con formato PNG, el dibujo realizado en una hoja 
de color amarilla y trazado con un lapicero de color azul, la fotografía tomada con un 
dispositivo móvil con un lente de 10 megapíxeles, se tomó en cuenta el diseño de la Fig. 4.19 
tal como se observa en la Fig. 4.20. 
 
 
Fig. 4.20 UIDP no ideal para el caso de estudio 2 
 
La composición dibujada a mano alzada se agrega en la herramienta para la generación de la 
aplicación. 
 
115 
 
4.2.2. Generar aplicación  
En esta subsección se continúa con el caso de estudio, en esta parte se describe el 
funcionamiento de la aplicación para generar un proyecto conforme a la imagen ingresada y 
agregar las características al proyecto.  
Siguiendo los pasos del anterior caso de estudio, como primer paso se ingresa a la pestaña 
Freehand, donde se muestra el formulario para seleccionar la imagen y el botón de Upload 
File para iniciar el proceso de identificación (ver Fig. 4.21). 
 
 
Fig. 4.21 Menú del generador pestaña Freehand 
 
Al darle al botón seleccionar archivo nos abrirá una ventana de selección y para buscar la 
imagen que representa la composición de UIDPs (ver Fig. 4.22). 
 
116 
 
 
Fig. 4.22 Pestaña Freehand selección de imagen 
 
Una vez seleccionada la imagen, se presiona el botón Upload File (ver Fig. 4.23). 
 
Fig. 4.23 Pestaña Freehand selección de imagen 
 
Al continuar con la selección de la imagen, se carga la imagen (ver Fig. 4.24). 
117 
 
 
Fig. 4.24 Pestaña Freehand subiendo archivo 
 
Ahora, el modal notifica e indica la clasificación de los cuatro primeros UIDPs identificados, 
estos son: bus-tag-pag, busc-mdell-vid, busc-carr y bus-me-gal-fol-rea (ver Fig. 4.25). 
 
Fig. 4.25 Pestaña Freehand UIDPs identificados 
 
La pantalla de selección de patrones desplegará los cuatro primeros patrones identificados y 
seleccionados, (ver Fig. 4.26). 
118 
 
 
 
Fig. 4.26 Pestaña Freehand Select Patterns 
 
Se elige un solo patrón de composición que más se parezca al UIDP original, el cual es la 
composición: Bus-men-sho-pro-sta-com (ver Fig. 4.27). 
 
Fig. 4.27 Pestaña Freehand Select Patterns 
 
119 
 
Al continuar con el proceso, se muestra la sección de Dominio, para este patrón su relación 
corresponde solamente para el dominio entretenimiento (ver Fig. 4.28). 
 
 
Fig. 4.28 Pestaña Freehand Select Domain 
 
En la imagen aparece una sola plantilla a seleccionar  la opción visto en el caso anterior (ver 
Fig 4.29)  
 
Fig. 4.29 Pestaña Freehand Select Template 
Ahora se selecciona el tipo de aplicación Social Media, que en este caso es Redes sociales. 
(ver Fig. 4.14). 
120 
 
 
 
Fig. 4.30 Pestaña Freehand Select the type of Entertainment Application 
 
En seguida, se cuenta con la selección de plataforma y dispositivos, para este caso se elige la 
opción Smart Tv y se selecciona la opción para la versión de Android™ (ver Fig. 4.31). 
 
 
Fig. 4.31 Pestaña Freehand Select Device and Platform 
Al continuar, en la pantalla de configuración se agregan las propiedades al proyecto, se 
rellena un formulario con datos de despliegue de la aplicación, incluyendo datos del autor 
(ver Fig. 4.32). 
 
121 
 
 
Fig. 4.32 Pestaña Freehand Configure Application 
 
Pasa a la validación, se abre un modal con un breve resumen la configuración del proyecto a 
generar (ver Fig. 4.33). 
 
 
Fig. 4.33 Pestaña Freehand Configure Application 
Para terminar, la herramienta envía a la pantalla de Descarga del código fuente generado 
mediante un archivo ZIP (ver Fig. 4.34).  
 
122 
 
 
Fig. 4.34 Pestaña Freehand Download 
 
Finalmente, se descomprime el archivo ZIP y se revisa el proyecto generado por la 
herramienta (ver Fig. 4.35). 
 
Fig. 4.35 Archivo zip 
 
4.2.3. Revisión de la aplicación generada 
Por último, la aplicación se prueba en el entorno de desarrollo para verificar las clases y la 
configuración del proyecto, los resultados se mostraron en la Fig. 4.36 
 
 
 
123 
 
 Gallery Search Menu 
 
 Reaction y follow 
 
 
 
Fig. 4.36 Revisión del Proyecto Caso de estudio 2 
 
Como conclusión, para el segundo caso de estudio se comprueba que la generación para 
dispositivos TV la cual está lista para su compilación y ejecución.  Por lo tanto, generar una 
aplicación Social Media para las necesidades de los usuarios para dispositivos TV es 
satisfactoria y queda para el usuario la disponibilidad de ver, buscar calificar y seguir 
imágenes de uno o más usuarios y para el caso del desarrollador tiene un vínculo más sencillo 
de generar un proyecto satisfactorio para una rápida manipulación del código fuente 
generado.  
  
124 
 
Capítulo 5 Conclusión y recomendaciones 
5.1. Conclusiones 
Los resultados obtenidos gracias al apoyo de las técnicas de Deep Learning aportan un gran 
avance para estimular futuros desarrollos para diferentes ámbitos como aplicaciones 
médicas. Este aporte en la ingeniería de software, da un panorama amplio para los 
desarrolladores que buscan procedimientos exactos, confiables y con costo menor de lo 
promediado. Cabe aclarar que la integración del Deep Learning, conlleva a una nueva línea 
de investigación para desarrollar e implementar aplicaciones en diferentes dominios y crea 
nuevas técnicas, métodos, paradigmas y metodologías que ampliarán una expectativa 
diferente a las técnicas convencionales que aún se trabajan.  
Los casos de estudio presentados demuestran un claro ejemplo de que las diferentes imágenes 
de prueba (imágenes ideales, no ideales, reales en blanco y negro, y reales a color), sin 
problema de clasificación. Los resultados obtenidos no solamente obtuvieron un impacto 
importante para la clasificación, sino también el tiempo de espera para reconocer un patrón 
se concluye que es adecuado.  
Este trabajo es una extensión de investigaciones previas que se presentan en Cortes-
Camarillo et al. [24], Cortes-Camarillo et al. [25], Sánchez-Morales et al. [26] y Sánchez-
Morales et al. [28] cuyas pruebas y resultados son un margen de referencia para mejorar los 
algoritmos de identificación de UIDPs en imágenes generadas a mano alzada. 
Gracias a estas nuevas técnicas de desarrollo de software, se logra administrar mejor los 
proyectos, factibilidad del proyecto y también la reducción del costo del desarrollo. Para los 
usuarios y los desarrolladores es importante siempre contar con herramientas que faciliten el 
desarrollo de software y permitan además una interacción mucho mayor con el entorno o 
ambiente que se manipula.  
 
5.2. Recomendaciones 
Al revisar los puntos observados, desarrollados, y generados del proceso de desarrollo de 
aplicaciones determinan los siguientes puntos especiales para atender las siguientes 
recomendaciones:  
125 
 
Es claro mencionar que este trabajo se realizó con los dominios de e-Commerce y Social 
Media, por tal motivo, el generar nuevos patrones compuestos que delimiten nuevas 
funcionalidades que aprovechen resolver algunos problemas específicos como integrar más 
patrones para hacer una aplicación más completa a la hora de generar una nueva aplicación, 
a la par, da la oportunidad de trabajar con otros dominios un ejemplo de ello es el dominio 
médico, ya que cuenta con otro tipo de patrones aún por conocer y analizar. 
La utilización de la red neuronal convolucional, promueve la investigación de hallar nuevas 
formas de crear redes neuronales específicas para analizar y desarrollar e implementar nuevos 
modelos, para este caso un ejemplo sería es que se promueva un nuevo modelo que permite 
obtener características para la detección bordes más pronunciadas para el UIDP de Page 
Product. Esto es conveniente ya que solamente se adecuaría únicamente al entrenamiento y 
entendimiento de los patrones. 
A pesar que se obtuvo un buen porcentaje del 74% en la precisión al clasificar los UIDPs aún 
falta mejorar esa precisión, sería conveniente aumentar categóricamente a más de 1000 
instancias por patrón u ocupar una nueva versión de la red neuronal convolucional 
Inception_v4 que mejora ciertas capacidades de clasificar, como la optimización de la 
memoria al usar el algoritmo de propagación hacia atrás y la implementación de un nuevo 
diseño de agregar las versiones de la red neuronal de Inception en una sola. 
Es necesario tener los componentes actualizados al día, por ello es necesario realizar 
seguimiento de la actualización y/o modificación de las versiones más recientes, esto con 
motivo de que no permita generar problemas con la compatibilidad de funcionalidad de los 
componentes porque tendría problemas de generación de la aplicación. 
 
 
 
 
 
 
126 
 
Productos académicos 
En este apartado, se presentan los trabajos derivados de este proyecto de investigación. 
Artículos 
Aarón Colmenares Morales, Giner Alor-Hernández, Laura Nely 
Sánchez-Morales, Ulises Juárez Martínez, José Luis Sánchez-
Cervantes. Proceso de Desarrollo de aplicaciones para el dominio 
social media usando técnicas de Deep Learning. Research in 
Computing Science Issue 148 (7) (2019). ISSN 1870-4069 Estatus: 
Publicado. 
 
Estancia Académica 
Universidad Veracruzana. Xalapa, Ver. El Centro de 
investigación en Inteligencia (CIIA). Periodo: 1 de agosto al 31 
de agosto del 2019. Dr. Héctor Gabriel Acosta Mesa y Dr. 
Nicandro Cruz Ramírez. 
  
127 
 
Referencias 
[1] U. Schick. (2018, Marzo 29). What is Artificial Intelligence? [online]. Available: 
https://news.sap.com/2018/03/what-is-artificial-intelligence [Accessed: 18-Oct] 
[2] (2018). Deep Learning (Aprendizaje Profundo) Tres cosas que es necesario saber. 
[online]. Available: https://es.mathworks.com/discovery/deep-learning.html  [Accessed: 18-
Oct] 
[3] Y. LeCun et al., “Deep learning,” NATURE, vol 521, pp. 436-444, May 2015. 
[4] (2018). Design Patterns. [online]. Available: http://ui-patterns.com/patterns [Accessed: 
18-Oct] 
[5] M. Tsikerdekis and S. Zeadally, “Online Deception in Social Media,” Communications 
of the ACM, vol 57, Issue 9, pp. 72-80, September 2014. 
[6] (2018). Comercio Electrónico. [online]. Available https://azure.microsoft.com/es-
mx/solutions/ecommerce/ [Accessed: 18-Oct] 
[7] (2018). TensorFlow [online]. Available: https://www.tensorflow.org/?hl=es  [Accessed: 
18-Oct] 
[8] (2018). Theano at a Glance. [online]. Available: 
http://deeplearning.net/software/theano/introduction.html [Accessed: 18-Oct] 
[9] (2018). Caffe. [online]. Available: http://caffe.berkeleyvision.org/ [Accessed: 18-Oct] 
[10] (2018). Deep Learning for Java. [online]. Available: https://deeplearning4j.org/ 
[Accessed: 18-Oct] 
[11] (2018). What is Python? Executive Summary. [online]. Available: 
https://www.python.org/doc/essays/blurb/  [Accessed: 18-Oct] 
[12] (2018). What is Java technology and why do I need it. [online]. Available: 
https://www.java.com/en/download/faq/whatis_java.xml  [Accessed: 18-Oct] 
[13] (2018). C programming Language.  [online]. Available: 
https://www.techopedia.com/definition/24068/c-programming-language-c [Accessed: 18-
Oct] 
128 
 
[14] (2018). BOA Constructor. [online]. Available: http://boa-constructor.sourceforge.net/ 
[Accessed: 18-Oct] 
[15] (2018). Eclipse. [online]. Available: https://www.eclipse.org/ide/ [Accessed: 18-Oct] 
[16] (2018). PyDev. [online]. Available: http://www.pydev.org/ [Accessed: 18-Oct] 
[17] (2018). NetBeans IDE Features. [online]. Available: https://netbeans.org/features/ 
[Accessed: 18-Oct] 
[18] (2018). What is the Apache HTTP Server Project?. [online]. Available: 
http://httpd.apache.org/ABOUT_APACHE.html . [Accessed: 18-Oct] 
[19] (2018). Apache Tomcat. [online]. Available:  http://tomcat.apache.org/ [Accessed: 18-
Oct] 
[20] (2018). Oracle GlassFish Server. [online]. Available:  
http://www.oracle.com/technetwork/middleware/glassfish/overview/index.html  [Accessed: 
18-Oct] 
[21] E. G. Maida and J. Pacienzia. (2015, diciembre). Metodologías de desarrollo de 
software, [online]. Available FTP:  bibliotecadigital.uca.edu.ar Directory: repositorio/tesis 
File: metodologias-desarrollo-software.pdf 
[22] S. A. Asri et al., “Web Based Information System for Job Training Activities Using 
Personal Extreme Programming (PXP),” in Journal of Physics Conference Series, pp. 1-8, 
Enero 2018. 
[23] E. G. Maida and J. Pacienzia. (2015, diciembre). Metodologías de desarrollo de 
software, [online]. Available FTP:  bibliotecadigital.uca.edu.ar Directory: repositorio/tesis 
File: metodologias-desarrollo-software.pdf 
[24] V. Y. Rosales-Morales et al., “An analysis of tools for automatic software development 
and automatic code generation,” Facultad de Ingenieria, No. 77, pp. 75-87, December 2015. 
[25] C. A. Cortes-Camarillo et al., “Análisis comparativo de patrones de diseño de interfaz 
de usuario para el desarrollo,” Research in Computing Science, vol 126, pp. 31-41, 2016. 
129 
 
[26] C. A. Cortes-Camarillo et al., “EduGene: A UIDP-Based Educational App Generator 
for Multiple Devices and Platforms,” International Journal of Human-Computer Interaction, 
pp. 1-23, April 2018. 
[27] C. A. Cortes-Camarillo et al., “Atila: A UIDPs-based educational application generator 
for mobile devices,” International Conferece on Electronics, Commnications and Computers 
(CONIELECOMP), pp. 1-7, April 2017. 
[28] L. N. Sánchez-Morales et al., “Generation of User Interfaces for Mobile Applications 
Using Neuronal Networks,” New Perspectives on Applied Industrial Tools and Techniques, 
pp. 211-231, June 2017. 
[29] S. L. da-Costa et al., “A User Interface Stereotype to build Web Portals,” 9th Latin 
American Web Congress, pp. 10-18, 2014. 
[30] L. N. Sánchez-Morales et al., “Módulo de generación de aplicaciones multidispositivo 
a partir del procesamiento de imágenes,” Research in Computing Science on Computer 
science and computer engineering, Issue 9, pp. 81-94, 2015. 
[31] A. Halbe and Dr. A. R. Joshi, “A Novel Approach to HTML Page Creation Using Neural 
Network,” Procedia Computer Science, vol 45, pp. 197-204, 2015. 
[32] Y. Baveye et al., “Deep Learning for Image Memorability Prediction: The Emotional 
Bias,” Proceedings of the 2016 ACM on Multimedia Conference, pp. 491-495, October 2015. 
[33] S. Bianco et al., “Deep learning for logo recognition,” Neurocomputing, vol 245, pp. 23-
30, 2017. 
[34] Y. Liu et al., “Deep learning for pixel-level image fusion: Recent Advances and future 
prospects,” Information Fusion, vol 42, pp. 158-173, 2018. 
[35] S. Pang et al., “Deep learning to frame objects for visual target tracking,” Engineering 
Applications of Artificial Intelligence, vol 65, pp. 406-420, 2017. 
[36] A. Krishevsky et al., “ImageNet classification with deep convolutional neural 
networks,” NIPS’12 Proceedings of the 25th International Conference on Neural Information 
Processing Systems, vol 1, pp. 1-9, December 2012. 
130 
 
[37] C. Huang et al., “Large-scale Semantic Web Image Retrieval Using Bimodal Deep 
Learning Techniques,” Information Sciences, pp. 1-39, November 2017. 
 [38] A. Nedzved et al., “Software Development Technology with Automatic Configuration 
to Classes of Image Processing Problems,” Software and Hardware for pattern recognition 
and image analysis, vol 23, No 2, pp 269-277, 2013. 
 
131 
 
